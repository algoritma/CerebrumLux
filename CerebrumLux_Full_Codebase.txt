--- CMakeLists.txt --- 
cmake_minimum_required(VERSION 3.20)
project(CerebrumLux)

set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

find_package(Qt6 REQUIRED COMPONENTS Core Gui Widgets Charts)

set(CMAKE_AUTOMOC ON)
set(CMAKE_AUTORCC ON)
set(CMAKE_AUTOUIC ON)

set(PROJECT_SRC_DIR "${CMAKE_CURRENT_SOURCE_DIR}/src")
set(PROJECT_TESTS_DIR "${CMAKE_CURRENT_SOURCE_DIR}/tests")

# OpenSSL Entegrasyonu (FetchContent ile)
include(FetchContent)

FetchContent_Declare(
  openssl_project
  GIT_REPOSITORY https://github.com/openssl/openssl.git
  GIT_TAG openssl-3.1.0 # Veya ihtiyacÄ±nÄ±z olan baÅŸka bir kararlÄ± sÃ¼rÃ¼m
  FIND_PACKAGE_ARGS NAMES OpenSSL
)

FetchContent_MakeAvailable(openssl_project)

file(GLOB_RECURSE CEREBRUML_LUX_CORE_SOURCES
    "${PROJECT_SRC_DIR}/brain/*.cpp"
    "${PROJECT_SRC_DIR}/communication/*.cpp"
    "${PROJECT_SRC_DIR}/core/*.cpp"
    "${PROJECT_SRC_DIR}/data_models/*.cpp"
    "${PROJECT_SRC_DIR}/gui/*.cpp"
    "${PROJECT_SRC_DIR}/gui/panels/*.cpp"
    "${PROJECT_SRC_DIR}/meta/*.cpp"
    "${PROJECT_SRC_DIR}/planning_execution/*.cpp"
    "${PROJECT_SRC_DIR}/sensors/*.cpp"
    "${PROJECT_SRC_DIR}/user/*.cpp"
    "${PROJECT_SRC_DIR}/learning/*.cpp"
    "${PROJECT_SRC_DIR}/gui/panels/CapsuleTransferPanel.cpp"
    "${PROJECT_SRC_DIR}/learning/UnicodeSanitizer.cpp"
    "${PROJECT_SRC_DIR}/learning/StegoDetector.cpp"
)

add_library(CerebrumLuxCore STATIC ${CEREBRUML_LUX_CORE_SOURCES})

target_include_directories(CerebrumLuxCore PUBLIC
    "${PROJECT_SRC_DIR}"
    "${PROJECT_SRC_DIR}/brain"
    "${PROJECT_SRC_DIR}/communication"
    "${PROJECT_SRC_DIR}/core"
    "${PROJECT_SRC_DIR}/data_models"
    "${PROJECT_SRC_DIR}/gui"
    "${PROJECT_SRC_DIR}/gui/panels"
    "${PROJECT_SRC_DIR}/meta"
    "${PROJECT_SRC_DIR}/planning_execution"
    "${PROJECT_SRC_DIR}/sensors"
    "${PROJECT_SRC_DIR}/tools"
    "${PROJECT_SRC_DIR}/user"
    "${PROJECT_SRC_DIR}/learning"
    "${PROJECT_SRC_DIR}/external"
    "${OPENSSL_INCLUDE_DIR}"
)

target_link_libraries(CerebrumLuxCore PUBLIC Qt6::Core Qt6::Widgets Qt6::Gui Qt6::Charts OpenSSL::SSL OpenSSL::Crypto crypto)

add_executable(CerebrumLuxGUI "${PROJECT_SRC_DIR}/main.cpp")
# DÃ¼zeltme: CerebrumLuxGUI iÃ§in "-lqtmain" kaldÄ±rÄ±ldÄ±
target_link_libraries(CerebrumLuxGUI PRIVATE CerebrumLuxCore Qt6::Core Qt6::Gui Qt6::Widgets OpenSSL::SSL OpenSSL::Crypto crypto)

target_include_directories(CerebrumLuxGUI PRIVATE
    "${PROJECT_SRC_DIR}"
    "${PROJECT_SRC_DIR}/brain"
    "${PROJECT_SRC_DIR}/communication"
    "${PROJECT_SRC_DIR}/core"
    "${PROJECT_SRC_DIR}/data_models"
    "${PROJECT_SRC_DIR}/gui"
    "${PROJECT_SRC_DIR}/gui/panels"
    "${PROJECT_SRC_DIR}/meta"
    "${PROJECT_SRC_DIR}/planning_execution"
    "${PROJECT_SRC_DIR}/sensors"
    "${PROJECT_SRC_DIR}/tools"
    "${PROJECT_SRC_DIR}/user"
    "${PROJECT_SRC_DIR}/learning"
    "${PROJECT_SRC_DIR}/external"
    "${OPENSSL_INCLUDE_DIR}"
)

file(GLOB TEST_MAIN_SOURCE "${PROJECT_TESTS_DIR}/test_response_engine.cpp")
add_executable(test_response_engine ${TEST_MAIN_SOURCE})
target_link_libraries(test_response_engine PRIVATE CerebrumLuxCore OpenSSL::SSL OpenSSL::Crypto crypto)

target_include_directories(test_response_engine PRIVATE
    "${PROJECT_SRC_DIR}"
    "${PROJECT_SRC_DIR}/brain"
    "${PROJECT_SRC_DIR}/communication"
    "${PROJECT_SRC_DIR}/core"
    "${PROJECT_SRC_DIR}/data_models"
    "${PROJECT_SRC_DIR}/gui"
    "${PROJECT_SRC_DIR}/gui/panels"
    "${PROJECT_SRC_DIR}/planning_execution"
    "${PROJECT_SRC_DIR}/sensors"
    "${PROJECT_SRC_DIR}/tools"
    "${PROJECT_SRC_DIR}/user"
    "${PROJECT_TESTS_DIR}"
    "${PROJECT_SRC_DIR}/learning"
    "${PROJECT_SRC_DIR}/external"
    "${OPENSSL_INCLUDE_DIR}"
)

# YENÄ°: nlp_online_trainer iÃ§in ayrÄ± bir yÃ¼rÃ¼tÃ¼lebilir hedef
add_executable(nlp_online_trainer "${PROJECT_SRC_DIR}/tools/nlp_online_trainer.cpp")
target_link_libraries(nlp_online_trainer PRIVATE CerebrumLuxCore OpenSSL::SSL OpenSSL::Crypto crypto)

target_include_directories(nlp_online_trainer PRIVATE
    "${PROJECT_SRC_DIR}"
    "${PROJECT_SRC_DIR}/communication" 
    "${PROJECT_SRC_DIR}/core"
    "${PROJECT_SRC_DIR}/external"
    "${OPENSSL_INCLUDE_DIR}"
) 
--- SRC TREE STRUCTURE --- 
Folder PATH listing
Volume serial number is FA39-51CE
C:\USERS\AIB\CEREBRUMLUX\SRC
¦   main.cpp
¦   
+---brain
¦       autoencoder.cpp
¦       autoencoder.h
¦       cryptofig_processor.cpp
¦       cryptofig_processor.h
¦       intent_analyzer.cpp
¦       intent_analyzer.h
¦       intent_learner.cpp
¦       intent_learner.h
¦       intent_template.cpp
¦       intent_template.h
¦       prediction_engine.cpp
¦       prediction_engine.h
¦       
+---communication
¦       ai_insights_engine.cpp
¦       ai_insights_engine.h
¦       natural_language_processor.cpp
¦       natural_language_processor.h
¦       response_engine.cpp
¦       response_engine.h
¦       suggestion_engine.cpp
¦       suggestion_engine.h
¦       
+---core
¦       enums.h
¦       logger.cpp
¦       logger.h
¦       utils.cpp
¦       utils.h
¦       
+---data_models
¦       dynamic_sequence.cpp
¦       dynamic_sequence.h
¦       sequence_manager.cpp
¦       sequence_manager.h
¦       
+---external
¦   +---nlohmann
¦           json.hpp
¦           
+---gui
¦   ¦   console_stream.h
¦   ¦   DataTypes.h
¦   ¦   EngineIntegration.h
¦   ¦   engine_integration.cpp
¦   ¦   engine_integration.h
¦   ¦   MainWindow.cpp
¦   ¦   MainWindow.h
¦   ¦   
¦   +---panels
¦           CapsuleTransferPanel.cpp
¦           CapsuleTransferPanel.h
¦           GraphPanel.cpp
¦           GraphPanel.h
¦           LogPanel.cpp
¦           LogPanel.h
¦           SimulationPanel.cpp
¦           SimulationPanel.h
¦           
+---learning
¦       Capsule.h
¦       KnowledgeBase.cpp
¦       KnowledgeBase.h
¦       LearningModule.cpp
¦       LearningModule.h
¦       StegoDetector.cpp
¦       StegoDetector.h
¦       UnicodeSanitizer.cpp
¦       UnicodeSanitizer.h
¦       WebFetcher.cpp
¦       WebFetcher.h
¦       
+---meta
¦       meta_evolution_engine.cpp
¦       meta_evolution_engine.h
¦       meta_evolution_engine_sim.cpp
¦       
+---planning_execution
¦       goal_manager.cpp
¦       goal_manager.h
¦       planner.cpp
¦       planner.h
¦       
+---sensors
¦       atomic_signal.cpp
¦       atomic_signal.h
¦       signal_processor.h
¦       simulated_processor.cpp
¦       simulated_processor.h
¦       
+---tools
¦       nlp_online_trainer.cpp
¦       
+---user
        user_profile_manager.cpp
        user_profile_manager.h
        
 
--- TESTS TREE STRUCTURE --- 
Folder PATH listing
Volume serial number is FA39-51CE
C:\USERS\AIB\CEREBRUMLUX\TESTS
    test_response_engine.cpp
    
No subfolders exist 

 
--- C:\Users\aib\CerebrumLux\src\main.cpp --- 
// DÃ¼zeltme: Windows GUI uygulamalarÄ± iÃ§in Qt'nin Ã¶zel baÅŸlÄ±ÄŸÄ±
#include <QApplication>
#include <QTimer>
#include <iostream>   
#include <memory>     
#include <fstream>    
#include <QDebug>     
#include <iomanip> 
#include <sstream> 

// OpenSSL iÃ§in gerekli baÅŸlÄ±klar (Sadece EVP_CIPHER_iv_length iÃ§in gerekli olanÄ± bÄ±rakÄ±ldÄ±)
#include <openssl/evp.h>    

#include "gui/MainWindow.h"
#include "gui/engine_integration.h"
#include "gui/panels/LogPanel.h" 

#ifdef _WIN32 
#include <Windows.h>
#include <io.h>
#include <fcntl.h>
#endif

// AI core bileÅŸenleri
#include "sensors/atomic_signal.h"
#include "core/enums.h"
#include "core/utils.h" 
#include "core/logger.h"
#include "sensors/simulated_processor.h"
#include "data_models/sequence_manager.h"
#include "brain/intent_analyzer.h"
#include "brain/intent_learner.h"
#include "brain/prediction_engine.h"
#include "brain/autoencoder.h"
#include "brain/cryptofig_processor.h"
#include "communication/ai_insights_engine.h"
#include "planning_execution/goal_manager.h"
#include "planning_execution/planner.h"
#include "communication/response_engine.h"
#include "communication/suggestion_engine.h"
#include "meta/meta_evolution_engine.h"
#include "user/user_profile_manager.h"
#include "communication/natural_language_processor.h"
#include "learning/KnowledgeBase.h"
#include "learning/LearningModule.h" 
#include "learning/Capsule.h"       


// Qt'nin debug mesajlarÄ±nÄ± Logger'a yÃ¶nlendirecek Ã¶zel mesaj iÅŸleyici
void customQtMessageHandler(QtMsgType type, const QMessageLogContext &context, const QString &msg)
{
    std::string source_file = context.file ? context.file : "unknown";
    int source_line = context.line;

    switch (type) {
    case QtDebugMsg:
        Logger::get_instance().log(LogLevel::DEBUG, msg.toStdString(), source_file.c_str(), source_line);
        break;
    case QtInfoMsg:
        Logger::get_instance().log(LogLevel::INFO, msg.toStdString(), source_file.c_str(), source_line);
        break;
    case QtWarningMsg:
        Logger::get_instance().log(LogLevel::WARNING, msg.toStdString(), source_file.c_str(), source_line);
        break;
    case QtCriticalMsg:
        Logger::get_instance().log_error_to_cerr(LogLevel::ERR_CRITICAL, msg.toStdString(), source_file.c_str(), source_line);
        break;
    case QtFatalMsg:
        Logger::get_instance().log_error_to_cerr(LogLevel::ERR_CRITICAL, msg.toStdString(), source_file.c_str(), source_line);
        abort(); 
    }
}


int main(int argc, char *argv[])
{
    #ifdef _WIN32 
    SetConsoleOutputCP(CP_UTF8);
    SetConsoleCP(CP_UTF8);
    _setmode(_fileno(stdout), _O_U8TEXT);
    _setmode(_fileno(stderr), _O_U8TEXT);
    #endif

    std::ofstream early_diagnostic_log("cerebrum_lux_early_diagnostic.log", std::ios_base::app);
    if (early_diagnostic_log.is_open()) {
        early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] main function entered." << std::endl;
        early_diagnostic_log.flush();
    } else {
        std::cerr << "ERROR: Could not open early_diagnostic_log. This is a critical failure." << std::endl;
    }

    QApplication app(argc, argv);

    qRegisterMetaType<IngestResult>("IngestResult");
    qRegisterMetaType<IngestReport>("IngestReport");

    Logger::get_instance().init(LogLevel::INFO, "cerebrum_lux_gui_log.txt", "MAIN_APP"); 
    LOG(LogLevel::INFO, "Application starting up. Standard streams (cout/cerr) will output to console. Qt logs and custom logs go to GUI.");
    early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] QApplication initialized. Logger ready (buffered)." << std::endl;
    early_diagnostic_log.flush();

    // --- AI motoru bileÅŸenleri ---
    SequenceManager sequenceManager;
    IntentAnalyzer analyzer;
    SuggestionEngine suggester(analyzer);
    UserProfileManager userProfileManager;
    IntentLearner learner(analyzer, suggester, userProfileManager);
    PredictionEngine predictor(analyzer, sequenceManager);
    CryptofigAutoencoder autoencoder;
    CryptofigProcessor cryptofig_processor(analyzer, autoencoder);
    AIInsightsEngine insights_engine(analyzer, learner, predictor, autoencoder, cryptofig_processor);
    GoalManager goal_manager(insights_engine);
    NaturalLanguageProcessor nlp(goal_manager);
    Planner planner(analyzer, suggester, goal_manager, predictor, insights_engine);
    ResponseEngine responder(analyzer, goal_manager, insights_engine, &nlp);

    early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] Core AI components initialized." << std::endl;
    early_diagnostic_log.flush();

    // --- Learning Module ---
    KnowledgeBase kb;
    kb.load("knowledge.json");
    LearningModule learning_module(kb);

    early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] Learning Module and KnowledgeBase initialized." << std::endl;
    early_diagnostic_log.flush();

    // --- Meta Engine ---
    MetaEvolutionEngine meta_engine(
        analyzer,
        learner,
        predictor,
        goal_manager,
        cryptofig_processor,
        insights_engine,
        learning_module
    );

    early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] Meta Engine initialized." << std::endl;
    early_diagnostic_log.flush();

    // --- GUI entegrasyonu ---
    EngineIntegration integration(meta_engine, sequenceManager, learning_module, kb);
    MainWindow window(integration, learning_module);
    window.show(); 

    early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] MainWindow created and shown." << std::endl;
    early_diagnostic_log.flush();

    QTextEdit* guiLogTextEdit = nullptr;
    if (window.getLogPanel()) {
        guiLogTextEdit = window.getLogPanel()->getLogTextEdit(); 
    }

    if (guiLogTextEdit) {
        Logger::get_instance().set_log_panel_text_edit(guiLogTextEdit); 
        LOG(LogLevel::INFO, "Logger: Direct GUI QTextEdit link established. Buffered logs flushed to GUI.");
        early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] Logger linked directly to GUI QTextEdit." << std::endl;

        early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] Standard streams NOT redirected to GUI (intentionally). They will appear in console." << std::endl;

        qInstallMessageHandler(customQtMessageHandler);
        LOG(LogLevel::INFO, "Qt message handler installed for redirecting qDebug() etc. to Logger.");
        early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] Qt message handler installed." << std::endl;

    } else {
        LOG_ERROR_CERR(LogLevel::ERR_CRITICAL, "ERROR: GUI LogPanel's QTextEdit could not be found for direct linking. Logs will ONLY go to file and console.");
        early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] ERROR: GUI LogPanel's QTextEdit not found for direct linking." << std::endl;
    }
    early_diagnostic_log.flush();

    // --- YENÄ°: LearningModule::ingest_envelope iÃ§in Test SenaryolarÄ± ---
    LOG(LogLevel::INFO, "--- Starting LearningModule::ingest_envelope Test Scenarios ---");

    // Helper to sign and encrypt capsules for testing
    // Lambda LearningModule objesini yakalÄ±yor
    auto create_signed_encrypted_capsule = [&](const std::string& id_prefix, const std::string& content, const std::string& source_peer, float confidence) {
        Capsule c;
        static unsigned int local_capsule_id_counter = 0; // main.cpp iÃ§in yerel sayaÃ§
        c.id = id_prefix + std::to_string(++local_capsule_id_counter); 
        c.content = content;
        c.source = source_peer;
        c.topic = "Test Topic";
        c.confidence = confidence;
        c.plain_text_summary = content.substr(0, std::min((size_t)100, content.length())) + "...";
        c.timestamp_utc = std::chrono::system_clock::now();
        
        c.embedding = learning_module.compute_embedding(c.content);
        c.cryptofig_blob_base64 = learning_module.cryptofig_encode(c.embedding);

        std::string aes_key = learning_module.get_aes_key_for_peer(source_peer);
        std::string iv = learning_module.generate_random_bytes(EVP_CIPHER_iv_length(EVP_aes_256_gcm()));
        c.encryption_iv_base64 = learning_module.base64_encode_string(iv); // LearningModule'Ã¼n public base64_encode_string metodu kullanÄ±ldÄ±
        c.encrypted_content = learning_module.aes_gcm_encrypt(c.content, aes_key, iv);

        // Ed25519 fonksiyonlarÄ± yorum satÄ±rÄ± yapÄ±ldÄ±ÄŸÄ± iÃ§in burada da simÃ¼le ediyoruz
        // std::string private_key = learning_module.get_my_private_key(); 
        // c.signature_base64 = learning_module.ed25519_sign(c.encrypted_content, private_key);
        c.signature_base64 = "valid_signature"; // GeÃ§ici simÃ¼lasyon
        return c;
    };


    // Test Senaryosu 1: BaÅŸarÄ±lÄ± KapsÃ¼l Yutma (Valid Signature, Clean Content)
    Capsule test_capsule_1 = create_signed_encrypted_capsule("valid_capsule_", "Bu temiz bir test kapsuludur. Guzel bir gun geciriyoruz.", "Test_Peer_A", 0.8f);
    IngestReport report_1 = learning_module.ingest_envelope(test_capsule_1, test_capsule_1.signature_base64, test_capsule_1.source);
    LOG(LogLevel::INFO, "Test 1 Result: " << static_cast<int>(report_1.result) << " - " << report_1.message);

    // Test Senaryosu 2: GeÃ§ersiz Ä°mza
    Capsule test_capsule_2 = create_signed_encrypted_capsule("invalid_sig_capsule_", "Bu kapsulun imzasi gecersiz olmali.", "Unauthorized_Peer", 0.5f);
    test_capsule_2.signature_base64 = "invalid_signature"; // Kasten yanlÄ±ÅŸ imza
    IngestReport report_2 = learning_module.ingest_envelope(test_capsule_2, test_capsule_2.signature_base64, test_capsule_2.source);
    LOG(LogLevel::INFO, "Test 2 Result (Invalid Signature): " << static_cast<int>(report_2.result) << " - " << report_2.message);

    // Test Senaryosu 3: Steganografi Ä°Ã§eren KapsÃ¼l
    Capsule test_capsule_3 = create_signed_encrypted_capsule("stego_capsule_", "Normal gorunen bir metin ama icinde hidden_message_tag var.", "Suspicious_Source", 0.7f); // StegoDetector tetiklemeli
    IngestReport report_3 = learning_module.ingest_envelope(test_capsule_3, test_capsule_3.signature_base64, test_capsule_3.source);
    LOG(LogLevel::INFO, "Test 3 Result (Steganography Detected): " << static_cast<int>(report_3.result) << " - " << report_3.message);

    // Test Senaryosu 4: Unicode Temizleme Gerektiren KapsÃ¼l
    Capsule test_capsule_4 = create_signed_encrypted_capsule("unicode_capsule_", "Metin\x01\x02\x03iÃ§inde kontrol karakterleri var. \t Yeni satir.", "Dirty_Source", 0.9f); // UnicodeSanitizer tetiklemeli
    IngestReport report_4 = learning_module.ingest_envelope(test_capsule_4, test_capsule_4.signature_base64, test_capsule_4.source);
    LOG(LogLevel::INFO, "Test 4 Result (Sanitization Needed): " << static_cast<int>(report_4.result) << " - " << report_4.message);
    if (report_4.result == IngestResult::SanitizationNeeded) {
        LOG(LogLevel::INFO, "    Sanitized Content: " << report_4.processed_capsule.content);
    }

    LOG(LogLevel::INFO, "--- Finished LearningModule::ingest_envelope Test Scenarios ---");
    // --- Test SenaryolarÄ± Sonu ---


    // --- Engine dÃ¶ngÃ¼sÃ¼ ---
    QTimer engineTimer;
    QObject::connect(&engineTimer, &QTimer::timeout, [&](){
        meta_engine.run_meta_evolution_cycle(sequenceManager.get_current_sequence_ref());
    });
    engineTimer.start(1000); 

    early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] Engine timer started. Entering QApplication::exec()." << std::endl;
    early_diagnostic_log.flush();

    int result = app.exec();

    kb.save("knowledge.json");
    early_diagnostic_log << get_current_timestamp_str() << " [EARLY DIAGNOSTIC] Application exited with code: " << result << std::endl;
    early_diagnostic_log.close(); 
    
    return result;
} 
--- C:\Users\aib\CerebrumLux\src\brain\autoencoder.cpp --- 
#include "autoencoder.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/logger.h" // LOG makrosu iÃ§in
#include "../core/utils.h" // SafeRNG ve diÄŸer yardÄ±mcÄ± fonksiyonlar iÃ§in
#include <cmath>     // std::exp, std::sqrt iÃ§in
#include <algorithm> // std::min/max iÃ§in
#include <cstdio>    // fopen, fwrite, fread, fclose iÃ§in
#include <limits>    // std::numeric_limits iÃ§in
#include <iostream>  // std::cerr iÃ§in
#include <sstream>   // std::stringstream iÃ§in


// Statik const int Ã¼yelerinin dÄ±ÅŸ tanÄ±mlarÄ±
const int CryptofigAutoencoder::INPUT_DIM;
const int CryptofigAutoencoder::LATENT_DIM;

CryptofigAutoencoder::CryptofigAutoencoder() {
    initialize_random_weights();
}

void CryptofigAutoencoder::initialize_random_weights() {
    // DaÄŸÄ±tÄ±m nesnesi artÄ±k yerel olarak burada oluÅŸturuluyor.
    std::uniform_real_distribution<float> dist(-0.5f, 0.5f);

    encoder_weights_1.resize(INPUT_DIM * LATENT_DIM);
    encoder_bias_1.resize(LATENT_DIM);
    decoder_weights_1.resize(LATENT_DIM * INPUT_DIM);
    decoder_bias_1.resize(INPUT_DIM);

    // TÃ¼m Ã§aÄŸrÄ±lar SafeRNG kullanacak ÅŸekilde deÄŸiÅŸtirildi.
    for (size_t i = 0; i < encoder_weights_1.size(); ++i) encoder_weights_1[i] = dist(SafeRNG::get_instance().get_generator());
    for (size_t i = 0; i < encoder_bias_1.size(); ++i) encoder_bias_1[i] = dist(SafeRNG::get_instance().get_generator());
    for (size_t i = 0; i < decoder_weights_1.size(); ++i) decoder_weights_1[i] = dist(SafeRNG::get_instance().get_generator());
    for (size_t i = 0; i < decoder_bias_1.size(); ++i) decoder_bias_1[i] = dist(SafeRNG::get_instance().get_generator());

    LOG_DEFAULT(LogLevel::INFO, "CryptofigAutoencoder: Agirliklar rastgele baslatildi.\n");
}

float CryptofigAutoencoder::sigmoid(float x) const {
    return 1.0f / (1.0f + std::exp(-x));
}

float CryptofigAutoencoder::sigmoid_derivative(float x) const {
    float s = sigmoid(x);
    return s * (1.0f - s);
}

std::vector<float> CryptofigAutoencoder::encode(const std::vector<float>& input_features) const {
    if (input_features.size() != INPUT_DIM) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "CryptofigAutoencoder::encode: Girdi boyutu uyuÅŸmuyor! Beklenen: " << INPUT_DIM << ", Gelen: " << input_features.size() << "\n");
        return std::vector<float>(LATENT_DIM, 0.0f); // Hata durumunda sÄ±fÄ±r vektÃ¶r dÃ¶ndÃ¼r
    }

    std::vector<float> latent_features(LATENT_DIM, 0.0f);
    for (int j = 0; j < LATENT_DIM; ++j) {
        float sum = 0.0f;
        for (int i = 0; i < INPUT_DIM; ++i) {
            sum += input_features[i] * encoder_weights_1[i * LATENT_DIM + j];
        }
        latent_features[j] = sigmoid(sum + encoder_bias_1[j]);
    }
    return latent_features;
}

std::vector<float> CryptofigAutoencoder::decode(const std::vector<float>& latent_features) const {
    if (latent_features.size() != LATENT_DIM) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "CryptofigAutoencoder::decode: Gizil boyut uyuÅŸmuyor! Beklenen: " << LATENT_DIM << ", Gelen: " << latent_features.size() << "\n");
        return std::vector<float>(INPUT_DIM, 0.0f);
    }

    std::vector<float> reconstructed_features(INPUT_DIM, 0.0f);
    for (int j = 0; j < INPUT_DIM; ++j) {
        float sum = 0.0f;
        for (int i = 0; i < LATENT_DIM; ++i) {
            sum += latent_features[i] * decoder_weights_1[i * INPUT_DIM + j];
        }
        reconstructed_features[j] = sigmoid(sum + decoder_bias_1[j]); // Ã‡Ä±kÄ±ÅŸ katmanÄ±nda da sigmoid
    }
    return reconstructed_features;
}

std::vector<float> CryptofigAutoencoder::reconstruct(const std::vector<float>& input_features) const {
    return decode(encode(input_features));
}

void CryptofigAutoencoder::adjust_weights_on_error(const std::vector<float>& input_features, float learning_rate_ae) {
    if (input_features.size() != INPUT_DIM) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "CryptofigAutoencoder::adjust_weights_on_error: Girdi boyutu uyuÅŸmuyor! Ayarlama yapÄ±lamÄ±yor.\n");
        return;
    }

    std::vector<float> latent_features = encode(input_features);
    std::vector<float> reconstructed_features = decode(latent_features);

    float total_error = 0.0f;
    for (int i = 0; i < INPUT_DIM; ++i) {
        float error = input_features[i] - reconstructed_features[i];
        total_error += error * error;
    }
    total_error = std::sqrt(total_error / INPUT_DIM); // RMSE

    if (total_error > 0.1f) { 
        float adjustment_magnitude = learning_rate_ae * total_error; 

        for (int j = 0; j < INPUT_DIM; ++j) {
            float output_error = input_features[j] - reconstructed_features[j];
            decoder_bias_1[j] += adjustment_magnitude * output_error;
            decoder_bias_1[j] = std::min(1.0f, std::max(-1.0f, decoder_bias_1[j]));

            for (int i = 0; i < LATENT_DIM; ++i) {
                decoder_weights_1[i * INPUT_DIM + j] += adjustment_magnitude * output_error * latent_features[i];
                decoder_weights_1[i * INPUT_DIM + j] = std::min(1.0f, std::max(-1.0f, decoder_weights_1[i * INPUT_DIM + j]));
            }
        }

        for (int j = 0; j < LATENT_DIM; ++j) {
            float latent_error_signal = 0.0f;
            for (int k = 0; k < INPUT_DIM; ++k) {
                latent_error_signal += (input_features[k] - reconstructed_features[k]) * decoder_weights_1[j * INPUT_DIM + k];
            }
            encoder_bias_1[j] += adjustment_magnitude * latent_error_signal;
            encoder_bias_1[j] = std::min(1.0f, std::max(-1.0f, encoder_bias_1[j]));

            for (int i = 0; i < INPUT_DIM; ++i) {
                encoder_weights_1[i * LATENT_DIM + j] += adjustment_magnitude * latent_error_signal * input_features[i];
                encoder_weights_1[i * LATENT_DIM + j] = std::min(1.0f, std::max(-1.0f, encoder_weights_1[i * LATENT_DIM + j]));
            }
        }
        LOG_DEFAULT(LogLevel::DEBUG, "CryptofigAutoencoder: Agirliklar hataya gore ayarlandi. Hata: " << total_error << "\n");
    }
}

void CryptofigAutoencoder::save_weights(const std::string& filename) const {
    FILE* fp = fopen(filename.c_str(), "wb");
    if (!fp) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Autoencoder agirlik dosyasi yazilamadi: " << filename << " (errno: " << errno << ")\n");
        return;
    }

    fwrite(&INPUT_DIM, sizeof(int), 1, fp);
    fwrite(&LATENT_DIM, sizeof(int), 1, fp);

    size_t size;
    size = encoder_weights_1.size(); fwrite(&size, sizeof(size_t), 1, fp); fwrite(encoder_weights_1.data(), sizeof(float), size, fp);
    size = encoder_bias_1.size();    fwrite(&size, sizeof(size_t), 1, fp); fwrite(encoder_bias_1.data(), sizeof(float), size, fp);
    size = decoder_weights_1.size(); fwrite(&size, sizeof(size_t), 1, fp); fwrite(decoder_weights_1.data(), sizeof(float), size, fp);
    size = decoder_bias_1.size();    fwrite(&size, sizeof(size_t), 1, fp); fwrite(decoder_bias_1.data(), sizeof(float), size, fp);

    fclose(fp);
    LOG_DEFAULT(LogLevel::INFO, "CryptofigAutoencoder agirliklari kaydedildi: " << filename << "\n");
}

void CryptofigAutoencoder::load_weights(const std::string& filename) {
    FILE* fp = fopen(filename.c_str(), "rb");
    if (!fp) {
        LOG_DEFAULT(LogLevel::WARNING, "Uyari: Autoencoder agirlik dosyasi bulunamadi, rastgele agirliklar kullaniliyor: " << filename << " (errno: " << errno << ")\n");
        initialize_random_weights();
        return;
    }

    int loaded_input_dim, loaded_latent_dim;
    fread(&loaded_input_dim, sizeof(int), 1, fp);
    fread(&loaded_latent_dim, sizeof(int), 1, fp);

    if (loaded_input_dim != INPUT_DIM || loaded_latent_dim != LATENT_DIM) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Autoencoder agirlik dosyasi boyutlari uyuÅŸmuyor! Dosya: " << loaded_input_dim << "x" << loaded_latent_dim << ", Beklenen: " << INPUT_DIM << "x" << LATENT_DIM << ". Rastgele agirliklar kullaniliyor.\n");
        fclose(fp);
        initialize_random_weights();
        return;
    }

    size_t size;
    fread(&size, sizeof(size_t), 1, fp); encoder_weights_1.resize(size); fread(encoder_weights_1.data(), sizeof(float), size, fp);
    fread(&size, sizeof(size_t), 1, fp); encoder_bias_1.resize(size);    fread(encoder_bias_1.data(), sizeof(float), size, fp);
    fread(&size, sizeof(size_t), 1, fp); decoder_weights_1.resize(size); fread(decoder_weights_1.data(), sizeof(float), size, fp);
    fread(&size, sizeof(size_t), 1, fp); decoder_bias_1.resize(size);    fread(decoder_bias_1.data(), sizeof(float), size, fp);

    fclose(fp);
    LOG_DEFAULT(LogLevel::INFO, "CryptofigAutoencoder agirliklari yuklendi: " << filename << "\n");
}

float CryptofigAutoencoder::calculate_reconstruction_error(const std::vector<float>& original, const std::vector<float>& reconstructed) const {
    if (original.size() != reconstructed.size() || original.empty()) {
        return std::numeric_limits<float>::max();
    }
    float error_sum_sq = 0.0f;
    for (size_t i = 0; i < original.size(); ++i) {
        float diff = original[i] - reconstructed[i];
        error_sum_sq += diff * diff;
    }
    return std::sqrt(error_sum_sq / original.size());
} 
--- C:\Users\aib\CerebrumLux\src\brain\autoencoder.h --- 
#ifndef CEREBRUM_LUX_AUTOENCODER_H
#define CEREBRUM_LUX_AUTOENCODER_H

#include <vector>
#include <string>  // For std::string
#include "../core/enums.h" // LogLevel iÃ§in
#include "../core/utils.h" // SafeRNG ve diÄŸerleri iÃ§in
#include <cmath>   // std::exp iÃ§in

// *** CryptofigAutoencoder sÄ±nÄ±fÄ± tanÄ±mÄ± ***
class CryptofigAutoencoder {
public:
    // YapÄ±landÄ±rma parametreleri
    static const int INPUT_DIM = 18;  // statistical_features_vector boyutu (10'dan 18'e gÃ¼ncellendi)
    static const int LATENT_DIM = 3;  // latent_cryptofig_vector boyutu

    CryptofigAutoencoder();

    // Encoder: statistical_features -> latent_cryptofig
    virtual std::vector<float> encode(const std::vector<float>& input_features) const;

    // Decoder: latent_cryptofig -> reconstructed_statistical_features
    virtual std::vector<float> decode(const std::vector<float>& latent_features) const;
    virtual float calculate_reconstruction_error(const std::vector<float>& original, const std::vector<float>& reconstructed) const; // YENÄ° EKLENDÄ° VE VIRTUAL

    
    // Encoder ve Decoder'Ä± birleÅŸtirerek yeniden yapÄ±landÄ±rma
    std::vector<float> reconstruct(const std::vector<float>& input_features) const;

    // Meta-Ã¶ÄŸrenme esintili, tek adÄ±mlÄ± aÄŸÄ±rlÄ±k ayarlamasÄ±
    void adjust_weights_on_error(const std::vector<float>& input_features, float learning_rate_ae);

    // AÄŸÄ±rlÄ±klarÄ± dosyaya kaydetme/yÃ¼kleme
    void save_weights(const std::string& filename) const;
    void load_weights(const std::string& filename);

private:
    // AÄŸÄ±rlÄ±klar ve bias'lar
    std::vector<float> encoder_weights_1; // INPUT_DIM * LATENT_DIM
    std::vector<float> encoder_bias_1;    // LATENT_DIM

    std::vector<float> decoder_weights_1; // LATENT_DIM * INPUT_DIM
    std::vector<float> decoder_bias_1;    // INPUT_DIM

    // YardÄ±mcÄ± fonksiyonlar
    float sigmoid(float x) const;
    float sigmoid_derivative(float x) const; // Heuristik Ã¶ÄŸrenme iÃ§in gerekli olabilir
    void initialize_random_weights();
};

#endif // CEREBRUM_LUX_AUTOENCODER_H 
--- C:\Users\aib\CerebrumLux\src\brain\cryptofig_processor.cpp --- 
#include "cryptofig_processor.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/logger.h"      // LOG makrosu iÃ§in
#include "../core/utils.h"       // intent_to_string iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in
#include "intent_learner.h"      // IntentLearner iÃ§in
#include "intent_analyzer.h"     // IntentAnalyzer iÃ§in
#include "autoencoder.h"         // CryptofigAutoencoder iÃ§in
#include <numeric> // std::accumulate
#include <iostream>  // std::cerr iÃ§in
#include <sstream>   // std::stringstream iÃ§in

// === CryptofigProcessor Implementasyonlari ===
CryptofigProcessor::CryptofigProcessor(IntentAnalyzer& analyzer_ref, CryptofigAutoencoder& autoencoder_ref)
    : analyzer(analyzer_ref), autoencoder(autoencoder_ref) {}

// Bu metod DynamicSequence'i iÅŸleyerek hem statistical_features_vector'Ä± kullanacak hem de latent_cryptofig_vector'Ä± gÃ¼ncelleyecek. 
void CryptofigProcessor::process_sequence(DynamicSequence& sequence, float autoencoder_learning_rate) {
    LOG_DEFAULT(LogLevel::DEBUG, "CryptofigProcessor::process_sequence: Latent kriptofig Autoencoder ile olusturuluyor ve ogrenme tetikleniyor.\n");
    if (sequence.statistical_features_vector.empty() || sequence.statistical_features_vector.size() != CryptofigAutoencoder::INPUT_DIM) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "CryptofigProcessor::process_sequence: DynamicSequence.statistical_features_vector boÅŸ veya boyut uyuÅŸmuyor. Autoencoder iÅŸlemi atlanÄ±yor.\n");
        sequence.latent_cryptofig_vector.assign(CryptofigAutoencoder::LATENT_DIM, 0.0f); // Latent vektÃ¶rÃ¼ sÄ±fÄ±rla
        return;
    }
    sequence.latent_cryptofig_vector = autoencoder.encode(sequence.statistical_features_vector);
    autoencoder.adjust_weights_on_error(sequence.statistical_features_vector, autoencoder_learning_rate);
    LOG_DEFAULT(LogLevel::DEBUG, "CryptofigProcessor::process_sequence: Latent kriptofig olusturuldu ve Autoencoder ogrenme adimi tamamlandi.\n");
}


void CryptofigProcessor::apply_cryptofig_for_learning(IntentLearner& learner, const std::vector<float>& received_cryptofig, UserIntent target_intent) const {
    LOG_DEFAULT(LogLevel::DEBUG, "CryptofigProcessor::apply_cryptofig_for_learning: Niyet " << intent_to_string(target_intent) << " iÃ§in kriptofig ile Ã¶ÄŸrenme baÅŸlatÄ±ldÄ±.\n");
    std::vector<float> current_weights = analyzer.get_intent_weights(target_intent);
    if (current_weights.empty() || current_weights.size() != received_cryptofig.size()) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "apply_cryptofig_for_learning: Boyut uyuÅŸmazlÄ±ÄŸÄ± veya boÅŸ aÄŸÄ±rlÄ±klar. Ä°lerleme durduruldu.\n");
        return;
    }

    float assimilation_rate = learner.get_learning_rate() * 5.0f; 
    assimilation_rate = std::min(0.5f, assimilation_rate); 

    for (size_t i = 0; i < current_weights.size(); ++i) {
        current_weights[i] += assimilation_rate * (received_cryptofig[i] - current_weights[i]);
        current_weights[i] = std::min(5.0f, std::max(-5.0f, current_weights[i]));
    }
    analyzer.update_template_weights(target_intent, current_weights);
    
    LOG_DEFAULT(LogLevel::DEBUG, "CryptofigProcessor::apply_cryptofig_for_learning: Ã–ÄŸrenme tamamlandÄ±.\n");
}

// Getter metodu tanÄ±mÄ± (const)
const CryptofigAutoencoder& CryptofigProcessor::get_autoencoder() const {
    return autoencoder;
}
// Getter metodu tanÄ±mÄ± (non-const)
CryptofigAutoencoder& CryptofigProcessor::get_autoencoder() {
    return autoencoder;
}


// === CryptofigProcessor ImplementasyonlarÄ± (Eksik Metotlar GÃ¼ncellendi) ===

void CryptofigProcessor::process_expert_cryptofig(const std::vector<float>& expert_cryptofig, IntentLearner& learner) {
    LOG_DEFAULT(LogLevel::DEBUG, "[CryptofigProcessor] Uzman kriptofigi iÅŸleniyor. Boyut: " << expert_cryptofig.size() << ". Bu, AI'nÄ±n meta-evrim sÃ¼recinin bir parÃ§asÄ± olarak harici bilgi aktarÄ±mÄ±nÄ± temsil eder.\n");
    // TODO: Bu kÄ±sÄ±m, AI'Ä±n kendini geliÅŸtirmesinin ve meta-evrimin kritik bir parÃ§asÄ± olacaktÄ±r.
    // Gelecekte, bu expert_cryptofig'in hangi niyetle iliÅŸkili olduÄŸu belirlenecek ve
    // IntentLearner'Ä±n Ã¶ÄŸrenme algoritmalarÄ± bu bilgiyi sindirmek iÃ§in kullanÄ±lacaktÄ±r.
    // Ã–rneÄŸin, learner.assimilate_expert_knowledge(expert_cryptofig, inferred_target_intent); ÅŸeklinde bir Ã§aÄŸrÄ± yapÄ±labilir.
    // Åžimdilik, sadece loglama yapÄ±yoruz ve bir yapÄ±lacak notu bÄ±rakÄ±yoruz.
}

std::vector<float> CryptofigProcessor::generate_cryptofig_from_signals(const DynamicSequence& sequence) {
    LOG_DEFAULT(LogLevel::DEBUG, "[CryptofigProcessor] Sinyallerden kriptofig Ã¼retiliyor (Autoencoder kullanÄ±larak).\n");
    if (sequence.statistical_features_vector.empty() || sequence.statistical_features_vector.size() != CryptofigAutoencoder::INPUT_DIM) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "CryptofigProcessor::generate_cryptofig_from_signals: DynamicSequence.statistical_features_vector boÅŸ veya boyut uyuÅŸmuyor. BoÅŸ latent vektÃ¶r dÃ¶ndÃ¼rÃ¼lÃ¼yor.\n");
        return std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f); // Hata durumunda sÄ±fÄ±r vektÃ¶r dÃ¶ndÃ¼r
    }
    // Autoencoder kullanarak istatistiksel Ã¶zelliklerden latent kriptofig Ã¼retme
    return autoencoder.encode(sequence.statistical_features_vector);
} 
--- C:\Users\aib\CerebrumLux\src\brain\cryptofig_processor.h --- 
#ifndef CEREBRUM_LUX_CRYPTOFIG_PROCESSOR_H
#define CEREBRUM_LUX_CRYPTOFIG_PROCESSOR_H

#include <vector>
#include <string> // For wstring
#include "../core/enums.h"         // Enumlar iÃ§in
#include "../core/utils.h"         // For convert_wstring_to_string (if needed elsewhere)
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in ileri bildirim
#include "intent_learner.h"        // IntentLearner iÃ§in ileri bildirim
#include "intent_analyzer.h"       // IntentAnalyzer iÃ§in ileri bildirim
#include "autoencoder.h"           // CryptofigAutoencoder iÃ§in ileri bildirim


// Ä°leri bildirimler
class IntentAnalyzer;
class IntentLearner;
class CryptofigAutoencoder;
struct DynamicSequence;

// *** CryptofigProcessor: Kriptofiglerin olusturulmasi ve islenmesi iÃ§in ***
class CryptofigProcessor {
public:
    CryptofigProcessor(IntentAnalyzer& analyzer_ref, CryptofigAutoencoder& autoencoder_ref);

    // Bu metod DynamicSequence'i iÅŸleyerek hem statistical_features_vector'Ä± kullanacak hem de latent_cryptofig_vector'Ä± gÃ¼ncelleyecek.
    void process_sequence(DynamicSequence& sequence, float autoencoder_learning_rate); 

    void apply_cryptofig_for_learning(IntentLearner& learner, const std::vector<float>& received_cryptofig, UserIntent target_intent) const;
    //CryptofigAutoencoder& get_autoencoder() const { return autoencoder; } // Getter metodu
    virtual void process_expert_cryptofig(const std::vector<float>& expert_cryptofig, IntentLearner& learner); // YENÄ° EKLENDÄ° VE VIRTUAL
    virtual std::vector<float> generate_cryptofig_from_signals(const DynamicSequence& sequence); // YENÄ° EKLENDÄ° VE VIRTUAL
    virtual CryptofigAutoencoder& get_autoencoder(); //non-const versiyo
    virtual const CryptofigAutoencoder& get_autoencoder() const; // Getter metodu - Sadece prototip

private:
    IntentAnalyzer& analyzer;
    CryptofigAutoencoder& autoencoder; // Autoencoder referansÄ±
};

#endif // CEREBRUM_LUX_CRYPTOFIG_PROCESSOR_H 
--- C:\Users\aib\CerebrumLux\src\brain\intent_analyzer.cpp --- 
#include "intent_analyzer.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/logger.h"      // LOG makrosu iÃ§in
#include "../core/utils.h"       // intent_to_string, abstract_state_to_string iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in
#include "autoencoder.h"         // CryptofigAutoencoder::LATENT_DIM iÃ§in
#include "intent_template.h"     // IntentTemplate iÃ§in
// #include "../communication/natural_language_processor.h" // KALDIRILDI: NaturalLanguageProcessor iÃ§in eklendi
#include <algorithm>             // std::min/max iÃ§in
#include <cmath>                 // std::log10 iÃ§in
#include <fstream>               // Dosya G/Ã‡ iÃ§in
#include <iostream>              // std::cerr, std::cout iÃ§in
#include <sstream>               // std::stringstream iÃ§in


// === IntentTemplate Implementasyonu (burada kalmalÄ±, IntentAnalyzer'Ä±n bir parÃ§asÄ±) ===
IntentTemplate::IntentTemplate(UserIntent intent_id, const std::vector<float>& initial_weights)
    : id(intent_id), weights(initial_weights) {
        action_success_scores[AIAction::DisableSpellCheck] = 0.0f;
        action_success_scores[AIAction::EnableCustomDictionary] = 0.0f;
        action_success_scores[AIAction::ShowUndoHistory] = 0.0f;
        action_success_scores[AIAction::CompareVersions] = 0.0f;
        action_success_scores[AIAction::DimScreen] = 0.0f;
        action_success_scores[AIAction::MuteNotifications] = 0.0f;
        action_success_scores[AIAction::LaunchApplication] = 0.0f;
        action_success_scores[AIAction::OpenFile] = 0.0f;
        action_success_scores[AIAction::SetReminder] = 0.0f;
        action_success_scores[AIAction::SimulateOSAction] = 0.0f;
        action_success_scores[AIAction::SuggestBreak] = 0.0f;
        action_success_scores[AIAction::OptimizeForGaming] = 0.0f;
        action_success_scores[AIAction::EnableFocusMode] = 0.0f;
        action_success_scores[AIAction::AdjustAudioVolume] = 0.0f;
        action_success_scores[AIAction::OpenDocumentation] = 0.0f;
        action_success_scores[AIAction::SuggestSelfImprovement] = 0.0f; 
    }

// === IntentAnalyzer Implementasyonlari ===

// Kurucu parametresiz hale getirildi
IntentAnalyzer::IntentAnalyzer() 
    : confidence_threshold_for_known_intent(0.1f) { 
    
    // AÄŸÄ±rlÄ±klar artÄ±k LATENT_DIM boyutunda olmalÄ±
    intent_templates.emplace_back(UserIntent::FastTyping,    std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::Editing,       std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::IdleThinking,  std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    // YENÄ° NÄ°YETLER
    intent_templates.emplace_back(UserIntent::Programming,    std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::Gaming,         std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::MediaConsumption,std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::CreativeWork,   std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::Research,       std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::Communication,  std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    
    // Yeni eklenen niyetler iÃ§in baÅŸlangÄ±Ã§ aÄŸÄ±rlÄ±klarÄ±
    intent_templates.emplace_back(UserIntent::VideoEditing,   std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::Browsing,       std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::Reading,        std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 
    intent_templates.emplace_back(UserIntent::GeneralInquiry, std::vector<float>(CryptofigAutoencoder::LATENT_DIM, 0.0f)); 

    // VarsayÄ±lan aÄŸÄ±rlÄ±klarÄ± daha anlamlÄ± baÅŸlatma (latent uzaydaki temsili anlamlara gÃ¶re)
    // Ã–rn: latent_activity, latent_complexity, latent_engagement gibi
    intent_templates[0].weights = {-0.2f, -0.5f,  0.8f}; // FastTyping (DÃ¼ÅŸÃ¼k karmaÅŸÄ±klÄ±k, yÃ¼ksek etkileÅŸim)
    intent_templates[1].weights = { 0.5f,  0.8f,  0.6f}; // Editing (Orta aktiflik, yÃ¼ksek karmaÅŸÄ±klÄ±k)
    intent_templates[2].weights = { 0.8f, -0.7f, -0.5f}; // IdleThinking (YÃ¼ksek pasiflik, dÃ¼ÅŸÃ¼k etkileÅŸim)

    // Yeni niyetler iÃ§in daha iyi baÅŸlangÄ±Ã§ aÄŸÄ±rlÄ±klarÄ± (Ã¶rnek)
    intent_templates[3].weights = { 0.6f,  0.9f,  0.7f}; // Programming (odaklanma, karmaÅŸÄ±klÄ±k, etkileÅŸim)
    intent_templates[4].weights = { 0.9f,  0.7f,  0.9f}; // Gaming (yÃ¼ksek aktiflik, orta karmaÅŸÄ±klÄ±k, yÃ¼ksek etkileÅŸim)
    intent_templates[5].weights = {-0.8f, -0.6f,  0.2f}; // MediaConsumption (dÃ¼ÅŸÃ¼k aktiflik, dÃ¼ÅŸÃ¼k karmaÅŸÄ±klÄ±k, az etkileÅŸim)
    intent_templates[6].weights = { 0.7f,  0.8f,  0.7f}; // CreativeWork (orta aktiflik, yÃ¼ksek karmaÅŸÄ±klÄ±k, etkileÅŸim)
    intent_templates[7].weights = { 0.4f,  0.6f,  0.8f}; // Research (orta aktiflik, yÃ¼ksek dÄ±ÅŸ etkileÅŸim)
    intent_templates[8].weights = { 0.7f,  0.3f,  0.9f}; // Communication (yÃ¼ksek aktiflik, dÃ¼ÅŸÃ¼k karmaÅŸÄ±klÄ±k, yÃ¼ksek etkileÅŸim)
    
    // Yeni eklenen niyetler iÃ§in daha iyi baÅŸlangÄ±Ã§ aÄŸÄ±rlÄ±klarÄ± (devamÄ±)
    intent_templates[9].weights  = { 0.7f, 0.9f, 0.6f}; // VideoEditing (yÃ¼ksek karmaÅŸÄ±klÄ±k, gÃ¶rsel odaklanma)
    intent_templates[10].weights = { 0.5f, 0.4f, 0.7f}; // Browsing (orta aktiflik, dÃ¼ÅŸÃ¼k karmaÅŸÄ±klÄ±k, yÃ¼ksek dÄ±ÅŸ etkileÅŸim)
    intent_templates[11].weights = { 0.3f, 0.5f, 0.4f}; // Reading (dÃ¼ÅŸÃ¼k aktiflik, orta karmaÅŸÄ±klÄ±k, iÃ§sel odaklanma)
    intent_templates[12].weights = { 0.4f, 0.6f, 0.5f}; // GeneralInquiry (orta aktiflik, orta karmaÅŸÄ±klÄ±k, bilgi arayÄ±ÅŸÄ±)
}

UserIntent IntentAnalyzer::analyze_intent(const DynamicSequence& sequence) {
    // latent_cryptofig_vector kontrol ediliyor
    if (sequence.latent_cryptofig_vector.empty() || sequence.latent_cryptofig_vector.size() != CryptofigAutoencoder::LATENT_DIM) { 
        LOG_DEFAULT(LogLevel::WARNING, "IntentAnalyzer::analyze_intent: Latent cryptofig vektÃ¶rÃ¼ boÅŸ veya boyut uyuÅŸmazlÄ±ÄŸÄ±. Unknown dÃ¶ndÃ¼rÃ¼lÃ¼yor.\n");
        return UserIntent::Unknown;
    }

    UserIntent best_intent_from_crypto = UserIntent::Unknown;
    float max_score_from_crypto = -std::numeric_limits<float>::max(); // BaÅŸlangÄ±Ã§ta Ã§ok dÃ¼ÅŸÃ¼k bir deÄŸer

    for (auto& tmpl : intent_templates) {
        float score = 0.0f;
        // AÄŸÄ±rlÄ±k boyutu latent kriptofig boyutu ile eÅŸleÅŸmeli
        if (tmpl.weights.size() != CryptofigAutoencoder::LATENT_DIM) { 
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "IntentAnalyzer::analyze_intent: Niyet ÅŸablonu aÄŸÄ±rlÄ±k boyutu latent kriptofig boyutuyla uyuÅŸmuyor! Niyet: " << intent_to_string(tmpl.id) << ".\n");
            continue; // Bu ÅŸablonu atla
        }
        for (size_t i = 0; i < tmpl.weights.size(); ++i) {
            score += tmpl.weights[i] * sequence.latent_cryptofig_vector[i]; // latent_cryptofig_vector kullanÄ±lÄ±yor
        }
        
        // --- BaÄŸlamsal Skor Ayarlama MantÄ±ÄŸÄ± (Ã¶nceden vardÄ±) ---
        if (tmpl.id == UserIntent::Editing) {
            if (sequence.avg_keystroke_interval > 1500.0f && sequence.control_key_frequency > 0.2f) {
                score *= 1.5f; 
                LOG_DEFAULT(LogLevel::DEBUG, "IntentAnalyzer: Editing skoru yavaÅŸ yazÄ±m ve kontrol tuÅŸlarÄ± nedeniyle artÄ±rÄ±ldÄ±.\n");
            }
        }

        if (tmpl.id == UserIntent::IdleThinking) {
            if (sequence.avg_keystroke_interval > 5000.0f) { 
                score *= 2.0f; 
                LOG_DEFAULT(LogLevel::DEBUG, "IntentAnalyzer: IdleThinking skoru Ã§ok yavaÅŸ yazÄ±m nedeniyle artÄ±rÄ±ldÄ±.\n");
            }
        }

        if (tmpl.id == UserIntent::Gaming) {
            if (sequence.avg_keystroke_interval > 2000.0f) {
                score *= 0.2f; 
                LOG_DEFAULT(LogLevel::DEBUG, "IntentAnalyzer: Gaming skoru yavaÅŸ yazÄ±m nedeniyle dÃ¼ÅŸÃ¼rÃ¼ldÃ¼.\n");
            }
        }
        // --- BaÄŸlamsal Skor Ayarlama MantÄ±ÄŸÄ± Sonu ---

        if (score > max_score_from_crypto) {
            max_score_from_crypto = score;
            best_intent_from_crypto = tmpl.id;
        }
    }
    
    if (max_score_from_crypto < this->confidence_threshold_for_known_intent) { 
        LOG_DEFAULT(LogLevel::INFO, "IntentAnalyzer: En yÃ¼ksek kriptofig skoru (" << max_score_from_crypto << ") eÅŸik deÄŸerinin (" << this->confidence_threshold_for_known_intent << ") altÄ±nda. Niyet 'Unknown' olarak ayarlandÄ±.\n");
        best_intent_from_crypto = UserIntent::Unknown;
    }

    return best_intent_from_crypto;
}

void IntentAnalyzer::set_confidence_threshold(float threshold) {
    confidence_threshold_for_known_intent = std::min(0.8f, std::max(0.01f, threshold));
}

void IntentAnalyzer::update_template_weights(UserIntent intent_id, const std::vector<float>& new_weights) {
    for (auto& tmpl : intent_templates) {
        if (tmpl.id == intent_id) {
            tmpl.weights = new_weights;
            return;
        }
    }
}

void IntentAnalyzer::update_action_success_score(UserIntent intent_id, AIAction action, float score_change) {
    for (auto& tmpl : intent_templates) {
        if (tmpl.id == intent_id) {
            tmpl.action_success_scores[action] += score_change;
            tmpl.action_success_scores[action] = std::min(10.0f, std::max(-10.0f, tmpl.action_success_scores[action]));
            return;
        }
    }
}

std::vector<float> IntentAnalyzer::get_intent_weights(UserIntent intent_id) const {
    for (const auto& tmpl : intent_templates) {
        if (tmpl.id == intent_id) {
            return tmpl.weights;
        }
    }
    return {}; 
}

void IntentAnalyzer::report_learning_performance(UserIntent intent_id, float implicit_feedback_avg, float explicit_feedback_avg) {
    LOG_DEFAULT(LogLevel::INFO, "[Meta-AI] Niyet: " << intent_to_string(intent_id) << 
               ", Ortuk Performans (Ort): " << implicit_feedback_avg << 
               ", Acik Performans (Ort): " << explicit_feedback_avg << "\n"); 

}

void IntentAnalyzer::save_memory(const std::string& filename) const {
    FILE* fp = fopen(filename.c_str(), "w"); 
    if (!fp) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: AI hafiza dosyasi yazilamadi: " << filename << " (errno: " << errno << ")\n");
        return;
    }

    fprintf(fp, "%zu\n", intent_templates.size());
    for (const auto& tmpl : intent_templates) {
        fprintf(fp, "%d %zu ", static_cast<int>(tmpl.id), tmpl.weights.size());
        for (float w : tmpl.weights) {
            fprintf(fp, "%.8f ", w); 
        }
        fprintf(fp, "%zu ", tmpl.action_success_scores.size());
        for (const auto& pair : tmpl.action_success_scores) {
            fprintf(fp, "%d %.8f ", static_cast<int>(pair.first), pair.second); 
        }
        fprintf(fp, "\n");
    }
    fclose(fp);
    LOG_DEFAULT(LogLevel::INFO, "AI hafizasi kaydedildi: " << filename << "\n");
}

void IntentAnalyzer::load_memory(const std::string& filename) {
    FILE* fp = fopen(filename.c_str(), "r"); 
    if (!fp) {
        LOG_DEFAULT(LogLevel::WARNING, "Uyari: AI hafiza dosyasi bulunamadi, varsayilan sablonlar kullaniliyor: " << filename << " (errno: " << errno << ")\n");
        return;
    }

    intent_templates.clear(); 
    size_t num_templates;
    if (fscanf(fp, "%zu\n", &num_templates) != 1) { 
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: AI hafiza dosyasi formati bozuk veya bos (templates): " << filename << "\n");
        fclose(fp);
        return;
    }

    for (size_t i = 0; i < num_templates; ++i) {
        int intent_id_int;
        if (fscanf(fp, "%d", &intent_id_int) != 1) {
             LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: AI hafiza dosyasi yuklenirken intent_id okunamadi. Satir: " << i << "\n");
             break;
        }
        UserIntent intent_id = static_cast<UserIntent>(intent_id_int);

        size_t num_weights;
        if (fscanf(fp, "%zu", &num_weights) != 1) {
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: AI hafiza dosyasi yuklenirken num_weights okunamadi. Satir: " << i << "\n");
            break;
        }
        std::vector<float> weights(num_weights);
        for (size_t j = 0; j < num_weights; ++j) {
            if (fscanf(fp, "%f", &weights[j]) != 1) {
                LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: AI hafiza dosyasi yuklenirken weight okunamadi. Satir: " << i << ", Eleman: " << j << "\n");
                break;
            }
        }

        size_t num_action_scores;
        if (fscanf(fp, "%zu", &num_action_scores) != 1) {
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: AI hafiza dosyasi yuklenirken num_action_scores okunamadi. Satir: " << i << "\n");
            break;
        }
        std::map<AIAction, float> action_scores;
        for (size_t j = 0; j < num_action_scores; ++j) {
            int action_id_int;
            float score;
            if (fscanf(fp, "%d %f", &action_id_int, &score) != 2) {
                LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: AI hafiza dosyasi yuklenirken action_score okunamadi. Satir: " << i << ", Eleman: " << j << "\n");
                break;
            }
            action_scores[static_cast<AIAction>(action_id_int)] = score;
        }
        
        char newline_char;
        fscanf(fp, "%c", &newline_char); 

        intent_templates.emplace_back(intent_id, weights);
        intent_templates.back().action_success_scores = action_scores;
    }
    fclose(fp);
    LOG_DEFAULT(LogLevel::INFO, "AI hafizasi yuklendi: " << filename << "\n");
} 
--- C:\Users\aib\CerebrumLux\src\brain\intent_analyzer.h --- 
#ifndef CEREBRUM_LUX_INTENT_ANALYZER_H
#define CEREBRUM_LUX_INTENT_ANALYZER_H

#include <vector>  // For std::vector
#include <map>     // For std::map
#include <string>  // For std::string
#include <limits>  // For std::numeric_limits
#include "../core/enums.h"         // Enumlar iÃ§in
#include "../core/utils.h"         // For convert_wstring_to_string (if needed elsewhere)
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in ileri bildirim
#include "intent_template.h"       // IntentTemplate iÃ§in
#include "autoencoder.h"           // CryptofigAutoencoder::LATENT_DIM iÃ§in (sadece boyut iÃ§in)
// #include "../communication/natural_language_processor.h" // KALDIRILDI: NaturalLanguageProcessor iÃ§in baÅŸlÄ±k dosyasÄ± dahil edildi


// Ä°leri bildirimler
struct DynamicSequence;
struct IntentTemplate;
// class NaturalLanguageProcessor; // KALDIRILDI: NaturalLanguageProcessor iÃ§in ileri bildirim

// *** IntentAnalyzer: Kullanici niyetlerini analiz eder ***
class IntentAnalyzer {
public:
    // Kurucu parametresiz hale getirildi
    IntentAnalyzer(); 
    virtual UserIntent analyze_intent(const DynamicSequence& sequence); // Eklendi: virtual
    
    std::vector<IntentTemplate> intent_templates; 

    void update_template_weights(UserIntent intent_id, const std::vector<float>& new_weights); 
    void update_action_success_score(UserIntent intent_id, AIAction action, float score_change); 
    std::vector<float> get_intent_weights(UserIntent intent_id) const; 

    void save_memory(const std::string& filename) const;
    void load_memory(const std::string& filename);

    void report_learning_performance(UserIntent intent_id, float implicit_feedback_avg, float explicit_feedback_avg);

    float confidence_threshold_for_known_intent; 
    void set_confidence_threshold(float threshold); 

private:
    // NaturalLanguageProcessor& nlp; // KALDIRILDI: NaturalLanguageProcessor referansÄ±
};


#endif // CEREBRUM_LUX_INTENT_ANALYZER_H 
--- C:\Users\aib\CerebrumLux\src\brain\intent_learner.cpp --- 
#include "intent_learner.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/utils.h"       // intent_to_string
#include "../core/logger.h"      // LOG makrosu iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in
#include "intent_analyzer.h"     // IntentAnalyzer iÃ§in
#include "../sensors/atomic_signal.h"       // AtomicSignal iÃ§in
#include "../communication/suggestion_engine.h" // SuggestionEngine iÃ§in eklendi
#include "../brain/autoencoder.h" // CryptofigAutoencoder::LATENT_DIM iÃ§in eklendi
#include "../user/user_profile_manager.h" // UserProfileManager iÃ§in eklendi
// #include "../communication/natural_language_processor.h" // KALDIRILDI: NaturalLanguageProcessor iÃ§in eklendi
#include <numeric> // std::accumulate
#include <algorithm> // std::min, std::max
#include <cmath>     // std::abs
#include <iomanip>   // std::fixed, std::setprecision
#include <iostream>  // std::cout, std::cerr
#include <sstream>   // std::stringstream iÃ§in

// === IntentLearner Implementasyonlari ===

// Kurucu gÃ¼ncellendi - NaturalLanguageProcessor referansÄ± kaldÄ±rÄ±ldÄ±
IntentLearner::IntentLearner(IntentAnalyzer& analyzer_ref, SuggestionEngine& suggester_ref, UserProfileManager& user_profile_manager_ref)
    : analyzer(analyzer_ref), suggester(suggester_ref), user_profile_manager(user_profile_manager_ref), learning_rate(0.01f) {}

void IntentLearner::process_feedback(const DynamicSequence& sequence, UserIntent predicted_intent, const std::deque<AtomicSignal>& recent_signals) {
    // KullanÄ±cÄ± profiline niyet geÃ§miÅŸi ekle
    user_profile_manager.add_intent_history_entry(predicted_intent, sequence.last_updated_us);

    // Geri bildirim gÃ¼cÃ¼nÃ¼ hesapla (Ã¶rneÄŸin, tahmin edilen niyetin gÃ¼venine gÃ¶re)
    float feedback_strength = 0.0f; // VarsayÄ±lan olarak sÄ±fÄ±r

    // EÄŸer tahmin edilen niyet Unknown ise ve gÃ¼Ã§lÃ¼ bir potansiyel niyet varsa
    if (predicted_intent == UserIntent::Unknown) {
        UserIntent best_potential_known_intent = UserIntent::Unknown;
        float max_potential_score = -std::numeric_limits<float>::max();

        for (const auto& tmpl : analyzer.intent_templates) {
            if (tmpl.id != UserIntent::Unknown) {
                float score = 0.0f;
                // CryptofigAutoencoder::LATENT_DIM kullanÄ±larak weights boyutu kontrolÃ¼
                if (tmpl.weights.size() != CryptofigAutoencoder::LATENT_DIM) {
                    LOG_DEFAULT(LogLevel::ERR_CRITICAL, "IntentLearner::process_feedback: Niyet ÅŸablonu aÄŸÄ±rlÄ±k boyutu latent kriptofig boyutuyla uyuÅŸmuyor! Niyet: " << intent_to_string(tmpl.id) << ".\n");
                    continue; // Bu ÅŸablonu atla
                }
                for (size_t i = 0; i < tmpl.weights.size(); ++i) {
                    score += tmpl.weights[i] * sequence.latent_cryptofig_vector[i];
                }
                if (score > max_potential_score) {
                    max_potential_score = score;
                    best_potential_known_intent = tmpl.id;
                }
            }
        }

        if (best_potential_known_intent != UserIntent::Unknown && max_potential_score > analyzer.confidence_threshold_for_known_intent) {
            LOG_DEFAULT(LogLevel::INFO, "[AI-Ogrenen] 'Bilinmiyor' olarak tahmin edildi, ancak gÃ¼Ã§lÃ¼ potansiyel niyet '" << intent_to_string(best_potential_known_intent) << "' (geri bildirim: " << feedback_strength << ") bulundu. Bu niyet iÃ§in ayar yapÄ±lÄ±yor.\n");
            // Bu durumda, best_potential_known_intent iÃ§in aÄŸÄ±rlÄ±klarÄ± ayarla
            std::vector<float> current_weights = analyzer.get_intent_weights(best_potential_known_intent);
            if (current_weights.size() != sequence.latent_cryptofig_vector.size()) { // Boyut kontrolÃ¼
                 LOG_DEFAULT(LogLevel::ERR_CRITICAL, "IntentLearner::process_feedback: Current weights boyutu latent cryptofig boyutuyla uyuÅŸmuyor! Ayarlama atlanÄ±yor.\n");
            } else {
                for (size_t i = 0; i < current_weights.size(); ++i) {
                    current_weights[i] += learning_rate * (sequence.latent_cryptofig_vector[i] - current_weights[i]);
                    current_weights[i] = std::min(5.0f, std::max(-5.0f, current_weights[i]));
                }
                analyzer.update_template_weights(best_potential_known_intent, current_weights);
            }
        } else {
            // GerÃ§ekten Unknown ise, Ã¶ÄŸrenme oranÄ±nÄ± dÃ¼ÅŸÃ¼r veya hiÃ§bir ÅŸey yapma
            feedback_strength = 0.0f;
            LOG_DEFAULT(LogLevel::INFO, "[AI-Ogrenen] Niyet 'Bilinmiyor' iÃ§in hesaplanan geri bildirim gucu: " << feedback_strength << ". (Net potansiyel niyet bulunamadÄ±.)\n");
        }
    }
    else {
        // Bilinen bir niyet tahmin edildiyse, bu niyet iÃ§in aÄŸÄ±rlÄ±klarÄ± ayarla
        feedback_strength = 1.0f; // Pozitif geri bildirim
        LOG_DEFAULT(LogLevel::INFO, "[AI-Ogrenen] Niyet '" << intent_to_string(predicted_intent) << "' iÃ§in hesaplanan geri bildirim gucu: " << feedback_strength << "\n");
        std::vector<float> current_weights = analyzer.get_intent_weights(predicted_intent);
        if (current_weights.size() != sequence.latent_cryptofig_vector.size()) { // Boyut kontrolÃ¼
             LOG_DEFAULT(LogLevel::ERR_CRITICAL, "IntentLearner::process_feedback: Current weights boyutu latent cryptofig boyutuyla uyuÅŸmuyor! Ayarlama atlanÄ±yor.\n");
        } else {
            for (size_t i = 0; i < current_weights.size(); ++i) {
                current_weights[i] += learning_rate * (sequence.latent_cryptofig_vector[i] - current_weights[i]);
                current_weights[i] = std::min(5.0f, std::max(-5.0f, current_weights[i]));
            }
            analyzer.update_template_weights(predicted_intent, current_weights);
        }
    }

    // Implicit geri bildirim metriklerini topla ve iÅŸle
    AbstractState current_abstract_state = infer_abstract_state(recent_signals);
    user_profile_manager.add_state_history_entry(current_abstract_state, sequence.last_updated_us); // KullanÄ±cÄ± profiline durum geÃ§miÅŸi ekle
    evaluate_implicit_feedback(predicted_intent, current_abstract_state);
}

void IntentLearner::evaluate_implicit_feedback(UserIntent current_intent, AbstractState current_abstract_state) {
    double implicit_feedback_score = 0.0; // VarsayÄ±lan nÃ¶tr geri bildirim

    // AbstractState'e gÃ¶re genel bir modifikasyon yapÄ±sÄ±
    switch (current_abstract_state) {
        case AbstractState::PowerSaving:
            // Enerji tasarrufu modundayken farklÄ± niyetler nasÄ±l etkilenmeli?
            if (current_intent == UserIntent::Gaming ||
                current_intent == UserIntent::VideoEditing ||
                current_intent == UserIntent::CreativeWork) { // YÃ¼ksek performans gerektiren niyetler
                implicit_feedback_score = -0.5; // GÃ¼Ã§ tasarrufunda kÃ¶tÃ¼ performans -> negatif geri bildirim
                LOG_DEFAULT(LogLevel::INFO, "[AI-Ogrenen] GÃ¼Ã§ Tasarrufu modunda YÃ¼ksek Performans Niyeti algÄ±landÄ±. Negatif dolaylÄ± geri bildirim uygulandÄ±.");
            } else if (current_intent == UserIntent::MediaConsumption) { // Video izleme gibi, duruma gÃ¶re deÄŸiÅŸebilir
                // Daha detaylÄ± kontrol: Ã§Ã¶zÃ¼nÃ¼rlÃ¼k dÃ¼ÅŸÃ¼kse nÃ¶tr, yÃ¼ksekse hafif negatif olabilir.
                // Åžimdilik hafif negatif varsayalÄ±m, kullanÄ±cÄ± deneyimi tam olmayabilir.
                implicit_feedback_score = -0.1;
                LOG_DEFAULT(LogLevel::INFO, "[AI-Ogrenen] GÃ¼Ã§ Tasarrufu modunda Medya TÃ¼ketimi Niyeti algÄ±landÄ±. Hafif negatif dolaylÄ± geri bildirim uygulandÄ±.");
            } else if (current_intent == UserIntent::Browsing ||
                       current_intent == UserIntent::Reading ||
                       current_intent == UserIntent::GeneralInquiry) { // DÃ¼ÅŸÃ¼k gÃ¼Ã§ gerektiren niyetler
                implicit_feedback_score = 0.0; // NÃ¶tr veya hafif pozitif (eÄŸer kullanÄ±cÄ± uzun pil Ã¶mrÃ¼ne deÄŸer veriyorsa)
                LOG_DEFAULT(LogLevel::INFO, "[AI-Ogrenen] GÃ¼Ã§ Tasarrufu modunda DÃ¼ÅŸÃ¼k Performans Niyeti algÄ±landÄ±. NÃ¶tr dolaylÄ± geri bildirim uygulandÄ±.");
            }
            break;

        case AbstractState::HighPerformance:
            // YÃ¼ksek performans modundayken niyetler iÃ§in pozitif geri bildirim
            if (current_intent == UserIntent::Gaming ||
                current_intent == UserIntent::VideoEditing ||
                current_intent == UserIntent::CreativeWork) {
                implicit_feedback_score = 0.3; // YÃ¼ksek performansta iyi deneyim -> pozitif geri bildirim
            }
            break;

        case AbstractState::FaultyHardware: // Ã–rneÄŸin arÄ±zalÄ± donanÄ±m durumu
             if (current_intent != UserIntent::None) { // Herhangi bir niyet iÃ§in genel olarak negatif
                implicit_feedback_score = -0.7; // DonanÄ±m arÄ±zasÄ± tÃ¼m niyetleri olumsuz etkiler
             }
             break;
        // ... DiÄŸer AbstractState'ler ve onlarÄ±n UserIntent'ler Ã¼zerindeki etkileri buraya eklenebilir

        default:
            // VarsayÄ±lan durum: Ã–zel bir durum yoksa geri bildirim nÃ¶tr kalÄ±r veya baÅŸka bir mantÄ±k uygulanÄ±r
            implicit_feedback_score = 0.0;
            break;
    }

    LOG_DEFAULT(LogLevel::DEBUG, "[AI-Ogrenen] Niyet: " << static_cast<int>(current_intent) <<
                         ", Durum: " << static_cast<int>(current_abstract_state) <<
                         ", DolaylÄ± Geri Bildirim PuanÄ±: " << implicit_feedback_score);

    // implicit_feedback_history'yi gÃ¼ncelle
    implicit_feedback_history[current_intent].push_back(implicit_feedback_score);
    if (implicit_feedback_history[current_intent].size() > feedback_history_size) {
        implicit_feedback_history[current_intent].pop_front();
    }
}

AbstractState IntentLearner::infer_abstract_state(const std::deque<AtomicSignal>& recent_signals) {
    // Sinyallerden AbstractState Ã§Ä±karmak iÃ§in basit bir mantÄ±k
    // Daha karmaÅŸÄ±k bir Ã§Ä±karÄ±m mekanizmasÄ± burada geliÅŸtirilebilir.
    // Åžimdilik, en baskÄ±n AbstractState'i belirlemeye Ã§alÄ±ÅŸalÄ±m.

    std::map<AbstractState, float> state_scores;
    state_scores[AbstractState::None] = 0.0f; // VarsayÄ±lan durum

    // Sinyal tÃ¼rlerine gÃ¶re aÄŸÄ±rlÄ±klar (Ã¶rnek deÄŸerler, orijinalden alÄ±nmÄ±ÅŸtÄ±r)
    const float BRIGHTNESS_WEIGHT = 0.1f;
    const float BATTERY_WEIGHT = 0.1f;
    // DiÄŸer sensÃ¶r tipleri iÃ§in de benzer aÄŸÄ±rlÄ±klar eklenebilir

    for (const auto& sig : recent_signals) {
        switch (sig.sensor_type) {
            case SensorType::Display: {
                float brightness = sig.display_brightness;
                if (brightness < 0.3f) {
                    state_scores[AbstractState::PowerSaving] += BRIGHTNESS_WEIGHT * 0.5f;
                }
                // YÃ¼ksek parlaklÄ±k iÃ§in HighPerformance durumu da eklenebilir
                else if (brightness > 0.8f) {
                    state_scores[AbstractState::HighPerformance] += BRIGHTNESS_WEIGHT * 0.3f;
                }
                break;
            }
            case SensorType::Battery: {
                float change = sig.battery_percentage;
                if (change < -0.05f) { // %5'ten fazla dÃ¼ÅŸÃ¼ÅŸ
                    state_scores[AbstractState::FaultyHardware] += BATTERY_WEIGHT * 0.7f;
                }
                break;
            }
            // DiÄŸer sensÃ¶r tipleri iÃ§in AbstractState Ã§Ä±karÄ±m mantÄ±ÄŸÄ± buraya eklenebilir
            // Ã–rneÄŸin:
            // case SensorType::Temperature: {
            //     float temp = sig.value;
            //     if (temp > 80) { // Cihaz Ã§ok sÄ±cak
            //         state_scores[AbstractState::FaultyHardware] += 0.1f;
            //     }
            //     break;
            // }
            // case SensorType::AmbientLight: {
            //     float light = sig.value;
            //     if (light < 50) { // KaranlÄ±k ortam
            //         state_scores[AbstractState::PowerSaving] += 0.05f;
            //     }
            //     break;
            // }
            // case SensorType::HeartRate: {
            //     float hr = sig.value;
            //     if (hr > 100) { // YÃ¼ksek kalp atÄ±ÅŸ hÄ±zÄ±
            //         state_scores[AbstractState::Distracted] += 0.05f; // Stres
            //     }
            //     break;
            // }
            default:
                break;
        }
    }

    // En yÃ¼ksek puana sahip AbstractState'i bul
    AbstractState inferred_state = AbstractState::None;
    float max_score = 0.0f;

    for (const auto& pair : state_scores) {
        if (pair.second > max_score) {
            max_score = pair.second;
            inferred_state = pair.first;
        }
    }

    LOG_DEFAULT(LogLevel::DEBUG, "[AI-Ogrenen] Sinyallerden Ã§Ä±karÄ±lan AbstractState: " << static_cast<int>(inferred_state) << " (Puan: " << max_score << ")");
    return inferred_state;
}

void IntentLearner::adjust_learning_rate(float rate) {
    learning_rate = std::min(0.1f, std::max(0.001f, rate)); // Ã–ÄŸrenme oranÄ±nÄ± belirli sÄ±nÄ±rlar iÃ§inde tut
}

void IntentLearner::process_explicit_feedback(UserIntent predicted_intent, AIAction action, bool approved, const DynamicSequence& sequence, AbstractState current_abstract_state) {
    float reward = approved ? 1.0f : -1.0f; // OnaylandÄ±ysa pozitif, reddedildiyse negatif Ã¶dÃ¼l

    // current_state iÃ§in StateKey oluÅŸtur
    StateKey state_key = {predicted_intent, current_abstract_state};

    // SuggestionEngine'Ä±n Q-deÄŸerini gÃ¼ncelle
    suggester.update_q_value(state_key, action, reward);

    // KullanÄ±cÄ± profiline aÃ§Ä±k geri bildirimi kaydet
    // UserProfileManager'da bir metod (Ã¶rn. add_explicit_action_feedback) ekleyebiliriz.
    // Åžimdilik, sadece IntentLearner'Ä±n kendi explicit_feedback_history'sini gÃ¼ncelleyelim.
    explicit_feedback_history[predicted_intent].push_back(reward); 
    if (explicit_feedback_history[predicted_intent].size() > feedback_history_size) {
        explicit_feedback_history[predicted_intent].pop_front();
    }

    if (approved) {
        LOG_DEFAULT(LogLevel::INFO, "[AI-Ogrenen] KullanÄ±cÄ±dan aÃ§Ä±k geri bildirim: Niyet '" << intent_to_string(predicted_intent) <<
                             "', Eylem '" << static_cast<int>(action) << "' ONAYLANDI. Ã–ÄŸrenme gÃ¼Ã§lendiriliyor.");
    } else {
        LOG_DEFAULT(LogLevel::INFO, "[AI-Ogrenen] KullanÄ±cÄ±dan aÃ§Ä±k geri bildirim: Niyet '" << intent_to_string(predicted_intent) <<
                             "', Eylem '" << static_cast<int>(action) << "' REDDEDÄ°LDÄ°. Ã–ÄŸrenme zayÄ±flatÄ±lÄ±yor.");
    }

}


// --- EK METOTLAR (BoÅŸ bÄ±rakÄ±ldÄ± veya daha sonra geliÅŸtirilecek) ---

void IntentLearner::processMessages() {
    // Mesaj kuyruÄŸunu iÅŸleme mantÄ±ÄŸÄ± buraya gelecek
}

void IntentLearner::update_action_success_score(UserIntent intent, AIAction next_action, float success_score) {
    // Eylem baÅŸarÄ± puanÄ±nÄ± gÃ¼ncelleme mantÄ±ÄŸÄ± buraya gelecek
}

void IntentLearner::self_adjust_learning_rate(float adjustment_factor) {
    // Ã–ÄŸrenme oranÄ±nÄ± otomatik ayarlama mantÄ±ÄŸÄ± buraya gelecek
}

void IntentLearner::evaluate_and_meta_adjust() {
    // Meta ayarlama mantÄ±ÄŸÄ± buraya gelecek
}

void IntentLearner::adjust_template(UserIntent intent_id, const DynamicSequence& sequence, float feedback_strength) {
    // Niyet ÅŸablonlarÄ±nÄ± ayarlama mantÄ±ÄŸÄ± buraya gelecek
}

void IntentLearner::adjust_action_score(UserIntent intent_id, AIAction action, float score_change) {
    // Eylem skorlarÄ±nÄ± ayarlama mantÄ±ÄŸÄ± buraya gelecek
} 
--- C:\Users\aib\CerebrumLux\src\brain\intent_learner.h --- 
#ifndef CEREBRUM_LUX_INTENT_LEARNER_H
#define CEREBRUM_LUX_INTENT_LEARNER_H

#include <deque>   // For std::deque
#include <map>     // For std::map
#include <vector>  // For std::vector
#include "../core/enums.h"         // Enumlar iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in ileri bildirim
#include "../sensors/atomic_signal.h" // AtomicSignal iÃ§in (evaluate_implicit_feedback iÃ§inde kullanÄ±lÄ±r)
#include "intent_analyzer.h"       // IntentAnalyzer iÃ§in ileri bildirim
#include "../core/utils.h"
#include "../communication/suggestion_engine.h" // SuggestionEngine iÃ§in eklendi
#include "../user/user_profile_manager.h" // UserProfileManager iÃ§in eklendi

// Ä°leri bildirimler
struct DynamicSequence;
class IntentAnalyzer;
class SuggestionEngine;
class UserProfileManager; // UserProfileManager iÃ§in ileri bildirim eklendi

// *** IntentLearner: Geri bildirim yoluyla niyet tahminlerini gelistirir ***
class IntentLearner {
public:
    // Kurucuya SuggestionEngine ve UserProfileManager referanslarÄ± eklendi
    IntentLearner(IntentAnalyzer& analyzer_ref, SuggestionEngine& suggester_ref, UserProfileManager& user_profile_manager_ref); 
    
    //mesaj kuyruÄŸunu
    void adjust_learning_rate(float new_learning_rate);
    void processMessages();
    void update_action_success_score(UserIntent intent, AIAction next_action, float success_score);


    void process_feedback(const DynamicSequence& sequence, UserIntent predicted_intent, 
                          const std::deque<AtomicSignal>& recent_signals);

    // current_abstract_state parametresi eklendi
    virtual void process_explicit_feedback(UserIntent predicted_intent, AIAction action, bool approved, const DynamicSequence& sequence, AbstractState current_abstract_state);

    void self_adjust_learning_rate(float adjustment_factor);

    float get_learning_rate() const { return learning_rate; }

    const std::map<UserIntent, std::deque<float>>& get_implicit_feedback_history() const { 
        return implicit_feedback_history; 
    }

    bool get_implicit_feedback_for_intent(UserIntent intent_id, std::deque<float>& history_out) const {
        auto it = implicit_feedback_history.find(intent_id);
        if (it != implicit_feedback_history.end()) {
            history_out = it->second;
            return true;
        }
        return false;
    }
    size_t get_feedback_history_size() const { return feedback_history_size; } // Getter metodu

    float get_desired_other_signals_multiplier() const { return desired_other_signals_multiplier; }

    virtual AbstractState infer_abstract_state(const std::deque<AtomicSignal>& recent_signals); // Buraya 'virtual' ekleyin
    
private:
    IntentAnalyzer& analyzer; 
    SuggestionEngine& suggester; 
    UserProfileManager& user_profile_manager; // YENÄ°: UserProfileManager referansÄ± eklendi

    float learning_rate = 0.1f; // VarsayÄ±lan Ã¶ÄŸrenme oranÄ±
    //mesaj iÅŸleme metodu
    MessageQueue messageQueue;

    void evaluate_implicit_feedback(UserIntent current_intent, AbstractState current_abstract_state);
    void adjust_template(UserIntent intent_id, const DynamicSequence& sequence, float feedback_strength);
    void adjust_action_score(UserIntent intent_id, AIAction action, float score_change); 
    
    std::map<UserIntent, std::deque<float>> implicit_feedback_history;
    std::map<UserIntent, std::deque<float>> explicit_feedback_history;
    size_t feedback_history_size = 10; 

    void evaluate_and_meta_adjust();

    std::map<SensorType, float> sensor_performance_contribution; 
    std::map<SensorType, int> sensor_feedback_count; 
    
    float desired_other_signals_multiplier = 1.0f; 

};

#endif // CEREBRUM_LUX_INTENT_LEARNER_H 
--- C:\Users\aib\CerebrumLux\src\brain\intent_template.cpp --- 
#include "intent_template.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/enums.h"   // AIAction ve UserIntent enum'larÄ± iÃ§in
 
--- C:\Users\aib\CerebrumLux\src\brain\intent_template.h --- 
#ifndef CEREBRUM_LUX_INTENT_TEMPLATE_H
#define CEREBRUM_LUX_INTENT_TEMPLATE_H

#include <vector>  // For std::vector
#include <map>     // For std::map
#include <string>  // For std::string
#include "../core/enums.h" // UserIntent, AIAction enum'larÄ± iÃ§in
#include "../core/utils.h" // For convert_wstring_to_string (if needed elsewhere)

// Ä°leri bildirim: EÄŸer IntentTemplate iÃ§inde CryptofigAutoencoder'dan bir boyut kullanÄ±lÄ±yorsa, burada bildirilebilir.
// Ancak IntentTemplate'Ä±n kendisi CryptofigAutoencoder'Ä± doÄŸrudan kullanmadÄ±ÄŸÄ± iÃ§in ÅŸimdilik gerek yok.

// *** IntentTemplate: Dinamik niyet sablonlarini temsil eden yapi ***
struct IntentTemplate { 
    UserIntent id;
    std::vector<float> weights; // Bu aÄŸÄ±rlÄ±klar artÄ±k latent_cryptofig_vector boyutunda olacak
    std::map<AIAction, float> action_success_scores; 
    
    IntentTemplate(UserIntent intent_id, const std::vector<float>& initial_weights); 
};

#endif // CEREBRUM_LUX_INTENT_TEMPLATE_H 
--- C:\Users\aib\CerebrumLux\src\brain\prediction_engine.cpp --- 
#include "prediction_engine.h"
#include "../core/logger.h"
#include "../core/utils.h" // intent_to_string iÃ§in
#include "../data_models/dynamic_sequence.h"
#include "../data_models/sequence_manager.h"
#include "intent_analyzer.h"
#include "autoencoder.h"
#include <numeric>
#include <cmath>
#include <algorithm>
#include <fstream>
#include <iostream> // std::cout, std::cerr iÃ§in
#include <iomanip>
#include <sstream>   // std::stringstream iÃ§in

StateNode::StateNode(UserIntent i) : intent(i) {}

StateEdge::StateEdge(UserIntent from, UserIntent to)
    : from_intent(from), to_intent(to), transition_probability(0.0f),
      last_observed_us(0), observation_count(0) {}

PredictionEngine::PredictionEngine(IntentAnalyzer& analyzer_ref, SequenceManager& manager_ref)
    : analyzer(analyzer_ref), manager(manager_ref) {
    initialize_state_graph();
}

void PredictionEngine::initialize_state_graph() {
    for (int i = static_cast<int>(UserIntent::None); i < static_cast<int>(UserIntent::Count); ++i) {
        state_nodes.emplace_back(static_cast<UserIntent>(i));
    }
}

StateEdge* PredictionEngine::find_or_create_edge(UserIntent from_intent, UserIntent to_intent) {
    for (auto& edge : state_edges) {
        if (edge.from_intent == from_intent && edge.to_intent == to_intent) {
            return &edge;
        }
    }
    state_edges.emplace_back(from_intent, to_intent);
    return &state_edges.back();
}

void PredictionEngine::update_state_graph(UserIntent previous_intent, UserIntent current_intent, const DynamicSequence& sequence) {
    if (previous_intent == UserIntent::Unknown || current_intent == UserIntent::Unknown ||
        previous_intent == UserIntent::None || current_intent == UserIntent::None) {
        return;
    }

    StateEdge* edge = find_or_create_edge(previous_intent, current_intent);
    if (edge) {
        if (edge->observation_count == 0) {
            edge->transition_cryptofig_delta = sequence.latent_cryptofig_vector;
        } else {
            for (size_t i = 0; i < sequence.latent_cryptofig_vector.size(); ++i) {
                edge->transition_cryptofig_delta[i] =
                    (edge->transition_cryptofig_delta[i] * edge->observation_count + sequence.latent_cryptofig_vector[i]) / (edge->observation_count + 1);
            }
        }
        edge->observation_count++;
        edge->last_observed_us = sequence.last_updated_us;
    }

    StateNode* from_node = nullptr;
    for (auto& node : state_nodes) {
        if (node.intent == previous_intent) {
            from_node = &node;
            break;
        }
    }
    if (!from_node) {
        state_nodes.emplace_back(previous_intent);
        from_node = &state_nodes.back();
    }

    if (from_node) {
        from_node->total_outgoing_transitions++;
        for (auto& e : state_edges) {
            if (e.from_intent == previous_intent) {
                if (from_node->total_outgoing_transitions > 0) {
                    e.transition_probability = static_cast<float>(e.observation_count) / from_node->total_outgoing_transitions;
                } else {
                    e.transition_probability = 0.0f;
                }
            }
        }
    }
}

float PredictionEngine::calculate_euclidean_distance(const std::vector<float>& vec1, const std::vector<float>& vec2) const {
    if (vec1.empty() || vec2.empty() || vec1.size() != vec2.size()) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "calculate_euclidean_distance: Boyut uyuÅŸmazlÄ±ÄŸÄ± veya boÅŸ vektÃ¶rler. GeÃ§ersiz mesafe dÃ¶ndÃ¼rÃ¼lÃ¼yor.");
        return std::numeric_limits<float>::max();
    }
    float sum_sq_diff = 0.0f;
    for (size_t i = 0; i < vec1.size(); ++i) {
        sum_sq_diff += (vec1[i] - vec2[i]) * (vec1[i] - vec2[i]);
    }
    return std::sqrt(sum_sq_diff);
}

UserIntent PredictionEngine::predict_next_intent(UserIntent previous_intent, const DynamicSequence& current_sequence) const {
    UserIntent current_analyzed_intent = analyzer.analyze_intent(current_sequence);

    if (current_analyzed_intent == UserIntent::Unknown || previous_intent == UserIntent::Unknown ||
        current_analyzed_intent == UserIntent::None || previous_intent == UserIntent::None) {
        LOG_DEFAULT(LogLevel::DEBUG, "predict_next_intent: Current veya Previous intent bilinmiyor/hiÃ§biri, doÄŸrudan analiz dÃ¶ndÃ¼rÃ¼lÃ¼yor.\n");
        return current_analyzed_intent;
    }

    UserIntent most_probable_future_intent = current_analyzed_intent;
    float max_combined_score = -1.0f;

    const float CRYPTOFIG_SIMILARITY_SCALE = 0.5f;

    for (const auto& edge : state_edges) {
        if (edge.from_intent == current_analyzed_intent) {
            float combined_score = edge.transition_probability;

            if (!edge.transition_cryptofig_delta.empty() && edge.transition_cryptofig_delta.size() == current_sequence.latent_cryptofig_vector.size()) {
                float distance = calculate_euclidean_distance(current_sequence.latent_cryptofig_vector, edge.transition_cryptofig_delta);
                float cryptofig_similarity = std::exp(-distance / CRYPTOFIG_SIMILARITY_SCALE);

                float W1 = 0.7f;
                float W2 = 0.3f;

                combined_score = (edge.transition_probability * W1) + (cryptofig_similarity * W2);

                LOG_DEFAULT(LogLevel::TRACE, "Edge: " << intent_to_string(edge.from_intent) << " -> " << intent_to_string(edge.to_intent) <<
                           ", Prob: " << edge.transition_probability <<
                           ", Mesafe: " << distance <<
                           ", Benzerlik: " << cryptofig_similarity <<
                           ", BirleÅŸik Skor: " << combined_score);
            } else {
                 LOG_DEFAULT(LogLevel::WARNING, "predict_next_intent: Kriptofig delta boÅŸ veya boyut uyuÅŸmazlÄ±ÄŸÄ±. Sadece geÃ§iÅŸ olasÄ±lÄ±ÄŸÄ± kullanÄ±lÄ±yor.");
            }

            if (combined_score > max_combined_score) {
                max_combined_score = combined_score;
                most_probable_future_intent = edge.to_intent;
            }
        }
    }

    LOG_DEFAULT(LogLevel::DEBUG, "predict_next_intent: En yÃ¼ksek birleÅŸik skor: " << max_combined_score);

    if (max_combined_score < 0.25f) { 
        LOG_DEFAULT(LogLevel::DEBUG, "predict_next_intent: BirleÅŸik skor eÅŸiÄŸin altÄ±nda (" << max_combined_score << " < 0.2500), mevcut analiz dÃ¶ndÃ¼rÃ¼lÃ¼yor: " << intent_to_string(current_analyzed_intent));
        return current_analyzed_intent;
    }

    LOG_DEFAULT(LogLevel::DEBUG, "predict_next_intent: En olasÄ± gelecek niyet: " << intent_to_string(most_probable_future_intent));

    return most_probable_future_intent;
}

float PredictionEngine::query_intent_probability(UserIntent target_intent, const DynamicSequence& current_sequence) const {
    if (analyzer.analyze_intent(current_sequence) == target_intent) {
        return 0.7f;
    }
    return 0.3f;
}
void PredictionEngine::learn_time_patterns(const std::deque<AtomicSignal>& signal_buffer, UserIntent current_intent) {
    (void)signal_buffer;
    (void)current_intent;
}

void PredictionEngine::save_state_graph(const std::string& filename) const {
    FILE* fp = fopen(filename.c_str(), "w");
    if (!fp) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi dosyasi yazilamadi: " << filename << " (errno: " << errno << ")");
        return;
    }

    fprintf(fp, "%zu\n", state_nodes.size());
    for (const auto& node : state_nodes) {
        fprintf(fp, "%d %zu ", static_cast<int>(node.intent), node.dominant_cryptofig.size());
        for (float f : node.dominant_cryptofig) {
            fprintf(fp, "%.8f ", f);
        }
        fprintf(fp, "%d\n", node.total_outgoing_transitions);
    }

    fprintf(fp, "%zu\n", state_edges.size());
    for (const auto& edge : state_edges) {
        fprintf(fp, "%d %d %zu ", static_cast<int>(edge.from_intent), static_cast<int>(edge.to_intent), edge.transition_cryptofig_delta.size());
        for (float f : edge.transition_cryptofig_delta) {
            fprintf(fp, "%.8f ", f);
        }
        fprintf(fp, "%.8f %lld %d\n", edge.transition_probability, edge.last_observed_us, edge.observation_count);
    }
    fclose(fp);
    LOG_DEFAULT(LogLevel::INFO, "Durum grafigi kaydedildi: " << filename);
}

void PredictionEngine::load_state_graph(const std::string& filename) {
    FILE* fp = fopen(filename.c_str(), "r");
    if (!fp) {
        LOG_DEFAULT(LogLevel::WARNING, "Uyari: Durum grafigi dosyasi bulunamadi, bos grafik kullaniliyor: " << filename << " (errno: " << errno << ")");
        return;
    }

    state_nodes.clear();
    state_edges.clear();

    size_t num_nodes;
    if (fscanf(fp, "%zu\n", &num_nodes) != 1) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi dosyasi formati bozuk veya bos (nodes): " << filename);
        fclose(fp);
        return;
    }
    for (size_t i = 0; i < num_nodes; ++i) {
        int intent_id_int;
        if (fscanf(fp, "%d", &intent_id_int) != 1) { 
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi yuklenirken intent_id okunamadi. Satir: " << i << "\n");
            break; 
        }
        UserIntent intent = static_cast<UserIntent>(intent_id_int);

        size_t num_cryptofig_elements;
        if (fscanf(fp, "%zu", &num_cryptofig_elements) != 1) { 
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi yuklenirken num_cryptofig_elements okunamadi. Satir: " << i << "\n");
            break; 
        }
        std::vector<float> cryptofig(num_cryptofig_elements);
        for (size_t j = 0; j < num_cryptofig_elements; ++j) {
            if (fscanf(fp, "%f", &cryptofig[j]) != 1) { 
                LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi yuklenirken cryptofig elemanÄ± okunamadi. Satir: " << i << ", Eleman: " << j << "\n");
                break; 
            }
        }

        int total_outgoing_trans; 
        if (fscanf(fp, "%d", &total_outgoing_trans) != 1) {
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi yuklenirken total_outgoing_transitions okunamadi. Satir: " << i << "\n");
            break;
        }
        char newline_char_node;
        fscanf(fp, "%c", &newline_char_node); 

        StateNode node_temp(intent);
        node_temp.dominant_cryptofig = cryptofig;
        node_temp.total_outgoing_transitions = total_outgoing_trans;
        state_nodes.push_back(node_temp); 
    }

    size_t num_edges;
    if (fscanf(fp, "%zu\n", &num_edges) != 1) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi dosyasi formati bozuk veya bos (edges): " << filename);
        fclose(fp);
        return;
    }
    for (size_t i = 0; i < num_edges; ++i) {
        int from_intent_int, to_intent_int;
        if (fscanf(fp, "%d %d", &from_intent_int, &to_intent_int) != 2) { 
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi yuklenirken from_intent/to_intent okunamadi. Satir: " << i << "\n");
            break; 
        }
        UserIntent from_intent = static_cast<UserIntent>(from_intent_int);
        UserIntent to_intent = static_cast<UserIntent>(to_intent_int);

        size_t num_delta_elements;
        if (fscanf(fp, "%zu", &num_delta_elements) != 1) { 
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi yuklenirken num_delta_elements okunamadi. Satir: " << i << "\n");
            break; 
        }
        std::vector<float> delta(num_delta_elements);
        for (size_t j = 0; j < num_delta_elements; ++j) {
            if (fscanf(fp, "%f", &delta[j]) != 1) { 
                LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi yuklenirken delta elemanÄ± okunamadi. Satir: " << i << ", Eleman: " << j << "\n");
                break; 
            }
        }

        float prob;
        long long last_obs_us;
        int obs_count;
        if (fscanf(fp, "%f %lld %d", &prob, &last_obs_us, &obs_count) != 3) {
            LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: Durum grafigi yuklenirken edge verileri okunamadi. Satir: " << i << "\n");
            break; 
        } 
        char newline_char_edge;
        fscanf(fp, "%c", &newline_char_edge); 
        
        state_edges.emplace_back(from_intent, to_intent);
        state_edges.back().transition_cryptofig_delta = delta;
        state_edges.back().transition_probability = prob;
        state_edges.back().last_observed_us = last_obs_us;
        state_edges.back().observation_count = obs_count;
    }
    fclose(fp);
    LOG_DEFAULT(LogLevel::INFO, "Durum grafigi yuklendi: " << filename << "\n");
}
 
--- C:\Users\aib\CerebrumLux\src\brain\prediction_engine.h --- 
#ifndef CEREBRUM_LUX_PREDICTION_ENGINE_H
#define CEREBRUM_LUX_PREDICTION_ENGINE_H

#include <vector>  // For std::vector
#include <deque>   // For std::deque
#include <string>  // For std::string
#include <limits>  // For std::numeric_limits
#include <cmath>   // For std::exp
#include "../core/enums.h"         // Enumlar iÃ§in
#include "../core/utils.h"         // intent_to_string iÃ§in (LOG iÃ§inde kullanÄ±lÄ±r)
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in ileri bildirim
#include "intent_analyzer.h"       // IntentAnalyzer iÃ§in ileri bildirim
#include "autoencoder.h"           // CryptofigAutoencoder::LATENT_DIM iÃ§in (sadece boyut iÃ§in)

// Ä°leri bildirimler
struct DynamicSequence;
class IntentAnalyzer;
class SequenceManager; // PredictionEngine'Ä±n constructor'Ä±nda kullanÄ±ldÄ±ÄŸÄ± iÃ§in

// *** StateNode: Evrimsel Durum Grafigi iÃ§in dugum yapisi ***
struct StateNode {
    UserIntent intent;
    std::vector<float> dominant_cryptofig; // latent_cryptofig_vector boyutunda olacak
    int total_outgoing_transitions = 0; 

    StateNode(UserIntent i); // Constructor bildirimi
};


// *** StateEdge: Evrimsel Durum Grafigi iÃ§in kenar yapisi ***
struct StateEdge {
    UserIntent from_intent;
    UserIntent to_intent;
    std::vector<float> transition_cryptofig_delta; // latent_cryptofig_vector boyutunda olacak
    float transition_probability; 
    long long last_observed_us; 
    int observation_count; 

    StateEdge(UserIntent from, UserIntent to); // Constructor bildirimi
};


// *** PredictionEngine: Tahminci zeka iÃ§in durum grafigini kullanir ***
class PredictionEngine { 
public:
    PredictionEngine(IntentAnalyzer& analyzer_ref, SequenceManager& manager_ref);

    virtual UserIntent predict_next_intent(UserIntent previous_intent, const DynamicSequence& current_sequence) const; // latent_cryptofig_vector kullanacak

    void update_state_graph(UserIntent previous_intent, UserIntent current_intent, const DynamicSequence& sequence); // latent_cryptofig_vector kullanacak
    
    void save_state_graph(const std::string& filename) const;
    void load_state_graph(const std::string& filename);

    float query_intent_probability(UserIntent target_intent, const DynamicSequence& current_sequence) const;
    void learn_time_patterns(const std::deque<AtomicSignal>& signal_buffer, UserIntent current_intent);

private:
    IntentAnalyzer& analyzer;
    SequenceManager& manager; 

    std::vector<StateNode> state_nodes; 
    std::vector<StateEdge> state_edges; 

    void initialize_state_graph(); 
    StateEdge* find_or_create_edge(UserIntent from_intent, UserIntent to_intent); 

    float calculate_euclidean_distance(const std::vector<float>& vec1, const std::vector<float>& vec2) const;
};

#endif // CEREBRUM_LUX_PREDICTION_ENGINE_H 
--- C:\Users\aib\CerebrumLux\src\communication\ai_insights_engine.cpp --- 
#include "ai_insights_engine.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/logger.h"      // LOG makrosu iÃ§in
#include "../core/utils.h"       // DiÄŸer yardÄ±mcÄ± fonksiyonlar iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in
#include "../brain/intent_analyzer.h" // IntentAnalyzer iÃ§in
#include "../brain/intent_learner.h"  // IntentLearner iÃ§in
#include "../brain/prediction_engine.h" // PredictionEngine iÃ§in
#include "../brain/autoencoder.h"     // CryptofigAutoencoder iÃ§in
#include "../brain/cryptofig_processor.h" // CryptofigProcessor iÃ§in
#include <numeric>   // std::accumulate iÃ§in
#include <cmath>     // std::sqrt iÃ§in
#include <algorithm> // std::min/max iÃ§in
#include <iostream>  // std::cout, std::cerr iÃ§in
#include <iomanip>   // std::fixed, std::setprecision iÃ§in
#include <sstream>   // std::stringstream iÃ§in


// YENÄ°: AIInsightsEngine Implementasyonu
AIInsightsEngine::AIInsightsEngine(IntentAnalyzer& analyzer_ref, IntentLearner& learner_ref, 
                                 PredictionEngine& predictor_ref, CryptofigAutoencoder& autoencoder_ref,
                                 CryptofigProcessor& cryptofig_processor_ref)
    : analyzer(analyzer_ref), learner(learner_ref), predictor(predictor_ref), 
      autoencoder(autoencoder_ref), cryptofig_processor(cryptofig_processor_ref) {}

std::string AIInsightsEngine::generateResponse(UserIntent intent, const std::vector<float>& latent_cryptofig_vector) {
    // ... (Implementasyon)
    return "Response"; // Ã–rnek bir yanÄ±t
}

float AIInsightsEngine::calculate_average_feedback_score(UserIntent intent_id) const {
    auto it = learner.get_implicit_feedback_history().find(intent_id);
    if (it != learner.get_implicit_feedback_history().end() && !it->second.empty()) {
        return std::accumulate(it->second.begin(), it->second.end(), 0.0f) / it->second.size();
    }
    return 0.0f;
}

float AIInsightsEngine::calculate_autoencoder_reconstruction_error(const std::vector<float>& statistical_features) const {
    if (statistical_features.empty() || statistical_features.size() != CryptofigAutoencoder::INPUT_DIM) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "AIInsightsEngine::calculate_autoencoder_reconstruction_error: Istatistiksel ozellik vektoru bos veya boyut uyuÅŸmuyor. Yuksek hata donduruluyor.\n");
        return 1.0f; // Hata durumunda yÃ¼ksek hata dÃ¶ndÃ¼r
    }
    std::vector<float> reconstructed = autoencoder.reconstruct(statistical_features);
    float error = 0.0f;
    for (size_t i = 0; i < statistical_features.size(); ++i) {
        error += (statistical_features[i] - reconstructed[i]) * (statistical_features[i] - reconstructed[i]);
    }
    return std::sqrt(error / statistical_features.size()); // RMSE
}

// IntentAnalyzer Ã¼yesine eriÅŸim iÃ§in getter metodunun implementasyonu
IntentAnalyzer& AIInsightsEngine::get_analyzer() const {
    return analyzer;
}


std::vector<AIInsight> AIInsightsEngine::generate_insights(const DynamicSequence& current_sequence) {
    LOG_DEFAULT(LogLevel::DEBUG, "AIInsightsEngine::generate_insights: Icgoru uretimi basladi.\n");
    std::vector<AIInsight> insights;
    auto now = std::chrono::steady_clock::now();

    auto is_on_cooldown = [&](const std::string& key, int seconds) -> bool {
        auto it = insight_cooldowns.find(key);
        if (it != insight_cooldowns.end()) {
            auto time_since_last = std::chrono::duration_cast<std::chrono::seconds>(now - it->second).count();
            if (time_since_last < seconds) {
                return true;
            }
        }
        return false;
    };

    // 1. Niyet AnalizÃ¶rÃ¼ PerformansÄ± HakkÄ±nda Ä°Ã§gÃ¶rÃ¼ler
    if (current_sequence.latent_cryptofig_vector.empty() || current_sequence.latent_cryptofig_vector.size() != CryptofigAutoencoder::LATENT_DIM) {
        if (!is_on_cooldown("latent_data_missing", 300)) {
            // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
            insights.push_back({"Latent kriptofig verisi eksik veya gecersiz. Niyetleri dogru analiz edemeyebilirim.", AIAction::SuggestSelfImprovement, 1.0f});
            insight_cooldowns["latent_data_missing"] = now;
        }
    } else {
        UserIntent current_predicted_intent = analyzer.analyze_intent(current_sequence);
        if (current_predicted_intent == UserIntent::Unknown) {
            if (!is_on_cooldown("unknown_intent_struggle", 120)) {
                // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
                insights.push_back({"Su anki niyetinizi tam olarak algilamakta zorlaniyorum. Yeni ogrenme firsatlarina ihtiyacim var.", AIAction::SuggestSelfImprovement, 0.8f});
                insight_cooldowns["unknown_intent_struggle"] = now;
            }
        }
        
        float fast_typing_feedback = calculate_average_feedback_score(UserIntent::FastTyping);
        if (fast_typing_feedback < -0.2f && learner.get_implicit_feedback_history().count(UserIntent::FastTyping) && learner.get_implicit_feedback_history().at(UserIntent::FastTyping).size() > learner.get_feedback_history_size() / 2) { 
            if (!is_on_cooldown("low_fast_typing_feedback", 180)) {
                // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
                insights.push_back({"Hizli yazim modunda kullanici geri bildirimlerim dusuk seyrediyor. Bu niyet icin sablon agirliklarimi gozden gecirmeliyim.", AIAction::SuggestSelfImprovement, 0.7f});
                insight_cooldowns["low_fast_typing_feedback"] = now;
            }
        }
    }

    // 2. Autoencoder PerformansÄ± HakkÄ±nda Ä°Ã§gÃ¶rÃ¼ler
    if (!current_sequence.statistical_features_vector.empty()) {
        float reconstruction_error = calculate_autoencoder_reconstruction_error(current_sequence.statistical_features_vector);
        if (reconstruction_error > 0.3f) { 
            if (!is_on_cooldown("high_reconstruction_error", 60)) {
                // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
                insights.push_back({"Kriptofig analizim, mevcut sensor verisindeki bazi desenleri tam olarak ogrenemiyor. Autoencoder'in agirliklarini daha agresif ayarlamaliyim.", AIAction::SuggestSelfImprovement, 0.9f});
                insight_cooldowns["high_reconstruction_error"] = now;
            }
        } else if (reconstruction_error < 0.05f) { 
            if (!is_on_cooldown("low_reconstruction_error", 300)) {
                // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
                insights.push_back({"Autoencoder'im veriyi cok iyi yeniden yapilandiriyor. Belki latent uzayi daha da kucultebilirim? Bu, verimliligi artirabilir.", AIAction::SuggestSelfImprovement, 0.2f});
                insight_cooldowns["low_reconstruction_error"] = now;
            }
        }
    } else {
        if (!is_on_cooldown("no_stats_vector", 300)) {
             // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
             insights.push_back({"Istatistiksel ozellik vektoru bos, Autoencoder performansi hakkinda yorum yapamiyorum.", AIAction::None, 0.0f});
             insight_cooldowns["no_stats_vector"] = now;
        }
    }

    // 3. Genel Ã–ÄŸrenme MekanizmasÄ± HakkÄ±nda Ä°Ã§gÃ¶rÃ¼ler (Meta-Ayarlama)
    if (learner.get_learning_rate() > 0.05f && learner.get_implicit_feedback_history().size() > learner.get_feedback_history_size() / 2) { 
        if (!is_on_cooldown("high_learning_rate", 180)) {
            // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
            insights.push_back({"Ogrenme hizim su anda yuksek. Performansim stabil kalirsa biraz dusurmeye dusunebilirim.", AIAction::SuggestSelfImprovement, 0.3f});
            insight_cooldowns["high_learning_rate"] = now;
        }
    } else if (learner.get_learning_rate() < 0.005f && learner.get_implicit_feedback_history().size() > learner.get_feedback_history_size() / 2 && calculate_average_feedback_score(UserIntent::Unknown) < -0.5f) { 
        if (!is_on_cooldown("low_learning_rate_stuck", 120)) {
            // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
            insights.push_back({"Niyet algilamamda sorun yasiyorum ve ogrenme hizim dusuk. Daha hizli ogrenmek icin ogrenme oranimi artirmaliyim.", AIAction::SuggestSelfImprovement, 0.9f});
            insight_cooldowns["low_learning_rate_stuck"] = now;
        }
    }
    
    if (insights.empty()) {
        if (!is_on_cooldown("stable_state", 60)) {
            // DÃ¼zeltildi: TÃ¼rkÃ§e karakterler ASCII eÅŸdeÄŸerleriyle deÄŸiÅŸtirildi
            insights.push_back({"Ic durumum stabil gorunuyor. Yeni ogrenme firsatlari icin hazirim.", AIAction::None, 0.0f});
            insight_cooldowns["stable_state"] = now;
        }
    }

    LOG_DEFAULT(LogLevel::DEBUG, "AIInsightsEngine::generate_insights: Icgoru uretimi bitti. Sayi: " << insights.size() << "\n");
    return insights;
} 
--- C:\Users\aib\CerebrumLux\src\communication\ai_insights_engine.h --- 
#ifndef CEREBRUM_LUX_AI_INSIGHTS_ENGINE_H
#define CEREBRUM_LUX_AI_INSIGHTS_ENGINE_H

#include <vector>
#include <string>
#include <numeric>
#include <map>
#include <chrono>
#include "../core/enums.h"
#include "../core/utils.h"
#include "../data_models/dynamic_sequence.h"
#include "../brain/intent_analyzer.h"
#include "../brain/intent_learner.h"
#include "../brain/prediction_engine.h"
#include "../brain/autoencoder.h"
#include "../brain/cryptofig_processor.h"

#include "../brain/intent_learner.h"


// Ä°leri bildirimler
struct DynamicSequence;
class IntentAnalyzer;
class IntentLearner;
class PredictionEngine;
class CryptofigAutoencoder;
class CryptofigProcessor;

// YENÄ°: AIInsight struct tanÄ±mÄ± (Constructor parametre sÄ±rasÄ± dÃ¼zeltildi)
struct AIInsight {
    std::string observation;
    AIAction suggested_action = AIAction::None; // Suggested action'Ä± ikinci parametre yaptÄ±k
    float urgency = 0.0f;                       // Urgency'i Ã¼Ã§Ã¼ncÃ¼ parametre yaptÄ±k

    // Constructor parametre sÄ±rasÄ± dÃ¼zeltildi
    AIInsight(std::string obs, AIAction action, float urg)
        : observation(std::move(obs)), suggested_action(action), urgency(urg) {}
};

// YENÄ°: AIInsightsEngine sÄ±nÄ±fÄ± tanÄ±mÄ±
class AIInsightsEngine {
public:
    AIInsightsEngine(IntentAnalyzer& analyzer_ref, IntentLearner& learner_ref,
                     PredictionEngine& predictor_ref, CryptofigAutoencoder& autoencoder_ref,
                     CryptofigProcessor& cryptofig_processor_ref);
    virtual std::vector<AIInsight> generate_insights(const DynamicSequence& current_sequence);

    std::string generateResponse(UserIntent intent, const std::vector<float>& latent_cryptofig_vector);

    float calculate_autoencoder_reconstruction_error(const std::vector<float>& statistical_features) const;
    
    virtual IntentAnalyzer& get_analyzer() const; 

private:
    IntentAnalyzer& analyzer;
    IntentLearner& learner;
    PredictionEngine& predictor;
    CryptofigAutoencoder& autoencoder;
    CryptofigProcessor& cryptofig_processor;

    mutable std::map<std::string, std::chrono::steady_clock::time_point> insight_cooldowns;

    // YardÄ±mcÄ± fonksiyonlar
    float calculate_average_feedback_score(UserIntent intent_id) const;

};

#endif // CEREBRUM_LUX_AI_INSIGHTS_ENGINE_H 
--- C:\Users\aib\CerebrumLux\src\communication\natural_language_processor.cpp --- 
#include "natural_language_processor.h"
#include "../core/logger.h"
#include "../core/utils.h"
#include <sstream>
#include <algorithm>
#include <cmath>
#include <chrono>

// Default constructor for tooling
NaturalLanguageProcessor::NaturalLanguageProcessor()
    : goal_manager(nullptr) { 

    // intent keyword map (kÃ¼Ã§Ã¼k ve dikkatli seÃ§ilmiÅŸ ilk set)
    intent_keyword_map[UserIntent::Programming] = {"kod", "compile", "derle", "debug", "hata", "function", "class", "stack"};
    intent_keyword_map[UserIntent::Gaming]      = {"oyun", "fps", "level", "play", "match", "steam"};
    intent_keyword_map[UserIntent::MediaConsumption] = {"video", "izle", "film", "mÃ¼zik", "spotify", "youtube"};
    intent_keyword_map[UserIntent::CreativeWork] = {"tasarla", "foto", "gÃ¶rsel", "mÃ¼zik", "compose", "yarat", "Ã¼ret"};
    intent_keyword_map[UserIntent::Research]    = {"araÅŸtÄ±r", "search", "makale", "pdf", "dokÃ¼man", "read", "oku"};
    intent_keyword_map[UserIntent::Communication] = {"mail", "mesaj", "sohbet", "reply", "gÃ¶nder"};
    intent_keyword_map[UserIntent::Editing]     = {"dÃ¼zenle", "edit", "revize", "fix", "format"};
    intent_keyword_map[UserIntent::FastTyping]  = {"hÄ±zlÄ±", "yaz", "typing", "type", "speed"};

    // state keyword map
    state_keyword_map[AbstractState::PowerSaving] = {"pil", "battery", "ÅŸarj", "charging", "battery low", "pil zayÄ±f"};
    state_keyword_map[AbstractState::FaultyHardware] = {"donanÄ±m", "arada", "error", "Ã§Ã¶k", "crash", "bozul"};
    state_keyword_map[AbstractState::Distracted] = {"dikkat", "dikkatim", "dikkat daÄŸÄ±", "uyarÄ±", "notification"};
    state_keyword_map[AbstractState::Focused] = {"odak", "focus", "konsantre", "akÄ±ÅŸ"};
}

// Constructor: initialize keyword maps
NaturalLanguageProcessor::NaturalLanguageProcessor(GoalManager& goal_manager_ref)
    : goal_manager(&goal_manager_ref) { 

    // intent keyword map (kÃ¼Ã§Ã¼k ve dikkatli seÃ§ilmiÅŸ ilk set)
    intent_keyword_map[UserIntent::Programming] = {"kod", "compile", "derle", "debug", "hata", "function", "class", "stack"};
    intent_keyword_map[UserIntent::Gaming]      = {"oyun", "fps", "level", "play", "match", "steam"};
    intent_keyword_map[UserIntent::MediaConsumption] = {"video", "izle", "film", "mÃ¼zik", "spotify", "youtube"};
    intent_keyword_map[UserIntent::CreativeWork] = {"tasarla", "foto", "gÃ¶rsel", "mÃ¼zik", "compose", "yarat", "Ã¼ret"};
    intent_keyword_map[UserIntent::Research]    = {"araÅŸtÄ±r", "search", "makale", "pdf", "dokÃ¼man", "read", "oku"};
    intent_keyword_map[UserIntent::Communication] = {"mail", "mesaj", "sohbet", "reply", "gÃ¶nder"};
    intent_keyword_map[UserIntent::Editing]     = {"dÃ¼zenle", "edit", "revize", "fix", "format"};
    intent_keyword_map[UserIntent::FastTyping]  = {"hÄ±zlÄ±", "yaz", "typing", "type", "speed"};

    // state keyword map
    state_keyword_map[AbstractState::PowerSaving] = {"pil", "battery", "ÅŸarj", "charging", "battery low", "pil zayÄ±f"};
    state_keyword_map[AbstractState::FaultyHardware] = {"donanÄ±m", "arada", "error", "Ã§Ã¶k", "crash", "bozul"};
    state_keyword_map[AbstractState::Distracted] = {"dikkat", "dikkatim", "dikkat daÄŸÄ±", "uyarÄ±", "notification"};
    state_keyword_map[AbstractState::Focused] = {"odak", "focus", "konsantre", "akÄ±ÅŸ"};
}

// Helper: lowercase copy
std::string NaturalLanguageProcessor::to_lower_copy(const std::string& s) {
    std::string out = s;
    std::transform(out.begin(), out.end(), out.begin(),
                   [](unsigned char c){ return static_cast<char>(std::tolower(c)); });
    return out;
}

// Helper: keyword contained
bool NaturalLanguageProcessor::contains_keyword(const std::string& lower_text, const std::string& lower_keyword) {
    if (lower_keyword.empty()) return false;
    return lower_text.find(lower_keyword) != std::string::npos;
}

// Rule-based guess for intent
UserIntent NaturalLanguageProcessor::rule_based_intent_guess(const std::string& lower_text) const {
    for (const auto& kv : intent_keyword_map) {
        for (const auto& kw : kv.second) {
            if (contains_keyword(lower_text, to_lower_copy(kw))) {
                return kv.first;
            }
        }
    }
    return UserIntent::Unknown;
}

// Rule-based guess for state
AbstractState NaturalLanguageProcessor::rule_based_state_guess(const std::string& lower_text) const {
    for (const auto& kv : state_keyword_map) {
        for (const auto& kw : kv.second) {
            if (contains_keyword(lower_text, to_lower_copy(kw))) {
                return kv.first;
            }
        }
    }
    return AbstractState::NormalOperation;
}

// Cryptofig scoring
float NaturalLanguageProcessor::cryptofig_score_for_intent(UserIntent intent, const std::vector<float>& latent_cryptofig) const {
    if (latent_cryptofig.empty()) return 0.0f;
    std::lock_guard<std::mutex> lock(model_mutex);
    auto it = intent_cryptofig_weights.find(intent);
    if (it == intent_cryptofig_weights.end()) return 0.0f;

    const std::vector<float>& w = it->second;
    size_t n = std::min(w.size(), latent_cryptofig.size());
    double dot = 0.0, wn = 0.0;
    for (size_t i = 0; i < n; ++i) {
        dot += w[i] * latent_cryptofig[i];
        wn += std::abs(w[i]);
    }
    if (wn == 0.0) return static_cast<float>(dot);
    return static_cast<float>(dot / (wn + 1e-6));
}

// Infer intent
UserIntent NaturalLanguageProcessor::infer_intent_from_text(const std::string& user_input) const {
    std::string lower = to_lower_copy(user_input);

    UserIntent rule_guess = rule_based_intent_guess(lower);
    if (rule_guess != UserIntent::Unknown) {
        LOG_DEFAULT(LogLevel::DEBUG, "NLP: rule_based intent guess = " << intent_to_string(rule_guess));
        return rule_guess;
    }

    if (contains_keyword(lower, "nasÄ±l") || contains_keyword(lower, "ne") ||
        contains_keyword(lower, "neden") || contains_keyword(lower, "how") ||
        contains_keyword(lower, "what") || contains_keyword(lower, "why")) {
        return UserIntent::GeneralInquiry;
    }

    return UserIntent::Unknown;
}

// Infer state
AbstractState NaturalLanguageProcessor::infer_state_from_text(const std::string& user_input) const {
    std::string lower = to_lower_copy(user_input);
    AbstractState state = rule_based_state_guess(lower);
    LOG_DEFAULT(LogLevel::DEBUG, "NLP: rule_based state guess = " << abstract_state_to_string(state));
    return state;
}

// Generate response text
std::string NaturalLanguageProcessor::generate_response_text(
    UserIntent current_intent,
    AbstractState current_abstract_state,
    AIGoal current_goal,
    const DynamicSequence& sequence,
    const std::vector<std::string>& relevant_keywords
) const {
    std::stringstream ss;
    if (goal_manager) { 
        AIGoal gm_goal = goal_manager->get_current_goal();
        if (gm_goal != AIGoal::None && gm_goal != current_goal) {
            ss << "Benim gÃ¼ncel hedefim: " << goal_to_string(gm_goal) << ". ";
        }
    }

    switch (current_intent) {
        case UserIntent::Programming:
            ss << (current_abstract_state == AbstractState::Focused ?
                "Kod yazÄ±yorsunuz gibi gÃ¶rÃ¼nÃ¼yorsunuz. YardÄ±m ister misiniz?" :
                "Programlama ile ilgili bir ÅŸey mi arÄ±yorsunuz?"); break;
        case UserIntent::Gaming: ss << "Oyun modu algÄ±landÄ±. Bildirimleri sessize alabiliriz."; break;
        case UserIntent::MediaConsumption: ss << "Medya tÃ¼ketimi modu. RahatsÄ±z etmeyecek ÅŸekilde ortamÄ± optimize edebilirim."; break;
        case UserIntent::CreativeWork: ss << "YaratÄ±cÄ± Ã§alÄ±ÅŸma algÄ±landÄ±. Odak akÄ±ÅŸÄ±nÄ±zÄ± bozmayacak ÅŸekilde yardÄ±m ister misiniz?"; break;
        case UserIntent::Research: ss << "AraÅŸtÄ±rma modunda gibi gÃ¶rÃ¼nÃ¼yorsunuz. Ä°lgili kaynaklarÄ± hÄ±zlÄ±ca getirebilirim."; break;
        case UserIntent::Communication: ss << "Ä°letiÅŸim modunda. YazÄ±m denetimi ve hÄ±zlÄ± ÅŸablonlar sunabilirim."; break;
        case UserIntent::Editing: ss << "DÃ¼zenleme yapÄ±yorsunuz. Geri al geÃ§miÅŸini veya biÃ§imlendirme Ã¶nerilerini gÃ¶sterebilirim."; break;
        case UserIntent::FastTyping: ss << "HÄ±zlÄ± yazÄ±m modu algÄ±landÄ±. Otomatik dÃ¼zeltme ve hÄ±zlÄ± destek sunabilirim."; break;
        case UserIntent::GeneralInquiry: ss << "Sormak istediÄŸiniz konuda yardÄ±mcÄ± olabilirim. Sorunuzu detaylandÄ±rÄ±r mÄ±sÄ±nÄ±z?"; break;
        case UserIntent::Unknown: default:
            if (!relevant_keywords.empty()) ss << relevant_keywords.front() << " ";
            ss << "AnladÄ±ÄŸÄ±m kadarÄ±yla niyet net deÄŸil. Daha fazla bilgi verir misiniz?"; break;
    }

    if (sequence.current_battery_percentage < 20 && !sequence.current_battery_charging)
        ss << " Pil durumu dÃ¼ÅŸÃ¼k (" << static_cast<int>(sequence.current_battery_percentage) << "%).";
    else if (sequence.current_battery_percentage < 45)
        ss << " Pil seviyesi orta. Uzun kullanÄ±m iÃ§in pil Ã¶nerileri sunabilirim.";

    LOG_DEFAULT(LogLevel::DEBUG, "NLP::generate_response_text -> " << ss.str());
    return ss.str();
}

// Online model update
void NaturalLanguageProcessor::update_model(const std::string& observed_text, UserIntent true_intent, const std::vector<float>& latent_cryptofig) {
    if (latent_cryptofig.empty()) return;
    std::lock_guard<std::mutex> lock(model_mutex);

    auto &weights = intent_cryptofig_weights[true_intent];
    if (weights.size() < latent_cryptofig.size()) weights.resize(latent_cryptofig.size(), 0.01f);

    float pred = 0.0f;
    for (size_t i = 0; i < latent_cryptofig.size(); ++i) pred += weights[i] * latent_cryptofig[i];

    float error = 1.0f - pred;
    for (size_t i = 0; i < latent_cryptofig.size(); ++i) weights[i] += online_learning_rate * error * latent_cryptofig[i];

    LOG_DEFAULT(LogLevel::DEBUG, "NLP::update_model updated weights for intent " << intent_to_string(true_intent));
}

// ðŸ”¹ Incremental training
void NaturalLanguageProcessor::trainIncremental(const std::string& input, const std::string& expected_intent) {
    UserIntent true_intent = UserIntent::Unknown;

    if (expected_intent == "Programming") true_intent = UserIntent::Programming;
    else if (expected_intent == "Gaming") true_intent = UserIntent::Gaming;
    else if (expected_intent == "MediaConsumption") true_intent = UserIntent::MediaConsumption;
    else if (expected_intent == "CreativeWork") true_intent = UserIntent::CreativeWork;
    else if (expected_intent == "Research") true_intent = UserIntent::Research;
    else if (expected_intent == "Communication") true_intent = UserIntent::Communication;
    else if (expected_intent == "Editing") true_intent = UserIntent::Editing;
    else if (expected_intent == "FastTyping") true_intent = UserIntent::FastTyping;
    else if (expected_intent == "GeneralInquiry") true_intent = UserIntent::GeneralInquiry;

    // latent_cryptofig normalde DynamicSequence'den gelmeli, burada bir dummy oluÅŸturalÄ±m
    std::vector<float> dummy_cryptofig(CryptofigAutoencoder::LATENT_DIM, 0.5f); 
    update_model(input, true_intent, dummy_cryptofig);
}

// YENÄ°: load_model implementasyonu
void NaturalLanguageProcessor::load_model(const std::string& path) {
    std::lock_guard<std::mutex> lock(model_mutex);
    LOG_DEFAULT(LogLevel::INFO, "NLP: Model yÃ¼klendi (placeholder): " << path);
    // TODO: GerÃ§ek model yÃ¼kleme mantÄ±ÄŸÄ± buraya gelecek
    // Ã–rneÄŸin, intent_cryptofig_weights haritasÄ±nÄ± dosyadan yÃ¼kle
}

// YENÄ°: save_model implementasyonu
void NaturalLanguageProcessor::save_model(const std::string& path) const {
    std::lock_guard<std::mutex> lock(model_mutex);
    LOG_DEFAULT(LogLevel::INFO, "NLP: Model kaydedildi (placeholder): " << path);
    // TODO: GerÃ§ek model kaydetme mantÄ±ÄŸÄ± buraya gelecek
    // Ã–rneÄŸin, intent_cryptofig_weights haritasÄ±nÄ± dosyaya kaydet
}

// YENÄ°: predict_intent implementasyonu
std::string NaturalLanguageProcessor::predict_intent(const std::string& input) {
    std::string lower = to_lower_copy(input);
    UserIntent intent = infer_intent_from_text(lower); // Mevcut kural tabanlÄ± Ã§Ä±karÄ±m
    
    // Daha sofistike bir tahmin iÃ§in intent_cryptofig_weights kullanÄ±labilir.
    // Åžimdilik sadece kural tabanlÄ± tahmini dÃ¶ndÃ¼rÃ¼yoruz.
    LOG_DEFAULT(LogLevel::INFO, "NLP: Tahmin edilen intent (placeholder): " << intent_to_string(intent));
    return intent_to_string(intent);
}

// YENÄ°: fallback_response_for_intent implementasyonu
std::string NaturalLanguageProcessor::fallback_response_for_intent(UserIntent intent, AbstractState state, const DynamicSequence& sequence) const {
    (void)state; // KullanÄ±lmadÄ±
    (void)sequence; // KullanÄ±lmadÄ±
    return "AnladÄ±ÄŸÄ±m kadarÄ±yla niyetiniz: " + intent_to_string(intent) + ". Size nasÄ±l yardÄ±mcÄ± olabilirim?";
} 
--- C:\Users\aib\CerebrumLux\src\communication\natural_language_processor.h --- 
#ifndef CEREBRUM_LUX_NATURAL_LANGUAGE_PROCESSOR_H
#define CEREBRUM_LUX_NATURAL_LANGUAGE_PROCESSOR_H

#include <string>
#include <vector>
#include <map>
#include <mutex>
#include "../core/enums.h"
#include "../core/utils.h"
#include "../planning_execution/goal_manager.h"

class NaturalLanguageProcessor {
public:
    explicit NaturalLanguageProcessor(GoalManager& goal_manager_ref);
    NaturalLanguageProcessor(); // For tooling

    UserIntent infer_intent_from_text(const std::string& user_input) const;
    AbstractState infer_state_from_text(const std::string& user_input) const;

    std::string generate_response_text(
        UserIntent current_intent,
        AbstractState current_abstract_state,
        AIGoal current_goal,
        const DynamicSequence& sequence,
        const std::vector<std::string>& relevant_keywords = {}
    ) const;

    void update_model(const std::string& observed_text, UserIntent true_intent, const std::vector<float>& latent_cryptofig);

    void load_model(const std::string& path);
    void save_model(const std::string& path) const;

    std::string predict_intent(const std::string& input);
    
    // ðŸ”¹ Incremental training fonksiyonu (enum uyumlu)
    void trainIncremental(const std::string& input, const std::string& expected_intent);

private:
    GoalManager* goal_manager; // Changed to pointer
    std::map<UserIntent, std::vector<std::string>> intent_keyword_map;
    std::map<AbstractState, std::vector<std::string>> state_keyword_map;
    mutable std::map<UserIntent, std::vector<float>> intent_cryptofig_weights;
    float online_learning_rate = 0.05f;
    mutable std::mutex model_mutex;

    static std::string to_lower_copy(const std::string& s);
    static bool contains_keyword(const std::string& lower_text, const std::string& lower_keyword);
    float cryptofig_score_for_intent(UserIntent intent, const std::vector<float>& latent_cryptofig) const;
    UserIntent rule_based_intent_guess(const std::string& lower_text) const;
    AbstractState rule_based_state_guess(const std::string& lower_text) const;
    std::string fallback_response_for_intent(UserIntent intent, AbstractState state, const DynamicSequence& sequence) const;
};

#endif // CEREBRUM_LUX_NATURAL_LANGUAGE_PROCESSOR_H 
--- C:\Users\aib\CerebrumLux\src\communication\response_engine.cpp --- 
#include "response_engine.h"
#include "../core/logger.h"
#include "../core/utils.h" // YENÄ°: SafeRNG iÃ§in dahil edildi (action_to_string vb. iÃ§in de gerekli)
#include "../data_models/dynamic_sequence.h"
#include "../brain/intent_analyzer.h"
#include "../planning_execution/goal_manager.h"
#include "ai_insights_engine.h"
#include "natural_language_processor.h"
#include <sstream>
#include <iomanip>
#include <algorithm>
// #include <random> // KALDIRILDI, artÄ±k utils.h'den SafeRNG kullanÄ±lÄ±yor


// === YardÄ±mcÄ± fonksiyonlar (Header dosyasÄ±nda tanÄ±mlÄ± olduÄŸu iÃ§in burada tekrar tanÄ±mlanmayacak) ===
// static bool is_critical_action_suggestion(const std::string& suggestion);
// static std::string extract_action_description(const std::string& full_suggestion);


// Kurucu: yanÄ±t ÅŸablonlarÄ± burada tanÄ±mlanÄ±r
ResponseEngine::ResponseEngine(IntentAnalyzer& analyzer_ref, GoalManager& goal_manager_ref,
                               AIInsightsEngine& insights_engine_ref, NaturalLanguageProcessor* nlp_ptr)
    : analyzer(analyzer_ref), goal_manager(goal_manager_ref), insights_engine(insights_engine_ref),
      nlp(nlp_ptr) {

    // Ã–rnek yanÄ±t ÅŸablonlarÄ±
    response_templates[UserIntent::FastTyping][AbstractState::HighProductivity].responses = {
        "Harika bir hizla yaziyorsunuz! Odaklanmaya devam edin.",
        "ÃœretkenliÄŸiniz zirvede, devam edin!",
        "YazÄ±m akÄ±cÄ±lÄ±ÄŸÄ±nÄ±z etkileyici. Åžu anki akÄ±ÅŸÄ± bozmayalÄ±m."
    };

    response_templates[UserIntent::Editing][AbstractState::Focused].responses = {
        "DÃ¼zenleme modundasÄ±nÄ±z ve odaklanmÄ±ÅŸsÄ±nÄ±z. YardÄ±ma ihtiyacÄ±nÄ±z var mÄ±?",
        "Metninizi titizlikle dÃ¼zenliyorsunuz, takdire ÅŸayan."
    };

    response_templates[UserIntent::None][AbstractState::None].responses = {
        "Size yardÄ±mcÄ± olmak iÃ§in buradayÄ±m.",
        "NasÄ±l bir destek istersiniz?"
    };

    // ... DiÄŸer yanÄ±t ÅŸablonlarÄ± da benzer ÅŸekilde eklenecek ...
    // NOTE: Bu ÅŸablonlar ÅŸu anki kodda eksik, ancak derleme hatasÄ± vermez.
    // Projenin genel kodunda bu ÅŸablonlarÄ±n tam olarak tanÄ±mlÄ± olduÄŸu varsayÄ±lmaktadÄ±r.

    response_templates[UserIntent::FastTyping][AbstractState::NormalOperation].responses = {
        "Hizli yazim modunda gibisiniz. Daha verimli olmak iÃ§in Ã¶nerilerim olabilir mi? ",
        "Hizli yaziminizda dikkat dagiticilari azaltmak ister misiniz? "
    };
    response_templates[UserIntent::Unknown][AbstractState::None].responses = {
        "Mevcut niyetiniz belirsiz. Daha fazla veri toplanarak Ã¶ÄŸrenmeye devam ediyorum. ",
        "DavranÄ±ÅŸÄ±nÄ±zÄ± anlamaya Ã§alÄ±ÅŸÄ±yorum. LÃ¼tfen etkileÅŸiminize devam edin. "
    };
    response_templates[UserIntent::Unknown][AbstractState::LowProductivity].responses = {
        "Åžu anki aktiviteniz dÃ¼ÅŸÃ¼k ve niyetiniz belirsiz. Size nasÄ±l yardÄ±mcÄ± olabilirim? ",
        "OdaklanmanÄ±zÄ± artÄ±rmak iÃ§in bildirimleri sessize alabilirim. "
    };
    response_templates[UserIntent::Unknown][AbstractState::Distracted].responses = {
        "Dikkatinizin daÄŸÄ±ldÄ±ÄŸÄ±nÄ± algÄ±ladÄ±m. OdaklanmanÄ±za yardÄ±mcÄ± olacak bir ÅŸey yapabilirim? ",
        "Ã‡ok fazla dikkat daÄŸÄ±tÄ±cÄ± var gibi gÃ¶rÃ¼nÃ¼yor. Bildirimleri sessize alalÄ±m mÄ±? "
    };
    response_templates[UserIntent::None][AbstractState::FaultyHardware].responses = {
        "Sistem performansÄ±nÄ±z dÃ¼ÅŸÃ¼k gÃ¶rÃ¼nÃ¼yor. Optimizasyon yapmamÄ± ister misiniz?",
        "UygulamalarÄ±nÄ±z yavaÅŸ mÄ± Ã§alÄ±ÅŸÄ±yor? Arka plan iÅŸlemlerini kontrol edebilirim."
    };
    response_templates[UserIntent::Programming][AbstractState::Focused].responses = {
        "Programlama modundasÄ±nÄ±z ve odaklanmÄ±ÅŸsÄ±nÄ±z. AkÄ±ÅŸÄ±nÄ±zÄ± bozmayalÄ±m. ",
        "Kod yazÄ±mÄ±nÄ±zda bir yardÄ±ma ihtiyacÄ±nÄ±z var mÄ±? ",
        "Hata ayÄ±klama yapÄ±yor gibisiniz, bu konuda bir ipucu ister misiniz? "
    };
    response_templates[UserIntent::Programming][AbstractState::NormalOperation].responses = {
        "Programlama ile uÄŸraÅŸÄ±yorsunuz. HÄ±zlÄ±ca bir dokÃ¼man aÃ§mamÄ± ister misiniz? "
    };
    response_templates[UserIntent::Programming][AbstractState::Debugging].responses = {
        "YoÄŸun bir hata ayÄ±klama sÃ¼recindesiniz. Kodunuzun geÃ§miÅŸini kontrol edelim mi? ",
        "Bu sorun Ã¼zerinde ne kadar zamandÄ±r Ã§alÄ±ÅŸÄ±yorsunuz? Belki kÄ±sa bir mola iyi gelir."
    };
    response_templates[UserIntent::Gaming][AbstractState::Focused].responses = {
        "Oyun deneyiminiz zirvede! Ä°yi eÄŸlenceler. ",
        "Oyun oynarken tÃ¼m bildirimleri sessize almamÄ± ister misiniz? "
    };
    response_templates[UserIntent::Gaming][AbstractState::Distracted].responses = {
        "Oyun sÄ±rasÄ±nda dikkatiniz daÄŸÄ±lÄ±yor gibi. Sistem performansÄ±nÄ± optimize edelim mi? ",
        "Arka plan uygulamalarÄ±nÄ± kapatarak daha akÄ±cÄ± bir deneyim saÄŸlayabilirim. "
    };
    response_templates[UserIntent::MediaConsumption][AbstractState::PassiveConsumption].responses = {
        "Pasif medya tÃ¼ketiyorsunuz. Keyfinizi bozmayalÄ±m. ",
        "EkranÄ± daha da karartarak pil tasarrufu saÄŸlayabilirim. "
    };
    response_templates[UserIntent::MediaConsumption][AbstractState::NormalOperation].responses = {
        "Medya tÃ¼ketiyorsunuz. Ses seviyesini ayarlayabilirim. "
    };
    response_templates[UserIntent::CreativeWork][AbstractState::CreativeFlow].responses = {
        "YaratÄ±cÄ± akÄ±ÅŸ modundasÄ±nÄ±z! Size ilham verecek baÅŸka bir ÅŸey yapabilirim? ",
        "YaratÄ±cÄ±lÄ±ÄŸÄ±nÄ±zÄ± kesintiye uÄŸratmamak iÃ§in dikkat daÄŸÄ±tÄ±cÄ±larÄ± engelleyelim. "
    };
    response_templates[UserIntent::CreativeWork][AbstractState::NormalOperation].responses = {
        "YaratÄ±cÄ± bir iÅŸle uÄŸraÅŸÄ±yorsunuz. Sizin iÃ§in bir hatÄ±rlatÄ±cÄ± kurabilirim. "
    };
    response_templates[UserIntent::Research][AbstractState::SeekingInformation].responses = {
        "YoÄŸun bir bilgi arayÄ±ÅŸÄ±ndasÄ±nÄ±z. Ä°lgili dokÃ¼manlarÄ± aÃ§mamÄ± ister misiniz? ",
        "Odak modunu etkinleÅŸtirerek araÅŸtÄ±rmanÄ±za daha iyi odaklanabilirsiniz. "
    };
    response_templates[UserIntent::Communication][AbstractState::SocialInteraction].responses = {
        "Sosyal etkileÅŸim halindesiniz. HÄ±zlÄ± ve kesintisiz iletiÅŸim iÃ§in buradayÄ±m. ",
        "YazÄ±m denetimini hÄ±zlandÄ±rmak ister misiniz? "
    };
    response_templates[UserIntent::Communication][AbstractState::NormalOperation].responses = {
        "Ä°letiÅŸim kuruyorsunuz. E-posta veya mesajlaÅŸma uygulamasÄ±nÄ± hÄ±zlÄ±ca aÃ§abilirim. "
    };
}

std::string ResponseEngine::generate_response(UserIntent current_intent, AbstractState current_abstract_state, AIGoal current_goal, const DynamicSequence& sequence) const {
    LOG_DEFAULT(LogLevel::DEBUG, "ResponseEngine::generate_response: Niyet=" << intent_to_string(current_intent) << 
                ", Durum=" << abstract_state_to_string(current_abstract_state) << ", Hedef=" << goal_to_string(current_goal) << "\n"); 

    std::vector<std::string> insights_as_keywords; 
    std::vector<AIInsight> insights_from_engine = insights_engine.generate_insights(sequence);
    for (const auto& insight : insights_from_engine) {
        insights_as_keywords.push_back(insight.observation); 
    }

    // NLP ile yanÄ±t Ã¼retimi
    std::string final_response_text;
    if (nlp) { // Null check
        final_response_text = nlp->generate_response_text( 
            current_intent,
            current_abstract_state,
            current_goal,
            sequence,
            insights_as_keywords 
        );
    } else {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "ResponseEngine::generate_response: NaturalLanguageProcessor pointer null! Genel fallback yanâ”€â–’ta dâ”œâ•â”¼iliyor.\n"); // DÃœZELTÄ°LDÄ°: LogLevel::ERROR yerine ERR_CRITICAL
        // NLP yoksa veya null ise, eski kural tabanlÄ± yanÄ±tlardan birini seÃ§
        if (response_templates.count(current_intent) && response_templates.at(current_intent).count(current_abstract_state)) {
            // Hata dÃ¼zeltildi: current_abstract_state kullanÄ±ldÄ±
            std::uniform_int_distribution<> distrib(0, response_templates.at(current_intent).at(current_abstract_state).responses.size() - 1); 
            final_response_text = response_templates.at(current_intent).at(current_abstract_state).responses[distrib(SafeRNG::get_instance().get_generator())]; // SafeRNG kullanÄ±ldÄ±
        } else if (response_templates.count(UserIntent::None) && response_templates.at(UserIntent::None).count(AbstractState::None)) {
            std::uniform_int_distribution<> distrib(0, response_templates.at(UserIntent::None).at(AbstractState::None).responses.size() - 1);
            final_response_text = response_templates.at(UserIntent::None).at(AbstractState::None).responses[distrib(SafeRNG::get_instance().get_generator())]; // SafeRNG kullanÄ±ldÄ±
        } else {
            final_response_text = "NLP ve ÅŸablonlar kullanÄ±lamadÄ±ÄŸÄ± iÃ§in yardÄ±mcÄ± olamÄ±yorum.";
        }
    }


    // Kritik eylem Ã¶nerisi varsa onay sorusu ekle
    if (is_critical_action_suggestion(final_response_text)) {
        std::string action_description = extract_action_description(final_response_text); 
        final_response_text = "Åžu eylemi [" + action_description + "] yapmak istiyorum. OnaylÄ±yor musunuz? (Evet/HayÄ±r)";
        LOG_DEFAULT(LogLevel::DEBUG, "Kritik eylem onayÄ± istendi: " << final_response_text << "\n");
        return final_response_text;
    }

    // Dinamik yer tutucularÄ± ve ek mesajlar
    if (!final_response_text.empty()) {
        // Replace 'X ms'
        size_t pos_ms = final_response_text.find("X ms");
        if (pos_ms != std::string::npos) {
            std::stringstream ss_ms;
            ss_ms << std::fixed << std::setprecision(0) << sequence.avg_keystroke_interval / 1000.0f; 
            final_response_text.replace(pos_ms, 4, ss_ms.str() + " ms");
        }

        // Replace 'pil durumu'
        size_t pos_battery = final_response_text.find("pil durumu");
        if (pos_battery != std::string::npos) {
            std::stringstream ss_battery;
            ss_battery << (int)sequence.current_battery_percentage << "%";
            final_response_text.replace(pos_battery, 10, ss_battery.str());
        }

        // Add intent-specific concluding remarks (if not already handled by more specific responses)
        // Bu kÄ±sÄ±m artÄ±k NLP iÃ§inde daha iyi ele alÄ±nabilir, ancak basit bir fallback olarak burada durabilir.
        if (current_intent == UserIntent::FastTyping && !sequence.statistical_features_vector.empty() && sequence.statistical_features_vector[2] > 0.95f && final_response_text.find("Harika bir odaklanmayla") == std::string::npos) { 
            final_response_text += " Harika bir odaklanmayla Ã§alÄ±ÅŸÄ±yorsunuz.";
        } else if (current_intent == UserIntent::Editing && !sequence.statistical_features_vector.empty() && sequence.statistical_features_vector[3] > 0.40f && final_response_text.find("GeliÅŸmiÅŸ dÃ¼zenleme yetenekleriniz") == std::string::npos) { 
            final_response_text += " GeliÅŸmiÅŸ dÃ¼zenleme yetenekleriniz etkileyici.";
        }
    }

    LOG_DEFAULT(LogLevel::DEBUG, "ResponseEngine::generate_response: OluÅŸturulan yanÄ±t (NLP destekli): " << final_response_text << "\n");
    return final_response_text; 
} 
--- C:\Users\aib\CerebrumLux\src\communication\response_engine.h --- 
#ifndef CEREBRUM_LUX_RESPONSE_ENGINE_H
#define CEREBRUM_LUX_RESPONSE_ENGINE_H

#include <string> // std::string
#include <vector> // std::vector
#include <map>    // std::map
// #include <random> // KALDIRILDI: ArtÄ±k SafeRNG kullanÄ±lÄ±yor

#include "../core/enums.h" // UserIntent, AbstractState, AIGoal, AIAction, LogLevel
#include "../core/utils.h" // intent_to_string, abstract_state_to_string, action_to_string, YENÄ°: SafeRNG iÃ§in
#include "../data_models/dynamic_sequence.h"
#include "../brain/intent_analyzer.h"
#include "../planning_execution/goal_manager.h"
#include "ai_insights_engine.h"
#include "natural_language_processor.h"

// Ä°leri bildirimler
struct DynamicSequence;
class IntentAnalyzer;
class GoalManager;
class AIInsightsEngine;
class NaturalLanguageProcessor;

// YanÄ±t ÅŸablonlarÄ±nÄ± tutan yapÄ±
struct ResponseTemplate {
    std::vector<std::string> responses;
    float trigger_threshold = 0.0f;
};

// ResponseEngine sÄ±nÄ±fÄ±
class ResponseEngine {
public:
    // Kurucu: tÃ¼m baÄŸÄ±mlÄ±lÄ±klar referans olarak alÄ±nÄ±r
        ResponseEngine(IntentAnalyzer& analyzer_ref, GoalManager& goal_manager_ref,
                   AIInsightsEngine& insights_engine_ref, NaturalLanguageProcessor* nlp_ptr);

    // KullanÄ±cÄ±nÄ±n niyeti, durumu ve hedefi ile birlikte dinamik yanÄ±t Ã¼retir
    std::string generate_response(UserIntent current_intent, AbstractState current_abstract_state,
                                  AIGoal current_goal, const DynamicSequence& sequence) const;

private:
    IntentAnalyzer& analyzer;
    GoalManager& goal_manager;
    AIInsightsEngine& insights_engine;
    NaturalLanguageProcessor* nlp;

    // Niyet ve durum kombinasyonlarÄ±na gÃ¶re yanÄ±t ÅŸablonlarÄ±
    std::map<UserIntent, std::map<AbstractState, ResponseTemplate>> response_templates;

    // KALDIRILDI: mutable std::mt19937 gen; // Rastgele sayÄ± Ã¼reteci
    // KALDIRILDI: mutable std::random_device rd; 
};

// === YardÄ±mcÄ± fonksiyonlar ===
// Kritik eylem Ã¶nerisi iÃ§erip iÃ§ermediÄŸini kontrol eder
static bool is_critical_action_suggestion(const std::string& suggestion) {
    const std::vector<std::string> critical_keywords = {
        "optimize etmemi ister misiniz?", "UygulamalarÄ± kapatmamÄ± ister misiniz?",
        "Gerekli olmayan baÄŸlantÄ±larÄ± kesmemi ister misiniz?", "arka plan sÃ¼reÃ§lerini optimize edebilirim.",
        "gereksiz sekmeleri kapatarak", "Arka plan uygulamalarÄ±nÄ± kapatarak",
        "Sistem performansÄ±nÄ± optimize edelim mi?", "Kaydetmek ister misiniz?",
        "Otomatik dÃ¼zeltmemi ister misiniz?"
    };
    for (const auto& kw : critical_keywords) {
        if (suggestion.find(kw) != std::string::npos) return true;
    }
    return false;
}

// Kritik eylem Ã¶nerisinden sadece eylem aÃ§Ä±klamasÄ±nÄ± Ã§Ä±karÄ±r
static std::string extract_action_description(const std::string& full_suggestion) {
    std::string description = full_suggestion;

    // Ã–nek temizleme
    const std::vector<std::string> prefixes = {"AI Ã–nerisi: ", "[AI-ICGORU]: "};
    for (const auto& pre : prefixes) {
        if (description.rfind(pre, 0) == 0) {
            description.erase(0, pre.length());
        }
    }

    // SÄ±k kullanÄ±lan son ekleri temizle
    const std::vector<std::string> suffixes = {
        " ister misiniz?", " edebilirim.", " saÄŸlayabilirim.", " kapatabilirim.",
        " artÄ±rabilirim.", " optimize edebilirim?", " kesmemi ister misiniz?",
        " edelim mi?", " Ã¶neririm.", " olabilirim?", " Otomatik dÃ¼zeltmemi ister misiniz?",
        " Kaydetmek ister misiniz?"
    };
    for (const auto& suf : suffixes) {
        size_t pos = description.find(suf);
        if (pos != std::string::npos) description.erase(pos);
    }

    // Noktalama ve boÅŸluk temizleme
    while (!description.empty() && (description.back() == '.' || description.back() == '?' || 
                                   description.back() == ' ' || description.back() == '\n')) {
        description.pop_back();
    }
    return description;
}

#endif // CEREBRUM_LUX_RESPONSE_ENGINE_H 
--- C:\Users\aib\CerebrumLux\src\communication\suggestion_engine.cpp --- 
#include "suggestion_engine.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/utils.h"       // LOG ve SafeRNG iÃ§in
#include "../core/logger.h"      // YENÄ°: LOG makrosu iÃ§in logger.h dahil edildi
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in
#include "../brain/intent_analyzer.h" // IntentAnalyzer iÃ§in
#include <algorithm> // std::max iÃ§in
#include <iostream> // Debug iÃ§in

// === SuggestionEngine Implementasyonlari ===

SuggestionEngine::SuggestionEngine(IntentAnalyzer& analyzer_ref) 
    : analyzer(analyzer_ref) // KALDIRILDI: gen(rd())
{
    // Q-tablosunu baÅŸlatmaya gerek yok, eriÅŸildikÃ§e varsayÄ±lan 0.0f deÄŸeri alacak.
}

// YENÄ°: Q-deÄŸerini gÃ¼ncelleme metodu
void SuggestionEngine::update_q_value(const StateKey& state, AIAction action, float reward) {
    float current_q = q_table[state][action]; // VarsayÄ±lan olarak 0.0f eÄŸer yoksa
    
    q_table[state][action] += learning_rate_rl * (reward - current_q);

    LOG_DEFAULT(LogLevel::DEBUG, "SuggestionEngine: Q-deÄŸeri gÃ¼ncellendi. Niyet: " << intent_to_string(state.intent) << 
                ", Durum: " << abstract_state_to_string(state.state) << 
                ", Eylem: " << action_to_string(action) << 
                ", Ã–dÃ¼l: " << reward << ", Yeni Q: " << q_table[state][action] << "\n");
}


// suggest_action metodu gÃ¼ncellendi: Q-tablosu ve epsilon-greedy stratejisi kullanÄ±lÄ±yor
AIAction SuggestionEngine::suggest_action(UserIntent current_intent, AbstractState current_abstract_state, const DynamicSequence& sequence) {
    StateKey current_state_key = {current_intent, current_abstract_state}; 

    // Epsilon-greedy stratejisi
    std::uniform_real_distribution<float> distrib_rand(0.0f, 1.0f);
    if (distrib_rand(SafeRNG::get_instance().get_generator()) < exploration_rate_rl) { // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        // KeÅŸfet (rastgele eylem seÃ§)
        std::vector<AIAction> possible_actions;
        for (int i = 0; i < static_cast<int>(AIAction::Count); ++i) {
            AIAction action = static_cast<AIAction>(i);
            if (action != AIAction::None && action != AIAction::Count) { // GeÃ§ersiz eylemleri hariÃ§ tut
                possible_actions.push_back(action);
            }
        }
        if (!possible_actions.empty()) {
            std::uniform_int_distribution<> action_distrib(0, possible_actions.size() - 1);
            AIAction chosen_action = possible_actions[action_distrib(SafeRNG::get_instance().get_generator())]; // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
            LOG_DEFAULT(LogLevel::DEBUG, "SuggestionEngine: Rastgele eylem seÃ§ildi (keÅŸif). Niyet: " << intent_to_string(current_intent) << ", Durum: " << abstract_state_to_string(current_abstract_state) << ", Eylem: " << action_to_string(chosen_action) << "\n");
            return chosen_action;
        }
    } else {
        // Faydalan (en iyi Q-deÄŸerine sahip eylemi seÃ§)
        float max_q_value = -std::numeric_limits<float>::max();
        AIAction best_action = AIAction::None;
        
        if (q_table.count(current_state_key)) {
            const auto& actions_for_state = q_table.at(current_state_key);
            for (const auto& pair : actions_for_state) {
                if (pair.second > max_q_value) {
                    max_q_value = pair.second;
                    best_action = pair.first;
                }
            }
        }

        if (best_action != AIAction::None) {
            LOG_DEFAULT(LogLevel::DEBUG, "SuggestionEngine: En iyi eylem seÃ§ildi (faydalanma). Niyet: " << intent_to_string(current_intent) << ", Durum: " << abstract_state_to_string(current_abstract_state) << ", Eylem: " << action_to_string(best_action) << " (Q: " << max_q_value << ")\n");
            return best_action;
        }
    }

    // EÄŸer hiÃ§bir ÅŸey seÃ§ilemezse, varsayÄ±lan olarak None dÃ¶ndÃ¼r
    LOG_DEFAULT(LogLevel::DEBUG, "SuggestionEngine: VarsayÄ±lan eylem seÃ§ildi (None).\n");
    return AIAction::None;
}
 
--- C:\Users\aib\CerebrumLux\src\communication\suggestion_engine.h --- 
#ifndef CEREBRUM_LUX_SUGGESTION_ENGINE_H
#define CEREBRUM_LUX_SUGGESTION_ENGINE_H

#include <string> // std::string iÃ§in
#include <vector> // std::vector iÃ§in
#include <map>    // std::map iÃ§in
#include "../core/enums.h"         // Enumlar iÃ§in
#include "../core/utils.h"         // For SafeRNG and other utilities
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in ileri bildirim
#include "../brain/intent_analyzer.h" // IntentAnalyzer iÃ§in ileri bildirim

// Ä°leri bildirimler
struct DynamicSequence;
class IntentAnalyzer;

// *** StateKey: Q-Tablosu iÃ§in durum temsilcisi ***
// UserIntent ve AbstractState'i birleÅŸtirerek bir "durum" tanÄ±mlar.
struct StateKey {
    UserIntent intent;
    AbstractState state;

    // std::map'te anahtar olarak kullanÄ±labilmesi iÃ§in karÅŸÄ±laÅŸtÄ±rma operatÃ¶rÃ¼
    bool operator<(const StateKey& other) const {
        if (intent != other.intent) {
            return intent < other.intent;
        }
        return state < other.state;
    }
};

// *** SuggestionEngine: AI'Ä±n kullaniciya eylem Ã¶nerileri sunar ***
class SuggestionEngine {
public:
    SuggestionEngine(IntentAnalyzer& analyzer_ref);

    // Belirli bir niyet ve soyut durum iÃ§in en uygun eylemi Ã¶nerir (imza gÃ¼ncellendi)
    virtual AIAction suggest_action(UserIntent current_intent, AbstractState current_abstract_state, const DynamicSequence& sequence); // YENÄ°: virtual eklendi

    // YENÄ°: PekiÅŸtirmeli Ã¶ÄŸrenme iÃ§in Q-deÄŸerini gÃ¼nceller
    virtual void update_q_value(const StateKey& state, AIAction action, float reward); // YENÄ°: virtual eklendi

private:
    IntentAnalyzer& analyzer;

    // PekiÅŸtirmeli Ã¶ÄŸrenme iÃ§in Q-Tablosu
    std::map<StateKey, std::map<AIAction, float>> q_table;
    float learning_rate_rl = 0.1f; // Alfa
    float discount_factor_rl = 0.9f; // Gama
    float exploration_rate_rl = 0.1f; // Epsilon (epsilon-greedy iÃ§in)
};

#endif // CEREBRUM_LUX_SUGGESTION_ENGINE_H 
--- C:\Users\aib\CerebrumLux\src\core\enums.h --- 
#ifndef CEREBRUM_LUX_ENUMS_H
#define CEREBRUM_LUX_ENUMS_H

// Bu dosyada tÃ¼m enum tanÄ±mlarÄ± yer alacak:
// KeyType, KeyEventType, UserIntent, AIAction, SensorType, AbstractState, AIGoal, LogLevel

// Ä°leri bildirimler (gerekirse)
// extern LogLevel g_current_log_level; // Global deÄŸiÅŸken, utils.h/cpp'ye taÅŸÄ±nacak

// Ä°leri bildirimler (gerekirse, bu dosyanÄ±n dÄ±ÅŸÄ±ndaki sÄ±nÄ±flar iÃ§in)
// Bu dosya diÄŸer hiÃ§bir ÅŸeyi doÄŸrudan #include etmeyecek, temel enumlarÄ± saÄŸlayacak.


//Ä°Ã§erik Notu: cerebrum_lux_core.h dosyasÄ±ndaki tÃ¼m enum class tanÄ±mlarÄ±nÄ± (KeyType'tan AIGoal'e kadar) buraya taÅŸÄ±yÄ±n. g_current_log_level bildirimi buradan kaldÄ±rÄ±lacak, utils.h'e geÃ§ecek.

// Enum tanÄ±mlarÄ±
enum class KeyType : unsigned char;
enum class KeyEventType : unsigned char;
enum class UserIntent : unsigned char;
enum class AIAction : unsigned char;
enum class SensorType : unsigned char;
enum class AbstractState : unsigned char;
enum class AIGoal : unsigned char;
enum class LogLevel : unsigned char;

// Basilan tusun tipi
enum class KeyType : unsigned char {
    Alphanumeric, // Harf veya sayilar
    Whitespace,   // Bosluk, Sekme
    Control,      // Ctrl, Alt, Shift, Fn
    Modifier,     // Super/Windows/Command tuslari
    Navigation,   // Ok tuslari, Home, End
    Function,     // F1-F12
    Backspace,    // Geri tusu
    Enter,        // Enter tusu
    Other         // Diger ozel karakterler
};

// Tus olayi tipi (basma/birakma)
enum class KeyEventType : unsigned char {
    Press,
    Release
};

// Tahmini kullanici niyetleri
enum class UserIntent : unsigned char {
    None,         // HiÃ§bir niyetin belirlenmediÄŸi varsayÄ±lan durum iÃ§in
    Unknown,      // Bilinmiyor
    FastTyping,   // HÄ±zlÄ± Yazma Modu
    Editing,      // DÃ¼zenleme Modu
    IdleThinking, // DÃ¼ÅŸÃ¼nme/Ara Verme Modu
    
    // YENÄ° NÄ°YETLER
    Programming,      // YazÄ±lÄ±m geliÅŸtirme
    Gaming,           // Oyun oynama
    MediaConsumption, // Medya tÃ¼ketimi (video izleme, mÃ¼zik dinleme)
    CreativeWork,     // YaratÄ±cÄ± Ã§alÄ±ÅŸma (grafik tasarÄ±m, mÃ¼zik prodÃ¼ksiyonu)
    Research,         // AraÅŸtÄ±rma yapma (tarayÄ±cÄ±da yoÄŸun gezinme, okuma)
    Communication,    // Ä°letiÅŸim (mesajlaÅŸma, e-posta)

    // Eksik olanlar eklendi
    VideoEditing,     // Video dÃ¼zenleme
    Browsing,         // Ä°nternette gezinme
    Reading,          // Okuma
    GeneralInquiry,   // Genel sorgulama

    Count             // Enum bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ saymak iÃ§in (yardÄ±mcÄ± Ã¼ye)
};

// AI'in yapabileceÄŸi veya Ã¶nerebileceÄŸi eylemler
enum class AIAction : unsigned char {
    None,
    DisableSpellCheck,
    EnableCustomDictionary,
    ShowUndoHistory,
    CompareVersions,
    DimScreen,
    MuteNotifications,
    LaunchApplication, 
    OpenFile,          
    SetReminder,       
    SimulateOSAction,  
    SuggestBreak,       // Ara vermeyi Ã¶ner
    OptimizeForGaming,  // Oyun performansÄ± iÃ§in optimize et
    EnableFocusMode,    // Odaklanma modunu etkinleÅŸtir
    AdjustAudioVolume,  // Ses seviyesini ayarla
    OpenDocumentation,  // DokÃ¼mantasyon aÃ§ (Programlama iÃ§in)
    SuggestSelfImprovement, // AI'nÄ±n kendini geliÅŸtirme Ã¶nerisi

    Count             // Enum bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ saymak iÃ§in
};

// Yeni sensÃ¶r tipleri
enum class SensorType : unsigned char {
    None,             // YENÄ°: HiÃ§bir sensÃ¶r tipinin belirlenmediÄŸi varsayÄ±lan durum iÃ§in
    Keyboard,
    Mouse,
    Display,
    Battery,
    Network,
    Application,
    Microphone,
    Camera,
    GPS,
    HeartRate,
    AmbientLight,
    Temperature,
    Humidity,
    Pressure,
    Proximity,
    Accelerometer,
    Gyroscope,
    Magnetometer,
    Barometer,
    UVLight,
    Infrared,
    Gesture,
    Speech,
    EyeTracking,
    FacialExpression,
    BodyPosture,
    BrainActivity,
    EnvironmentalAudio,
    Touch,
    ProximityGesture,
    Haptic,
    Force,
    Chemical,
    HeartSound,
    BloodPressure,
    Glucose,
    Sleep,
    Stress,
    Hydration,
    Activity,
    Location,
    ObjectDetection,
    PoseEstimation,
    EmotionRecognition,
    SpeechRecognition,
    ContextAwareness,
    CognitiveLoad,
    EnvironmentalNoise,
    AirQuality,
    UVIndex,
    HeartRateVariability,
    GalvanicSkinResponse,
    BloodOxygen,
    RespirationRate,
    BloodAlcohol,
    GPSAccuracy,
    Compass,
    Altimeter,
    GeomagneticRotation,
    RelativeHumidity,
    AbsoluteHumidity,
    DewPoint,
    WindSpeed,
    WindDirection,
    Rainfall,
    Snowfall,
    CloudCover,
    Visibility,
    WaterTemperature,
    WaterPressure,
    WaterFlow,
    SoilMoisture,
    SoilTemperature,
    LeafWetness,
    SolarRadiation,
    Chlorophyll,
    PH,
    ElectricalConductivity,
    DissolvedOxygen,
    Turbidity,
    Salinity,
    ORP,
    IonSelective,
    Gas,
    Smoke,
    Flame,
    Motion,
    Vibration,
    Acoustic,
    Ultrasonic,
    InfraredProximity,
    Radar,
    Lidar,
    GeigerCounter,
    Seismic,
    Weight,
    Load,
    Torque,
    Flow,
    Level,
    Position,
    Displacement,
    Velocity,
    Acceleration,
    Angle,
    Distance,
    LightIntensity,
    Color,
    InfraredTemperature,
    MicrophoneArray,
    CameraArray,
    LidarArray,
    RadarArray,
    EEG,
    ECG,
    EMG,
    EOG,
    GSR,
    PPG,
    SPO2,
    BloodPressureCuff,
    GlucoseMeter,
    SleepMonitor,
    StressMonitor,
    HydrationMonitor,
    ActivityTracker,
    LocationTracker,
    ObjectRecognition,
    PoseTracking,
    EmotionDetection,
    SpeechDetection,
    ContextRecognition,
    CognitiveLoadMonitor,
    EnvironmentalNoiseMonitor,
    AirQualityMonitor,
    UVIndexMonitor,
    HeartRateVariabilityMonitor,
    GalvanicSkinResponseMonitor,
    BloodOxygenMonitor,
    RespirationRateMonitor,
    BloodAlcoholMonitor,
    GPSReceiver,
    CompassSensor,
    AltimeterSensor,
    GeomagneticRotationSensor,
    RelativeHumiditySensor,
    AbsoluteHumiditySensor,
    DewPointSensor,
    WindSpeedSensor,
    WindDirectionSensor,
    RainfallSensor,
    SnowfallSensor,
    CloudCoverSensor,
    VisibilitySensor,
    WaterTemperatureSensor,
    WaterPressureSensor,
    WaterFlowSensor,
    SoilMoistureSensor,
    SoilTemperatureSensor,
    LeafWetnessSensor,
    SolarRadiationSensor,
    ChlorophyllSensor,
    PHSensor,
    ElectricalConductivitySensor,
    DissolvedOxygenSensor,
    TurbiditySensor,
    SalinitySensor,
    ORPSensor,
    IonSelectiveSensor,
    GasSensor,
    SmokeSensor,
    FlameSensor,
    MotionSensor,
    VibrationSensor,
    AcousticSensor,
    UltrasonicSensor,
    InfraredProximitySensor,
    RadarSensor,
    LidarSensor,
    GeigerCounterSensor,
    SeismicSensor,
    WeightSensor,
    LoadSensor,
    TorqueSensor,
    FlowSensor,
    LevelSensor,
    PositionSensor,
    DisplacementSensor,
    VelocitySensor,
    AccelerationSensor,
    AngleSensor,
    DistanceSensor,
    LightIntensitySensor,
    ColorSensor,
    InfraredTemperatureSensor,

    Count             // Enum bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ saymak iÃ§in
};

// Daha yÃ¼ksek seviyeli, soyut durumlar
enum class AbstractState : unsigned char {
    None,
    HighProductivity,
    LowProductivity,
    Focused,
    Distracted,
    PowerSaving,
    NormalOperation,
    
    // YENÄ° SOYUT DURUMLAR
    CreativeFlow,     // YaratÄ±cÄ± bir "akÄ±ÅŸ" durumunda olma
    Debugging,        // Hata ayÄ±klama modunda olma (yoÄŸun kontrol tuÅŸu, hÄ±zlÄ± geri alma)
    PassiveConsumption, // Pasif medya tÃ¼ketimi (sadece izleme/dinleme)
    HardwareAnomaly,  // DonanÄ±m anormalliÄŸi (pil, aÄŸ, disk performansÄ± sorunlarÄ±)
    SeekingInformation, // Bilgi arayÄ±ÅŸÄ± (tarayÄ±cÄ±, arama motorlarÄ±)
    SocialInteraction,  // Sosyal etkileÅŸim (mesajlaÅŸma, sosyal medya)

    // Eksik olanlar eklendi
    HighPerformance,  // YÃ¼ksek performans modu
    FaultyHardware,   // ArÄ±zalÄ± donanÄ±m durumu

    Count             // Enum bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ saymak iÃ§in
};

// AI'Ä±n ulaÅŸmaya Ã§alÄ±ÅŸacaÄŸÄ± hedefler
enum class AIGoal : unsigned char {
    None,
    OptimizeProductivity,
    MaximizeBatteryLife,
    ReduceDistractions,
    // Gelecekte eklenecek diger hedefler
    EnhanceCreativity,    // YaratÄ±cÄ±lÄ±ÄŸÄ± artÄ±rma
    ImproveGamingExperience, // Oyun deneyimini iyileÅŸtirme
    FacilitateResearch,   // AraÅŸtÄ±rmayÄ± kolaylaÅŸtÄ±rma
    SelfImprovement,      // AI'nÄ±n kendi kendini geliÅŸtirme hedefi

    Count                 // Enum bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ saymak iÃ§in
};

// Raporlama seviyeleri
enum class LogLevel : unsigned char {
    SILENT,   // HiÃ§bir Ã§Ä±ktÄ±
    ERR_CRITICAL,    // Sadece hatalar (ERROR makro Ã§akÄ±ÅŸmasÄ±nÄ± Ã¶nlemek iÃ§in yeniden adlandÄ±rÄ±ldÄ±)
    WARNING,  // Hatalar ve uyarÄ±lar
    INFO,     // Genel bilgi mesajlarÄ± (varsayÄ±lan)
    DEBUG,    // DetaylÄ± hata ayÄ±klama bilgisi
    TRACE     // Ã‡ok detaylÄ±, her adÄ±mÄ± gÃ¶steren Ã§Ä±ktÄ±lar
};


// LearningRateAdjustmentMessage 
enum class MessageType {
    Unknown,
    LearningRateAdjustment
};

struct MessageData {
    MessageType type;
    float learningRate;
};

#endif // CEREBRUM_LUX_ENUMS_H 
--- C:\Users\aib\CerebrumLux\src\core\logger.cpp --- 
#include "logger.h"
#include "utils.h"       
// #include "../gui/panels/LogPanel.h" // ArtÄ±k doÄŸrudan LogPanel'e eriÅŸmiyoruz.
#include <chrono>
#include <ctime>
#include <iomanip> 
#include <string>  
#include <locale>  
#include <cerrno>  
#include <QMetaObject> 
#include <QString> 
#include <QTextEdit> 

std::string Logger::level_to_string(LogLevel level) const {
    switch (level) {
        case LogLevel::SILENT: return "SILENT";
        case LogLevel::ERR_CRITICAL: return "CRITICAL";
        case LogLevel::WARNING: return "WARNING";
        case LogLevel::INFO: return "INFO";
        case LogLevel::DEBUG: return "DEBUG";
        case LogLevel::TRACE: return "TRACE";
        default: return "UNKNOWN";
    }
}

Logger& Logger::get_instance() {
    static Logger instance;
    return instance;
}

void Logger::init(LogLevel level, const std::string& log_file_path, const std::string& log_source) {
    std::lock_guard<std::mutex> lock(mutex_); 
    level_ = level;
    log_source_ = log_source; 
    if (!log_file_path.empty()) {
        if (file_stream_.is_open()) {
            file_stream_.close();
        }
        file_stream_.open(log_file_path, std::ios_base::app); 
        if (!file_stream_.is_open()) {
            std::cerr << "Hata: Log dosyasÄ± aÃ§Ä±lamadÄ±: " << log_file_path << " (errno: " << errno << ")\n";
        }
    }
}

Logger::~Logger() {
    if (file_stream_.is_open()) {
        file_stream_.close();
    }
}

LogLevel Logger::get_level() const {
    return level_;
}

void Logger::set_log_panel_text_edit(QTextEdit* textEdit) {
    std::lock_guard<std::mutex> lock(buffer_mutex); 
    m_guiLogTextEdit = textEdit;
    if (m_guiLogTextEdit) {
        for (const std::string& buffered_log : initial_log_buffer) {
            QMetaObject::invokeMethod(m_guiLogTextEdit, "append", Qt::QueuedConnection, Q_ARG(QString, QString::fromStdString(buffered_log)));
        }
        initial_log_buffer.clear(); 
    }
}

void Logger::log(LogLevel level, const std::string& message, const char* file, int line) {
    if (level > level_) {
        return;
    }

    std::lock_guard<std::mutex> lock(mutex_); 

    log_counter_++;

    std::string time_str = get_current_timestamp_str();
    std::stringstream file_line_ss;
    file_line_ss << " (" << file << ":" << line << ")";

    std::string full_log_message = "[" + time_str + "] [" + level_to_string(level) + "] [" + log_source_ + ":" + std::to_string(log_counter_) + "] " +
                                   message + file_line_ss.str();

    {
        std::lock_guard<std::mutex> buffer_lock(buffer_mutex); 
        if (m_guiLogTextEdit) {
            QMetaObject::invokeMethod(m_guiLogTextEdit, "append", Qt::QueuedConnection,
                                      Q_ARG(QString, QString::fromStdString(full_log_message)));
        } else {
            initial_log_buffer.push_back(full_log_message);
        }
    }
    
    if (file_stream_.is_open()) {
        file_stream_ << full_log_message << std::endl;
    }
}

void Logger::log_error_to_cerr(LogLevel level, const std::string& message, const char* file, int line) {
    if (level > level_) {
        return;
    }

    std::lock_guard<std::mutex> lock(mutex_); 

    log_counter_++; 

    std::string time_str = get_current_timestamp_str();
    std::stringstream file_line_ss;
    file_line_ss << " (" << file << ":" << line << ")";

    std::string full_log_message = "[" + time_str + "] [" + level_to_string(level) + "] [" + log_source_ + ":" + std::to_string(log_counter_) + "] " +
                                   message + file_line_ss.str();

    {
        std::lock_guard<std::mutex> buffer_lock(buffer_mutex); 
        if (m_guiLogTextEdit) {
            QMetaObject::invokeMethod(m_guiLogTextEdit, "append", Qt::QueuedConnection,
                                      Q_ARG(QString, QString::fromStdString(full_log_message)));
        } else {
            initial_log_buffer.push_back(full_log_message);
        }
    }

    if (file_stream_.is_open()) {
        file_stream_ << full_log_message << std::endl;
    }
} 
--- C:\Users\aib\CerebrumLux\src\core\logger.h --- 
#ifndef CEREBRUM_LUX_LOGGER_H
#define CEREBRUM_LUX_LOGGER_H

#include <string>
#include <fstream>
#include <sstream>
#include <mutex>
#include <vector> 
#include <iostream> 
#include "enums.h" 
#include <QTextEdit> 

class Logger {
public:
    static Logger& get_instance(); 

    void init(LogLevel level, const std::string& log_file_path = "", const std::string& log_source = "SYSTEM"); 
    
    void log(LogLevel level, const std::string& message, const char* file, int line);
    void log_error_to_cerr(LogLevel level, const std::string& message, const char* file, int line);


    Logger(const Logger&) = delete; 
    void operator=(const Logger&) = delete; 

    LogLevel get_level() const;
    std::string level_to_string(LogLevel level) const; 

    void set_log_panel_text_edit(QTextEdit* textEdit);

private:
    Logger() : level_(LogLevel::INFO), m_guiLogTextEdit(nullptr), log_counter_(0), log_source_("SYSTEM") {} 
    ~Logger(); 

    LogLevel level_;
    std::ofstream file_stream_; 
    std::mutex mutex_; 

    QTextEdit* m_guiLogTextEdit;
    std::vector<std::string> initial_log_buffer;
    std::mutex buffer_mutex; 

    unsigned long long log_counter_; 
    std::string log_source_; 
};

#define LOG_INIT(log_file_name, log_source_name) Logger::get_instance().init(LogLevel::INFO, log_file_name, log_source_name)

#define LOG(level, message) \
    do { \
        if (Logger::get_instance().get_level() >= level) { \
            std::stringstream ss_log_stream; \
            ss_log_stream << message; \
            Logger::get_instance().log(level, ss_log_stream.str(), __FILE__, __LINE__); \
        } \
    } while(0)

#define LOG_DEFAULT(level, message) \
    do { \
        if (Logger::get_instance().get_level() >= level) { \
            std::stringstream log_ss_internal; \
            log_ss_internal << message; \
            Logger::get_instance().log(level, log_ss_internal.str(), __FILE__, __LINE__); \
        } \
    } while(0)

#define LOG_ERROR_CERR(level, message) \
    do { \
        if (Logger::get_instance().get_level() >= level) { \
            std::stringstream log_ss_internal_err; \
            log_ss_internal_err << message; \
            Logger::get_instance().log_error_to_cerr(level, log_ss_internal_err.str(), __FILE__, __LINE__); \
        } \
    } while(0)

#endif // CEREBRUM_LUX_LOGGER_H 
--- C:\Users\aib\CerebrumLux\src\core\utils.cpp --- 
#include "utils.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include <iostream>  // std::cout, std::cerr iÃ§in
#include <numeric>   // std::accumulate iÃ§in
#include <cmath>     // std::sqrt, std::log10, std::fabs, std::exp iÃ§in
#include <algorithm> // std::min, std::max, std::tolower iÃ§in
#include "../core/logger.h" // LOG_DEFAULT iÃ§in
// <locale>, <codecvt>, <stringapiset.h> utils.h'de dahil edildiÄŸi iÃ§in burada tekrar gerekmez

// OpenSSL BaÅŸlÄ±klarÄ± (Sadece utils.cpp iÃ§inde dahil ediliyor)
#include <openssl/crypto.h> // En genel OpenSSL baÅŸlÄ±ÄŸÄ±, diÄŸerlerini de iÃ§erebilir
#include <openssl/ssl.h>    // BazÄ± BIO fonksiyonlarÄ± SSL'e baÄŸÄ±mlÄ± olabilir
#include <openssl/evp.h>    // EVP_* fonksiyonlarÄ± iÃ§in (encrypt/decrypt iÃ§in)
#include <openssl/rand.h>   // RAND_bytes iÃ§in
#include <openssl/err.h>    // ERR_print_errors_fp iÃ§in
#include <openssl/bio.h>    // BIO_s_mem, BIO_new_mem_buf, BIO_free_all iÃ§in
#include <openssl/buffer.h>   // <-- BIO_get_buf_mem burada

extern "C" {
// OpenSSL BaÅŸlÄ±klarÄ± (Sadece utils.cpp iÃ§inde dahil ediliyor)
#include <openssl/crypto.h> // En genel OpenSSL baÅŸlÄ±ÄŸÄ±, diÄŸerlerini de iÃ§erebilir
#include <openssl/ssl.h>    // BazÄ± BIO fonksiyonlarÄ± SSL'e baÄŸÄ±mlÄ± olabilir
#include <openssl/evp.h>    // EVP_* fonksiyonlarÄ± iÃ§in (encrypt/decrypt iÃ§in)
#include <openssl/rand.h>   // RAND_bytes iÃ§in
#include <openssl/err.h>    // ERR_print_errors_fp iÃ§in
#include <openssl/bio.h>    // BIO_s_mem, BIO_new_mem_buf, BIO_free_all iÃ§in
#include <openssl/buffer.h> // BUF_MEM ve BIO_get_buf_mem iÃ§in KRÄ°TÄ°K!
}

#include <iostream>  // std::cout, std::cerr iÃ§in
#include <numeric>   // std::accumulate iÃ§in
#include <cmath>     // std::sqrt, std::log10, std::fabs, std::exp iÃ§in
#include <algorithm> // std::min, std::max, std::tolower iÃ§in
#include "../core/logger.h" // LOG_DEFAULT iÃ§in
// <locale>, <codecvt>, <stringapiset.h> utils.h'de dahil edildiÄŸi iÃ§in burada tekrar gerekmez

#include <iostream>  // std::cout, std::cerr iÃ§in
#include <numeric>   // std::accumulate iÃ§in
#include <cmath>     // std::sqrt, std::log10, std::fabs, std::exp iÃ§in
#include <algorithm> // std::min, std::max, std::tolower iÃ§in
#include "../core/logger.h" // LOG_DEFAULT iÃ§in
// <locale>, <codecvt>, <stringapiset.h> utils.h'de dahil edildiÄŸi iÃ§in burada tekrar gerekmez

// === SafeRNG ImplementasyonlarÄ± ===

// Kurucu: DoÄŸrudan sistem saatini seed olarak kullan (random_device kaldÄ±rÄ±ldÄ±)
SafeRNG::SafeRNG() {
    generator.seed(std::chrono::high_resolution_clock::now().time_since_epoch().count());
    // LOG_DEFAULT burada kullanÄ±lamaz Ã§Ã¼nkÃ¼ Logger henÃ¼z baÅŸlatÄ±lmamÄ±ÅŸ olabilir.
    // main'de Logger baÅŸlatÄ±ldÄ±ktan sonra SafeRNG'nin baÅŸlatÄ±ldÄ±ÄŸÄ±ndan emin olunmalÄ±.
}

// Tekil (singleton) eriÅŸim
SafeRNG& SafeRNG::get_instance() {
    static SafeRNG instance;
    return instance;
}

// Rastgele sayÄ± Ã¼reteci nesnesini dÃ¶ndÃ¼rÃ¼r
std::mt19937& SafeRNG::get_generator() {
    return generator;
}


// === YardÄ±mcÄ± Fonksiyon ImplementasyonlarÄ± (tÃ¼mÃ¼ std::string tabanlÄ±) ===

// Mevcut zamanÄ± formatlÄ± bir string olarak dÃ¶ndÃ¼ren yardÄ±mcÄ± fonksiyon
std::string get_current_timestamp_str() {
    auto now = std::chrono::system_clock::now();
    auto in_time_t = std::chrono::system_clock::to_time_t(now);
    
    std::stringstream ss;
#ifdef _WIN32
    struct tm buf;
    localtime_s(&buf, &in_time_t); // GÃ¼venli localtime (Windows)
    ss << std::put_time(&buf, "%Y-%m-%d %H:%M:%S"); 
#else
    ss << std::put_time(std::localtime(&in_time_t), "%Y-%m-%d %H:%M:%S"); // Standart localtime
#endif
    return ss.str();
}

// intent_to_string fonksiyonunun tanÄ±mÄ±
std::string intent_to_string(UserIntent intent) {
    switch (intent) {
        case UserIntent::None: return "HiÃ§biri";
        case UserIntent::Unknown: return "Bilinmiyor";
        case UserIntent::FastTyping: return "HÄ±zlÄ± Yazma Modu";
        case UserIntent::Editing: return "DÃ¼zenleme Modu";
        case UserIntent::IdleThinking: return "DÃ¼ÅŸÃ¼nme/Ara Verme Modu";
        case UserIntent::Programming: return "Programlama Modu";
        case UserIntent::Gaming: return "Oyun Modu";
        case UserIntent::MediaConsumption: return "Medya TÃ¼ketimi Modu";
        case UserIntent::CreativeWork: return "YaratÄ±cÄ± Ã‡alÄ±ÅŸma Modu";
        case UserIntent::Research: return "AraÅŸtÄ±rma Modu";
        case UserIntent::Communication: return "Ä°letiÅŸim Modu";
        case UserIntent::VideoEditing: return "Video DÃ¼zenleme";
        case UserIntent::Browsing: return "Ä°nternette Gezinme";
        case UserIntent::Reading: return "Okuma";
        case UserIntent::GeneralInquiry: return "Genel Sorgulama";
        case UserIntent::Count: return "Niyet SayÄ±sÄ±";
        default: return "TanÄ±mlanmamÄ±ÅŸ Niyet";
    }
}

// abstract_state_to_string fonksiyonunun tanÄ±mÄ±
std::string abstract_state_to_string(AbstractState state) {
    switch (state) {
        case AbstractState::None: return "HiÃ§biri";
        case AbstractState::HighProductivity: return "YÃ¼ksek Ãœretkenlik";
        case AbstractState::LowProductivity: return "DÃ¼ÅŸÃ¼k Ãœretkenlik";
        case AbstractState::Focused: return "OdaklanmÄ±ÅŸ";
        case AbstractState::Distracted: return "Dikkati DaÄŸÄ±lmÄ±ÅŸ";
        case AbstractState::PowerSaving: return "GÃ¼Ã§ Tasarrufu";
        case AbstractState::NormalOperation: return "Normal Ã‡alÄ±ÅŸma";
        case AbstractState::CreativeFlow: return "YaratÄ±cÄ± AkÄ±ÅŸ";
        case AbstractState::Debugging: return "Hata AyÄ±klama";
        case AbstractState::PassiveConsumption: return "Pasif TÃ¼ketim";
        case AbstractState::HardwareAnomaly: return "DonanÄ±m AnormalliÄŸi";
        case AbstractState::SeekingInformation: return "Bilgi ArayÄ±ÅŸÄ±";
        case AbstractState::SocialInteraction: return "Sosyal EtkileÅŸim";
        case AbstractState::HighPerformance: return "YÃ¼ksek Performans";
        case AbstractState::FaultyHardware: return "ArÄ±zalÄ± DonanÄ±m";
        case AbstractState::Count: return "Durum SayÄ±sÄ±";
        default: return "TanÄ±mlanmamÄ±ÅŸ Durum";
    }
}

// goal_to_string fonksiyonunun tanÄ±mÄ±
std::string goal_to_string(AIGoal goal) {
    switch (goal) {
        case AIGoal::None: return "Yok";
        case AIGoal::OptimizeProductivity: return "ÃœretkenliÄŸi Optimize Etmek";
        case AIGoal::MaximizeBatteryLife: return "Batarya Ã–mrÃ¼nÃ¼ Maksimuma Ã‡Ä±karmak";
        case AIGoal::ReduceDistractions: return "Dikkat DaÄŸÄ±tÄ±cÄ±larÄ± Azaltmak";
        case AIGoal::EnhanceCreativity: return "YaratÄ±cÄ±lÄ±ÄŸÄ± ArtÄ±rmak";
        case AIGoal::ImproveGamingExperience: return "Oyun Deneyimini Ä°yileÅŸtirmek";
        case AIGoal::FacilitateResearch: return "AraÅŸtÄ±rmayÄ± KolaylaÅŸtÄ±rmak";
        case AIGoal::SelfImprovement: return "Kendi Kendini GeliÅŸtirmek";
        case AIGoal::Count: return "Hedef SayÄ±sÄ±";
        default: return "Bilinmeyen Hedef";
    }
}

// YENÄ°: action_to_string fonksiyonunun tanÄ±mÄ±
std::string action_to_string(AIAction action) {
    switch (action) {
        case AIAction::DisableSpellCheck: return "Yazim denetimini devre disi birak";
        case AIAction::EnableCustomDictionary: return "Ozel sozlÃ¼gÃ¼ etkinlestir";
        case AIAction::ShowUndoHistory: return "Geri alma geÃ§misini goster";
        case AIAction::CompareVersions: return "Versiyonlari karsilastir";
        case AIAction::DimScreen: return "Ekrani karart";
        case AIAction::MuteNotifications: return "Bildirimleri sessize al";
        case AIAction::LaunchApplication: return "Uygulama baslat";
        case AIAction::OpenFile: return "Dosya aÃ§";
        case AIAction::SetReminder: return "Hatirlatici kur";
        case AIAction::SimulateOSAction: return "OS eylemi simule et"; 
        case AIAction::SuggestBreak: return "Ara vermeyi Ã¶ner";
        case AIAction::OptimizeForGaming: return "Oyun performansÄ± iÃ§in optimize et";
        case AIAction::EnableFocusMode: return "Odaklanma modunu etkinleÅŸtir";
        case AIAction::AdjustAudioVolume: return "Ses seviyesini ayarla";
        case AIAction::OpenDocumentation: return "DokÃ¼mantasyon aÃ§";
        case AIAction::SuggestSelfImprovement: return "Kendi kendini geliÅŸtirme Ã¶nerisi"; 
        case AIAction::None: return "HiÃ§bir eylem Ã¶nerisi yok"; 
        case AIAction::Count: return "Eylem Sayisi"; 
        default: return "Tanimlanmamis eylem"; 
    }
}

// SimÃ¼lasyon amaÃ§lÄ± basit bir string hash fonksiyonu
unsigned short hash_string(const std::string& s) {
    unsigned short hash = 0;
    for (char c : s) {
        hash = (hash * 31 + c) % 65535; 
    }
    return hash;
}

// std::wstring'den std::string'e dÃ¶nÃ¼ÅŸtÃ¼rme yardÄ±mcÄ± fonksiyonu
std::string convert_wstring_to_string(const std::wstring& wstr) {
    if (wstr.empty()) return std::string();
#ifdef _WIN32
    int size_needed = WideCharToMultiByte(CP_UTF8, 0, wstr.c_str(), (int)wstr.length(), NULL, 0, NULL, NULL);
    std::string str_to(size_needed, 0); // allocate space
    WideCharToMultiByte(CP_UTF8, 0, wstr.c_str(), (int)wstr.length(), &str_to[0], size_needed, NULL, NULL);
    return str_to;
#else
    // POSIX uyumlu sistemler iÃ§in std::codecvt_utf8 (C++17'de deprecated)
    // veya daha modern alternatifler (Ã¶rn. iconv, utfcpp) kullanÄ±labilir.
    // Åžimdilik C++17 Ã¶ncesi veya uyarÄ±yÄ± tolere eden derleyiciler iÃ§in bu yaklaÅŸÄ±m.
    using convert_type = std::codecvt_utf8<wchar_t>;
    std::wstring_convert<convert_type, wchar_t> converter;
    return converter.to_bytes(wstr);
#endif
}

// YENÄ°: Base64 kodlama yardÄ±mcÄ± fonksiyonu (BIO ile OpenSSL kullanÄ±mÄ±)
/*
std::string base64_encode(const std::string& in) {
    BIO *b64, *bmem;
    BUF_MEM *bptr;

    b64 = BIO_new(BIO_f_base64());
    bmem = BIO_new(BIO_s_mem());
    b64 = BIO_push(b64, bmem);
    BIO_set_flags(b64, BIO_FLAGS_BASE64_NO_NL); // Yeni satÄ±r karakterlerini engelle
    BIO_write(b64, in.c_str(), static_cast<int>(in.length()));
    BIO_flush(b64);
    BIO_get_buf_mem(b64, &bptr); // BUF_MEM iÃ§in openssl/buffer.h gerekli

    std::string out(bptr->data, bptr->length);
    BIO_free_all(b64);
    return out;
}
*/
std::string base64_encode(const std::string& in) {
    BIO *b64, *bmem;
    BUF_MEM *bptr;

    b64 = BIO_new(BIO_f_base64());
    bmem = BIO_new(BIO_s_mem());
    b64 = BIO_push(b64, bmem);
    BIO_set_flags(b64, BIO_FLAGS_BASE64_NO_NL);

    BIO_write(b64, in.data(), static_cast<int>(in.size()));
    BIO_flush(b64);

    // Eski yÃ¶ntem:
    // BIO_get_buf_mem(b64, &bptr);
    // std::string out(bptr->data, bptr->length);

    // Yeni uyumlu yÃ¶ntem:
    char *data;
    long len = BIO_get_mem_data(bmem, &data);
    std::string out(data, len);

    BIO_free_all(b64);
    return out;
}


// YENÄ°: Base64 kod Ã§Ã¶zme yardÄ±mcÄ± fonksiyonu (BIO ile OpenSSL kullanÄ±mÄ±)
std::string base64_decode(const std::string& in) {
    BIO *b64, *bmem;
    char* buffer = nullptr;
    size_t length = 0;

    b64 = BIO_new(BIO_f_base64());
    bmem = BIO_new_mem_buf(in.c_str(), static_cast<int>(in.length()));
    b64 = BIO_push(b64, bmem);
    BIO_set_flags(b64, BIO_FLAGS_BASE64_NO_NL);

    length = in.length();
    buffer = (char*)OPENSSL_malloc(length + 1); // +1 null sonlandÄ±rma iÃ§in
    if (!buffer) {
        // LOG_DEFAULT burada kullanÄ±lamaz, Ã§Ã¼nkÃ¼ utils.cpp'nin logger'dan Ã¶nce derlenmesi gerekebilir.
        // Hata durumunda boÅŸ string dÃ¶ndÃ¼rmek yeterli.
        return "";
    }
    
    int decoded_len = BIO_read(b64, buffer, static_cast<int>(length));
    if (decoded_len < 0) {
        OPENSSL_free(buffer);
        BIO_free_all(b64);
        return "";
    }
    buffer[decoded_len] = '\0'; 

    std::string out(buffer, decoded_len);
    OPENSSL_free(buffer);
    BIO_free_all(b64);
    return out;
}


// MessageQueue sÄ±nÄ±fÄ± implementasyonlarÄ±
void MessageQueue::enqueue(MessageData data) {
    {
        std::lock_guard<std::mutex> lock(mutex);
        queue.push(data);
    }
    cv.notify_one();
}

MessageData MessageQueue::dequeue() {
    std::unique_lock<std::mutex> lock(mutex);
    cv.wait(lock, [this]{ return !queue.empty(); });
    
    MessageData data = queue.front();
    queue.pop();
    return data;
}

bool MessageQueue::isEmpty() {
    std::lock_guard<std::mutex> lock(mutex);
    return queue.empty();
} 
--- C:\Users\aib\CerebrumLux\src\core\utils.h --- 
#ifndef CEREBRUM_LUX_UTILS_H
#define CEREBRUM_LUX_UTILS_H

#include <string>    // std::string iÃ§in
#include <sstream>   // std::stringstream iÃ§in
#include <chrono>    // std::chrono iÃ§in (timestamp)
#include <iomanip>   // std::put_time iÃ§in
#include <ctime>     // std::localtime iÃ§in
#include <cerrno>    // errno iÃ§in
#include <algorithm> // std::tolower (char versiyonu iÃ§in)
#include <locale>    // std::locale iÃ§in (sadece convert_wstring_to_string'de kullanÄ±lacak)
#include <codecvt>   // std::wstring_convert iÃ§in (convert_wstring_to_string'de kullanÄ±lacak)
#include <random>    // YENÄ°: std::random_device, std::mt19937 iÃ§in

// OpenSSL BaÅŸlÄ±klarÄ± (utils.h iÃ§inde dahil ediliyor)
#include <openssl/crypto.h>
#include <openssl/buffer.h>

#ifdef _WIN32
#include <stringapiset.h> // WideCharToMultiByte iÃ§in (Windows'a Ã¶zel)
#endif

// Mesaj sistemi iÃ§in (eÄŸer MessageData ve MessageType burada tanÄ±mlÄ±ysa)
#include <queue>
#include <mutex>
#include <condition_variable>
#include "enums.h" // MessageData, MessageType, UserIntent, AbstractState, AIGoal, LogLevel iÃ§in

// YENÄ°: Base64 encode/decode prototipleri (global fonksiyonlar olarak)
std::string base64_encode(const std::string& in);
std::string base64_decode(const std::string& in);

// YENÄ°: SafeRNG sÄ±nÄ±fÄ± tanÄ±mÄ± (tekil rastgele sayÄ± Ã¼reteci)
class SafeRNG {
public:
    static SafeRNG& get_instance(); // Tekil (singleton) eriÅŸim
    std::mt19937& get_generator(); // Rastgele sayÄ± Ã¼reteci nesnesini dÃ¶ndÃ¼rÃ¼r

    SafeRNG(const SafeRNG&) = delete; // KopyalamayÄ± engelle
    void operator=(const SafeRNG&) = delete; // AtamayÄ± engelle

private:
    SafeRNG(); // Kurucunun implementasyonu utils.cpp'ye taÅŸÄ±ndÄ±
    std::mt19937 generator; // Rastgele sayÄ± Ã¼reteci
};

// YardÄ±mcÄ± fonksiyon bildirimleri (tÃ¼mÃ¼ std::string tabanlÄ±)
std::string get_current_timestamp_str();
std::string intent_to_string(UserIntent intent);
std::string abstract_state_to_string(AbstractState state);
std::string goal_to_string(AIGoal goal);
std::string action_to_string(AIAction action); // YENÄ°: action_to_string bildirimi eklendi
unsigned short hash_string(const std::string& s); // ArtÄ±k std::string alÄ±yor

// std::wstring'den std::string'e dÃ¶nÃ¼ÅŸtÃ¼rme yardÄ±mcÄ± fonksiyonu
// Bu, sadece harici std::wstring'ler geldiÄŸinde veya bir std::wstring literalini dÃ¶nÃ¼ÅŸtÃ¼rmek gerektiÄŸinde kullanÄ±lacaktÄ±r.
// MÃ¼mkÃ¼n olduÄŸunca doÄŸrudan std::string kullanmayÄ± hedefliyoruz.
std::string convert_wstring_to_string(const std::wstring& wstr);

// MessageQueue sÄ±nÄ±fÄ±nÄ±n bildirimi (eÄŸer utils.h iÃ§inde ise)
class MessageQueue {
public:
    void enqueue(MessageData data);
    MessageData dequeue();
    bool isEmpty();

private:
    std::queue<MessageData> queue;
    std::mutex mutex;
    std::condition_variable cv;
};


#endif // CEREBRUM_LUX_UTILS_H 
--- C:\Users\aib\CerebrumLux\src\data_models\dynamic_sequence.cpp --- 
#include "dynamic_sequence.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../sensors/atomic_signal.h" // AtomicSignal iÃ§in
#include "../brain/autoencoder.h" // CryptofigAutoencoder iÃ§in
#include "../core/logger.h"      // LOG makrosu iÃ§in
#include "../core/utils.h"       // DiÄŸer yardÄ±mcÄ± fonksiyonlar iÃ§in
#include <numeric>   // std::accumulate iÃ§in
#include <cmath>     // std::sqrt, std::log10, std::fabs iÃ§in
#include <algorithm> // std::min, std::max iÃ§in
#include <iostream>  // std::cout, std::cerr iÃ§in
#include <iomanip>   // std::fixed, std::setprecision iÃ§in
#include <sstream>   // std::stringstream iÃ§in
#include <map>       // YENÄ°: std::map iÃ§in eklendi


// === DynamicSequence Implementasyonlari ===

DynamicSequence::DynamicSequence() : 
    last_updated_us(0), avg_keystroke_interval(0.0f),
    keystroke_variability(0.0f), alphanumeric_ratio(0.0f), control_key_frequency(0.0f),
    mouse_movement_intensity(0.0f), mouse_click_frequency(0.0f), avg_brightness(0.0f),
    battery_status_change(0.0f), network_activity_level(0.0f),
    current_app_hash(0), 
    current_battery_percentage(0), 
    current_battery_charging(false),
    current_display_on(false), 
    current_network_active(false),
    // Yeni eklenen sensÃ¶r verisi alanlarÄ± baÅŸlatÄ±lÄ±yor
    avg_audio_level_db(0.0f),
    avg_audio_frequency_hz(0.0f),
    speech_detection_ratio(0.0f),
    dominant_audio_environment_hash(0),
    avg_ambient_light_lux(0.0f),
    face_detection_ratio(0.0f),
    motion_detection_ratio(0.0f),
    avg_object_count(0),
    dominant_emotion_hash(0)
    {}


// update_from_signals fonksiyonu CryptofigAutoencoder referansÄ± alacak ÅŸekilde gÃ¼ncellendi
void DynamicSequence::update_from_signals(const std::deque<AtomicSignal>& signal_buffer, long long current_time_us, unsigned short app_hash, CryptofigAutoencoder& autoencoder) {
    LOG_DEFAULT(LogLevel::DEBUG, "DynamicSequence::update_from_signals: Basladi. Buffer boyutu: " << signal_buffer.size() << "\n");
    last_updated_us = current_time_us;
    current_app_hash = app_hash; 

    if (signal_buffer.empty()) {
        LOG_DEFAULT(LogLevel::DEBUG, "DynamicSequence::update_from_signals: Buffer boÅŸ, sÄ±fÄ±rlanÄ±yor.\n");
        statistical_features_vector.clear();
        latent_cryptofig_vector.clear();
        // Yeni eklenen alanlarÄ± da sÄ±fÄ±rla
        avg_audio_level_db = 0.0f; avg_audio_frequency_hz = 0.0f; speech_detection_ratio = 0.0f; dominant_audio_environment_hash = 0;
        avg_ambient_light_lux = 0.0f; face_detection_ratio = 0.0f; motion_detection_ratio = 0.0f; avg_object_count = 0; dominant_emotion_hash = 0;
        return;
    }

    std::vector<long long> intervals;
    int alphanumeric_count = 0;
    int control_modifier_count = 0; 
    int total_keyboard_press_events = 0;
    long long last_press_timestamp = 0; 

    long long total_mouse_movement = 0;
    int mouse_move_count = 0;
    int mouse_click_count = 0;
    int mouse_total_events_in_buffer = 0; 
    int last_mouse_x_in_buffer = -1; 
    int last_mouse_y_in_buffer = -1; 
    LOG_DEFAULT(LogLevel::DEBUG, "DynamicSequence::update_from_signals: Fare metrikleri baÅŸlangÄ±Ã§ deÄŸerleri ayarlandÄ±.\n"); 

    int total_brightness_sum = 0; 
    int brightness_sample_count = 0;

    int total_battery_change_sum = 0; 
    int battery_sample_count = 0;
    unsigned char last_battery_percentage_val = 0; 

    long long total_bandwidth_sum = 0; 
    int network_sample_count = 0;

    // Mikrofon ve Kamera iÃ§in yeni toplama deÄŸiÅŸkenleri
    float total_audio_level_db_sum = 0.0f;
    float total_audio_frequency_hz_sum = 0.0f;
    int audio_sample_count = 0;
    int speech_detected_count_total = 0;
    std::map<unsigned short, int> audio_environment_counts; // dominant_audio_environment_hash iÃ§in

    float total_ambient_light_lux_sum = 0.0f;
    int camera_sample_count = 0;
    int face_detected_count_total = 0;
    int motion_detected_count_total = 0;
    unsigned short total_object_count_sum = 0;
    std::map<unsigned short, int> emotion_counts; // dominant_emotion_hash iÃ§in


    for (size_t i = 0; i < signal_buffer.size(); ++i) {
        const AtomicSignal& current_sig = signal_buffer[i];

        LOG_DEFAULT(LogLevel::TRACE, "DynamicSequence::update_from_signals: Sinyal isleniyor (indeks " << i << ", tip: " << static_cast<int>(current_sig.sensor_type) << ")\n");

        if (current_sig.sensor_type == SensorType::Keyboard) {
            if (current_sig.event_type == KeyEventType::Press) {
                total_keyboard_press_events++;
                
                if (last_press_timestamp != 0) { 
                    intervals.push_back(current_sig.timestamp_us - last_press_timestamp);
                }
                last_press_timestamp = current_sig.timestamp_us; 
                
                if (current_sig.key_type == KeyType::Alphanumeric) { 
                    alphanumeric_count++;
                } else if (current_sig.key_type == KeyType::Control || current_sig.key_type == KeyType::Modifier) { 
                    control_modifier_count++;
                }
            }
        } else if (current_sig.sensor_type == SensorType::Mouse) {
            LOG_DEFAULT(LogLevel::TRACE, "DynamicSequence::update_from_signals: Fare sinyali isleniyor.\n");
            mouse_total_events_in_buffer++; 
            if (current_sig.mouse_event_type == 0) { 
                LOG_DEFAULT(LogLevel::TRACE, "DynamicSequence::update_from_signals: Fare hareket sinyali (x=" << current_sig.mouse_x << ", y=" << current_sig.mouse_y << ").\n");
                if (last_mouse_x_in_buffer != -1 && last_mouse_y_in_buffer != -1) { 
                    total_mouse_movement += (std::abs(current_sig.mouse_x - last_mouse_x_in_buffer) + std::abs(current_sig.mouse_y - last_mouse_y_in_buffer));
                    LOG_DEFAULT(LogLevel::TRACE, "DynamicSequence::update_from_signals: Toplam fare hareketi gÃ¼ncellendi: " << total_mouse_movement << ".\n");
                }
                mouse_move_count++;
            } else if (current_sig.mouse_event_type == 1) { 
                LOG_DEFAULT(LogLevel::TRACE, "DynamicSequence::update_from_signals: Fare tiklama sinyali (x=" << current_sig.mouse_x << ", y=" << current_sig.mouse_y << ", button=" << static_cast<int>(current_sig.mouse_button_state) << ").\n");
                mouse_click_count++;
            }
            last_mouse_x_in_buffer = current_sig.mouse_x;
            last_mouse_y_in_buffer = current_sig.mouse_y; 
            LOG_DEFAULT(LogLevel::TRACE, "DynamicSequence::update_from_signals: last_mouse_x_in_buffer ve last_mouse_y_in_buffer gÃ¼ncellendi.\n");            
        } else if (current_sig.sensor_type == SensorType::Display) {
            total_brightness_sum += current_sig.display_brightness;
            brightness_sample_count++;
            this->current_display_on = current_sig.display_on; // display_on bilgisini kaydet
        } else if (current_sig.sensor_type == SensorType::Battery) {
            if (battery_sample_count > 0) { 
                total_battery_change_sum += std::abs(current_sig.battery_percentage - last_battery_percentage_val);
            }
            last_battery_percentage_val = current_sig.battery_percentage; 
            battery_sample_count++;
            this->current_battery_percentage = current_sig.battery_percentage;
            this->current_battery_charging = current_sig.battery_charging;

        } else if (current_sig.sensor_type == SensorType::Network) {
            total_bandwidth_sum += current_sig.network_bandwidth_estimate;
            network_sample_count++;
            this->current_network_active = current_sig.network_active; // network_active bilgisini kaydet
        } else if (current_sig.sensor_type == SensorType::Microphone) { // YENÄ°: Mikrofon sinyallerini iÅŸle
            total_audio_level_db_sum += current_sig.audio_level_db;
            total_audio_frequency_hz_sum += current_sig.audio_frequency_hz;
            if (current_sig.speech_detected) {
                speech_detected_count_total++;
            }
            audio_environment_counts[current_sig.audio_environment_hash]++;
            audio_sample_count++;
        } else if (current_sig.sensor_type == SensorType::Camera) { // YENÄ°: Kamera sinyallerini iÅŸle
            total_ambient_light_lux_sum += current_sig.ambient_light_lux;
            if (current_sig.face_detected) {
                face_detected_count_total++;
            }
            if (current_sig.motion_detected) {
                motion_detected_count_total++;
            }
            total_object_count_sum += current_sig.object_count;
            emotion_counts[current_sig.emotion_hash]++;
            camera_sample_count++;
        }
    } 
    LOG_DEFAULT(LogLevel::DEBUG, "DynamicSequence::update_from_signals: Sinyal iÅŸleme dÃ¶ngÃ¼sÃ¼ bitti.\n");

    if (!intervals.empty()) {
        long long sum_intervals = std::accumulate(intervals.begin(), intervals.end(), 0LL);
        avg_keystroke_interval = static_cast<float>(sum_intervals) / intervals.size();
        
        long long sum_sq_diff = 0;
        for (long long interval : intervals) {
            sum_sq_diff += (interval - avg_keystroke_interval) * (interval - avg_keystroke_interval);
        }
        keystroke_variability = static_cast<float>(std::sqrt(static_cast<double>(sum_sq_diff) / intervals.size()));
    } else {
        avg_keystroke_interval = 0.0f;
        keystroke_variability = 0.0f;
    }

    if (total_keyboard_press_events > 0) {
        alphanumeric_ratio = static_cast<float>(alphanumeric_count) / total_keyboard_press_events;
        control_key_frequency = static_cast<float>(control_modifier_count) / total_keyboard_press_events;
    } else {
        alphanumeric_ratio = 0.0f;
        control_key_frequency = 0.0f;
    }

    mouse_movement_intensity = (mouse_move_count > 0) ? static_cast<float>(total_mouse_movement) / mouse_move_count : 0.0f;
    mouse_click_frequency = (total_keyboard_press_events + mouse_move_count + mouse_click_count > 0) ? static_cast<float>(mouse_click_count) / (total_keyboard_press_events + mouse_move_count + mouse_click_count) : 0.0f; 

    avg_brightness = (brightness_sample_count > 0) ? static_cast<float>(total_brightness_sum) / brightness_sample_count : 0.0f;

    battery_status_change = (battery_sample_count > 1) ? static_cast<float>(total_battery_change_sum) / (battery_sample_count - 1) : 0.0f; 
    battery_status_change /= 100.0f;

    network_activity_level = (network_sample_count > 0) ? static_cast<float>(total_bandwidth_sum) / network_sample_count : 0.0f;

    // YENÄ°: Mikrofon ve Kamera metriklerinin hesaplanmasÄ±
    avg_audio_level_db = (audio_sample_count > 0) ? total_audio_level_db_sum / audio_sample_count : 0.0f;
    avg_audio_frequency_hz = (audio_sample_count > 0) ? total_audio_frequency_hz_sum / audio_sample_count : 0.0f;
    speech_detection_ratio = (audio_sample_count > 0) ? static_cast<float>(speech_detected_count_total) / audio_sample_count : 0.0f;
    // En baskÄ±n ses ortamÄ±nÄ± bul
    dominant_audio_environment_hash = 0;
    int max_audio_env_count = 0;
    for (const auto& pair : audio_environment_counts) {
        if (pair.second > max_audio_env_count) {
            max_audio_env_count = pair.second;
            dominant_audio_environment_hash = pair.first;
        }
    }

    avg_ambient_light_lux = (camera_sample_count > 0) ? total_ambient_light_lux_sum / camera_sample_count : 0.0f;
    face_detection_ratio = (camera_sample_count > 0) ? static_cast<float>(face_detected_count_total) / camera_sample_count : 0.0f;
    motion_detection_ratio = (camera_sample_count > 0) ? static_cast<float>(motion_detected_count_total) / camera_sample_count : 0.0f;
    avg_object_count = (camera_sample_count > 0) ? static_cast<unsigned short>(static_cast<float>(total_object_count_sum) / camera_sample_count + 0.5f) : 0; // Yuvarlama
    // En baskÄ±n duyguyu bul
    dominant_emotion_hash = 0;
    int max_emotion_count = 0;
    for (const auto& pair : emotion_counts) {
        if (pair.second > max_emotion_count) {
            max_emotion_count = pair.second;
            dominant_emotion_hash = pair.first;
        }
    }


    const float MAX_INTERVAL_LOG_BASE_MS = 10000.0f; 
    const float MAX_MOUSE_MOVEMENT_FOR_NORM = 500.0f; 
    const float MAX_NETWORK_BANDWIDTH_FOR_NORM = 15000.0f; 
    const float MAX_AUDIO_LEVEL_DB_FOR_NORM = 90.0f; // -90dB (min) to 0dB (max)
    const float MAX_AUDIO_FREQ_HZ_FOR_NORM = 20000.0f;
    const float MAX_AMBIENT_LIGHT_LUX_FOR_NORM = 1000.0f; // Ä°Ã§/dÄ±ÅŸ mekan iÃ§in tipik bir Ã¼st limit
    const float MAX_OBJECT_COUNT_FOR_NORM = 5.0f; // Max beklenen nesne sayÄ±sÄ±


    float normalized_avg_interval = 0.0f;
    if (avg_keystroke_interval > 0) {
        normalized_avg_interval = std::min(1.0f, static_cast<float>(std::log10(avg_keystroke_interval / 1000.0f + 1)) / std::log10(MAX_INTERVAL_LOG_BASE_MS + 1));
    }

    float normalized_variability = 0.0f;
    if (keystroke_variability > 0) {
        normalized_variability = std::min(1.0f, static_cast<float>(std::log10(keystroke_variability / 1000.0f + 1)) / std::log10(MAX_INTERVAL_LOG_BASE_MS + 1));
    }

    // YENÄ°: Mikrofon ve Kamera metriklerinin normalize edilmesi
    float normalized_audio_level = std::min(1.0f, (avg_audio_level_db + MAX_AUDIO_LEVEL_DB_FOR_NORM) / MAX_AUDIO_LEVEL_DB_FOR_NORM); // -90dB'yi 0'a, 0dB'yi 1'e Ã§evir
    float normalized_audio_freq = std::min(1.0f, avg_audio_frequency_hz / MAX_AUDIO_FREQ_HZ_FOR_NORM);
    float normalized_ambient_light = std::min(1.0f, avg_ambient_light_lux / MAX_AMBIENT_LIGHT_LUX_FOR_NORM);
    float normalized_object_count = std::min(1.0f, static_cast<float>(avg_object_count) / MAX_OBJECT_COUNT_FOR_NORM);
    // Hash deÄŸerlerini 0-1 aralÄ±ÄŸÄ±na normalize et (maksimum unsigned short deÄŸeri 65535)
    float normalized_audio_env_hash = static_cast<float>(dominant_audio_environment_hash) / 65535.0f;
    float normalized_emotion_hash = static_cast<float>(dominant_emotion_hash) / 65535.0f;


    // statistical_features_vector dolduruluyor (YENÄ° SENSÃ–R VERÄ°LERÄ° EKLENDÄ°)
    statistical_features_vector.assign({
        normalized_avg_interval,                        // Klavye 0
        normalized_variability,                         // Klavye 1
        alphanumeric_ratio,                             // Klavye 2
        control_key_frequency,                          // Klavye 3
        std::min(1.0f, mouse_movement_intensity / MAX_MOUSE_MOVEMENT_FOR_NORM), // Fare 4
        mouse_click_frequency,                          // Fare 5 (zaten 0-1 arasi)
        avg_brightness / 255.0f,                        // Ekran 6 (0-255'i 0-1'e normalize et)
        battery_status_change,                          // Batarya 7 (Zaten 0-1'e normalize edildi, tekrar bÃ¶lme!)
        std::min(1.0f, network_activity_level / MAX_NETWORK_BANDWIDTH_FOR_NORM), // AÄŸ 8
        static_cast<float>(current_app_hash) / 65535.0f, // Uygulama 9 (hash'i 0-1'e normalize et)
        // YENÄ° MÄ°KROFON Ã–ZELLÄ°KLERÄ° (10, 11, 12, 13)
        normalized_audio_level,                         // Mikrofon 10
        normalized_audio_freq,                          // Mikrofon 11
        speech_detection_ratio,                         // Mikrofon 12
        normalized_audio_env_hash,                      // Mikrofon 13
        // YENÄ° KAMERA Ã–ZELLÄ°KLERÄ° (14, 15, 16, 17)
        normalized_ambient_light,                       // Kamera 14
        face_detection_ratio,                           // Kamera 15
        motion_detection_ratio,                         // Kamera 16
        normalized_object_count,                        // Kamera 17
        normalized_emotion_hash                         // Kamera 18
    });

    // Autoencoder kullanÄ±larak latent kriptofig Ã¼retiliyor
    if (statistical_features_vector.size() != CryptofigAutoencoder::INPUT_DIM) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "DynamicSequence::update_from_signals: statistical_features_vector boyutu ( " << statistical_features_vector.size() << ") CryptofigAutoencoder::INPUT_DIM (" << CryptofigAutoencoder::INPUT_DIM << ") ile uyuÅŸmuyor! Autoencoder iÅŸlemi atlanÄ±yor.\n");
        latent_cryptofig_vector.assign(CryptofigAutoencoder::LATENT_DIM, 0.0f); // Latent vektÃ¶rÃ¼ sÄ±fÄ±rla
    } else {
        latent_cryptofig_vector = autoencoder.encode(statistical_features_vector);
        // Hata durumunda Autoencoder'Ä±n aÄŸÄ±rlÄ±klarÄ±nÄ± ayarla (heuristik Ã¶ÄŸrenme)
        autoencoder.adjust_weights_on_error(statistical_features_vector, 0.01f); // Ã–ÄŸrenme oranÄ± Ã¶rnek
    }

    LOG_DEFAULT(LogLevel::DEBUG, "DynamicSequence::update_from_signals: Bitti. Cryptofig vektoru olusturuldu.\n");
} 
--- C:\Users\aib\CerebrumLux\src\data_models\dynamic_sequence.h --- 
#ifndef CEREBRUM_LUX_DYNAMIC_SEQUENCE_H
#define CEREBRUM_LUX_DYNAMIC_SEQUENCE_H

#include <vector>
#include <deque>
#include <chrono>
#include "../core/enums.h"    // Enumlar iÃ§in
#include "../core/utils.h"    // For convert_wstring_to_string (if needed elsewhere)
#include "../brain/autoencoder.h" // CryptofigAutoencoder iÃ§in ileri bildirim (sadece bildirim iÃ§in)
#include "../sensors/atomic_signal.h" // AtomicSignal'Ä±n tam tanÄ±mÄ± iÃ§in EKLEDÄ°M

// Ä°leri bildirim (CryptofigAutoencoder iÃ§in hala geÃ§erli, Ã§Ã¼nkÃ¼ sadece referansÄ± kullanÄ±lÄ±yor)
class CryptofigAutoencoder; 

// *** DynamicSequence: Niyet paternlerinin tasiyicisi (Bizim 'Fuzyon Kriptofig' prototipimiz) ***
struct DynamicSequence { 
    std::vector<float> statistical_features_vector; // Ä°statistiksel Ã¶zellikleri tutacak vektÃ¶r (Ã¶nceki cryptofig_vector)
    std::vector<float> latent_cryptofig_vector;     // Autoencoder tarafÄ±ndan Ã¼retilen dÃ¼ÅŸÃ¼k boyutlu, latent kriptofig
    long long last_updated_us;             
    
    float avg_keystroke_interval;          
    float keystroke_variability;           
    float alphanumeric_ratio;              
    float control_key_frequency;           
    
    float mouse_movement_intensity; 
    float mouse_click_frequency;    
    float avg_brightness;           
    float battery_status_change;    
    float network_activity_level;   

    unsigned short current_app_hash;       

    unsigned char current_battery_percentage; 
    bool current_battery_charging;
    bool current_display_on;      // Ekran aÃ§Ä±k/kapalÄ± durumu
    bool current_network_active;  // AÄŸ baÄŸlantÄ±sÄ± aktif/pasif durumu

    // YENÄ° EKLENECEK SENSÃ–R VERÄ°LERÄ° Ä°Ã‡Ä°N ALANLAR
    float avg_audio_level_db;
    float avg_audio_frequency_hz;
    float speech_detection_ratio; // buffer iÃ§inde konuÅŸma algÄ±lanan sinyal oranÄ±
    unsigned short dominant_audio_environment_hash; // buffer iÃ§indeki en baskÄ±n ses ortamÄ±

    float avg_ambient_light_lux;
    float face_detection_ratio; // buffer iÃ§inde yÃ¼z algÄ±lanan sinyal oranÄ±
    float motion_detection_ratio; // buffer iÃ§inde hareket algÄ±lanan sinyal oranÄ±
    unsigned short avg_object_count;
    unsigned short dominant_emotion_hash; // buffer iÃ§indeki en baskÄ±n duygu

    DynamicSequence();
    // update_from_signals metodu CryptofigAutoencoder referansÄ± alacak ÅŸekilde gÃ¼ncellendi
    void update_from_signals(const std::deque<AtomicSignal>& signal_buffer, long long current_time_us, unsigned short app_hash, CryptofigAutoencoder& autoencoder);
};

#endif // CEREBRUM_LUX_DYNAMIC_SEQUENCE_H 
--- C:\Users\aib\CerebrumLux\src\data_models\sequence_manager.cpp --- 
#include "sequence_manager.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/logger.h"      // LOG makrosu iÃ§in
#include "../core/utils.h"       // DiÄŸer yardÄ±mcÄ± fonksiyonlar iÃ§in
#include "../sensors/atomic_signal.h" // AtomicSignal iÃ§in
#include "../brain/cryptofig_processor.h" // CryptofigProcessor iÃ§in
#include "../brain/autoencoder.h" // CryptofigAutoencoder iÃ§in (get_autoencoder Ã§aÄŸrÄ±sÄ± iÃ§in)
#include <iostream>  // std::cout, std::cerr iÃ§in
#include <sstream>   // std::stringstream iÃ§in

// === SequenceManager Implementasyonlari ===


SequenceManager::SequenceManager() 
    : last_sequence_update_time_us(0),
      current_sequence(std::make_unique<DynamicSequence>()) 
{
    LOG_DEFAULT(LogLevel::INFO, "SequenceManager baÅŸlatÄ±ldÄ±.");
}

SequenceManager::~SequenceManager() {
    LOG_DEFAULT(LogLevel::INFO, "SequenceManager sonlandÄ±rÄ±ldÄ±.");
}

void SequenceManager::step_simulation() {
    LOG_DEFAULT(LogLevel::DEBUG, "SequenceManager step_simulation Ã§alÄ±ÅŸtÄ±.");
    // AdÄ±m simÃ¼lasyonu buraya eklenebilir
}

// add_signal fonksiyonu Cryptofrocessor referansÄ± alacak ÅŸekilde gÃ¼ncellendi
bool SequenceManager::add_signal(const AtomicSignal& signal, CryptofigProcessor& cryptofig_processor) { 
    LOG_DEFAULT(LogLevel::DEBUG, "add_signal: Sinyal tipi eklendi: " << static_cast<int>(signal.sensor_type) << ". Buffer boyutu: " << signal_buffer.size() << "\n"); 
    if (signal_buffer.size() >= max_buffer_size) {
        LOG_DEFAULT(LogLevel::TRACE, "add_signal: Buffer dolu, pop_front yapiliyor.\n"); 
        signal_buffer.pop_front(); 
    }
    signal_buffer.push_back(signal); 
    
    long long current_time_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();

    if (current_time_us - last_sequence_update_time_us > 500000 || 
        (signal_buffer.size() % (max_buffer_size / 5) == 0 && signal_buffer.size() > 0)) {
        LOG_DEFAULT(LogLevel::DEBUG, "add_signal: Sequence update tetikleniyor.\n"); 
        update_current_sequence(cryptofig_processor); // CryptofigProcessor referansÄ± ile Ã§aÄŸrÄ±ldÄ±
        last_sequence_update_time_us = current_time_us;
        LOG_DEFAULT(LogLevel::DEBUG, "add_signal: Sequence update tamamlandi, true dÃ¶ndÃ¼rÃ¼lÃ¼yor.\n"); 
        return true; 
    }
    LOG_DEFAULT(LogLevel::TRACE, "add_signal: Sequence update tetiklenmedi, false dÃ¶ndÃ¼rÃ¼lÃ¼yor.\n"); 
    return false;
}

// update_current_sequence fonksiyonu CryptofigProcessor referansÄ± alacak ÅŸekilde gÃ¼ncellendi
void SequenceManager::update_current_sequence(CryptofigProcessor& cryptofig_processor) {
    LOG_DEFAULT(LogLevel::DEBUG, "update_current_sequence: Basladi.\n"); 
    unsigned short current_app_hash_for_sequence = 0;
    if (!signal_buffer.empty()) {
        current_app_hash_for_sequence = signal_buffer.back().active_app_id_hash;
    }
    if (!current_sequence) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "update_current_sequence: current_sequence nullptr! Yeniden oluÅŸturuluyor.\n");
        current_sequence = std::make_unique<DynamicSequence>();
    }
    current_sequence->update_from_signals(signal_buffer, std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count(), current_app_hash_for_sequence, cryptofig_processor.get_autoencoder()); // Getter kullanÄ±ldÄ±
     
    LOG_DEFAULT(LogLevel::DEBUG, "update_current_sequence: Bitti.\n"); 
}

std::deque<AtomicSignal> SequenceManager::get_signal_buffer_copy() const {
    return signal_buffer;
}


 
--- C:\Users\aib\CerebrumLux\src\data_models\sequence_manager.h --- 
#ifndef CEREBRUM_LUX_SEQUENCE_MANAGER_H
#define CEREBRUM_LUX_SEQUENCE_MANAGER_H

#include <deque>
#include <memory>
#include <chrono>
#include "../core/enums.h"      // Enumlar iÃ§in
#include "../core/utils.h"      // For convert_wstring_to_string (if needed elsewhere)
#include "dynamic_sequence.h"   // DynamicSequence iÃ§in
#include "../sensors/atomic_signal.h" // AtomicSignal iÃ§in
#include "../brain/cryptofig_processor.h" // CryptofigProcessor iÃ§in ileri bildirim (parametre olarak kullanÄ±lacak)

// Ä°leri bildirim
class CryptofigProcessor; 

class DynamicSequence;

// *** SequenceManager: Dinamik sinyal dizilerini yonetir ***
class SequenceManager {
public:

    SequenceManager();
    ~SequenceManager();

    // add_signal fonksiyonu CryptofigProcessor referansÄ± alacak ÅŸekilde gÃ¼ncellendi
    bool add_signal(const AtomicSignal& signal, CryptofigProcessor& cryptofig_processor); 

    void step_simulation();

    std::deque<AtomicSignal> get_signal_buffer_copy() const; 

    // YENÄ°: current_sequence'e eriÅŸim iÃ§in getter metodu
    DynamicSequence& get_current_sequence_ref() { return *current_sequence; }
    const DynamicSequence& get_current_sequence_ref() const { return *current_sequence; }

private:
    // update_current_sequence metodu CryptofigProcessor referansÄ± alacak ÅŸekilde gÃ¼ncellendi
    void update_current_sequence(CryptofigProcessor& cryptofig_processor); 

    std::deque<AtomicSignal> signal_buffer; 
    size_t max_buffer_size = 100;           

    std::unique_ptr<DynamicSequence> current_sequence;

    uint64_t last_sequence_update_time_us;

};


#endif // CEREBRUM_LUX_SEQUENCE_MANAGER_H 
--- C:\Users\aib\CerebrumLux\src\gui\console_stream.h --- 
#ifndef CEREBRUM_LUX_CONSOLE_STREAM_H
#define CEREBRUM_LUX_CONSOLE_STREAM_H

#include <QTextEdit>
#include <QObject>
#include <iostream>

// QTextEdit'e yazmak iÃ§in ostream arabelleÄŸi
class QTextEditStreamBuf : public std::basic_streambuf<char> {
public:
    QTextEditStreamBuf(QTextEdit* editor, std::ostream& originalStream)
        : editor_(editor), originalStream_(originalStream) {}

    // YENÄ°: originalStream'e eriÅŸim iÃ§in public getter metodu
    std::ostream& originalStream() { return originalStream_; }

protected:
    virtual int overflow(int c) override {
        if (c != EOF) {
            char ch = static_cast<char>(c);
            // QTextEdit'e ekle
            editor_->insertPlainText(QString(ch));
            // Orijinal stream'e de yaz (opsiyonel, debug iÃ§in faydalÄ± olabilir)
            originalStream_.put(ch); 
        }
        return c;
    }

    virtual std::streamsize xsputn(const char* s, std::streamsize num) override {
        // QTextEdit'e ekle
        editor_->insertPlainText(QString::fromUtf8(s, static_cast<int>(num)));
        // Orijinal stream'e de yaz
        originalStream_.write(s, num);
        return num;
    }

private:
    QTextEdit* editor_;
    std::ostream& originalStream_;
};

// std::cout ve std::cerr'i QTextEdit'e yÃ¶nlendiren QObject
class ConsoleStream : public QObject {
    Q_OBJECT
public:
    ConsoleStream(QTextEdit* editor, std::ostream& stream, QObject* parent = nullptr)
        : QObject(parent), editor_(editor), original_stream_(stream), stream_buf_(editor, stream) {
        
        // Stream'in arabelleÄŸini kendi arabelleÄŸimize yÃ¶nlendiriyoruz
        old_buf_ = stream.rdbuf();
        stream.rdbuf(&stream_buf_);
    }

    ~ConsoleStream() override {
        // Uygulama kapanÄ±rken orijinal arabelleÄŸi geri yÃ¼klÃ¼yoruz
        original_stream_.rdbuf(old_buf_);
    }

private:
    QTextEdit* editor_;
    std::ostream& original_stream_;
    QTextEditStreamBuf stream_buf_;
    std::streambuf* old_buf_;
};

#endif // CEREBRUM_LUX_CONSOLE_STREAM_H 
--- C:\Users\aib\CerebrumLux\src\gui\DataTypes.h --- 
#ifndef DATATYPES_H
#define DATATYPES_H

#include <string>
#include <vector>
#include <chrono> // IngestReport iÃ§in
#include <map>    // IngestReport iÃ§in

// LearningModule'den gelen enum ve struct'lar
#include "../learning/LearningModule.h" // IngestResult ve IngestReport iÃ§in

// SimÃ¼lasyon verileri
struct SimulationData {
    std::string id; 
    int step;
    float value;
};

// Log verileri
struct LogData {
    std::string message;
    int level;
};

// Grafik verileri
struct GraphData {
    float x;
    float y;
};

// Q_DECLARE_METATYPE ile Qt'nin meta-sistemine kaydetme
// Bu, bu tÃ¼rlerin sinyaller ve slotlar arasÄ±nda veya QVariant iÃ§inde kullanÄ±lmasÄ±nÄ± saÄŸlar.
//Q_DECLARE_METATYPE(IngestResult)
//Q_DECLARE_METATYPE(IngestReport)

#endif // DATATYPES_H 
--- C:\Users\aib\CerebrumLux\src\gui\EngineIntegration.h --- 
#ifndef ENGINE_INTEGRATION_H
#define ENGINE_INTEGRATION_H

#include <string>
#include <vector>
#include "../learning/KnowledgeBase.h" 
#include "../learning/LearningModule.h" 
#include "../meta/meta_evolution_engine.h" 
#include "../data_models/sequence_manager.h" 
#include "DataTypes.h" 

class EngineIntegration {
public:
    EngineIntegration(MetaEvolutionEngine& meta_engine, SequenceManager& sequence_manager,
                      LearningModule& learning_module, KnowledgeBase& kb);

    MetaEvolutionEngine& getMetaEngine() { return meta_engine; }
    SequenceManager& getSequenceManager() { return sequence_manager; }
    LearningModule& getLearningModule() { return learning_module; }
    KnowledgeBase& getKnowledgeBase() { return kb; }

    void startCoreSimulation();
    void stopCoreSimulation();
    void processUserCommand(const std::string& command);

private:
    MetaEvolutionEngine& meta_engine;
    SequenceManager& sequence_manager;
    LearningModule& learning_module;
    KnowledgeBase& kb;
};

#endif // ENGINE_INTEGRATION_H 
--- C:\Users\aib\CerebrumLux\src\gui\engine_integration.cpp --- 
#include "engine_integration.h"
#include "../core/logger.h" // Loglama iÃ§in
// AI Core baÄŸÄ±mlÄ±lÄ±klarÄ± (gerekirse buraya dahil edilebilir, ÅŸimdilik sadece Logger ile logluyoruz)
// Ã–rneÄŸin, eÄŸer startCoreSimulation, SequenceManager'dan bir metot Ã§aÄŸÄ±racaksa
// #include "../data_models/sequence_manager.h"

// Kurucu
EngineIntegration::EngineIntegration(MetaEvolutionEngine& meta_engine_ref, SequenceManager& sequence_manager_ref,
                                     LearningModule& learning_module_ref, KnowledgeBase& kb_ref)
    : meta_engine(meta_engine_ref), sequence_manager(sequence_manager_ref),
      learning_module(learning_module_ref), kb(kb_ref)
{
    LOG(LogLevel::INFO, "EngineIntegration: Initialized.");
}

// YENÄ°: SimÃ¼lasyonu baÅŸlatma metodu
void EngineIntegration::startCoreSimulation() {
    LOG(LogLevel::INFO, "EngineIntegration: Core simulation started.");
    // TODO: Burada Cerebrum Lux'Ä±n ana simÃ¼lasyon dÃ¶ngÃ¼sÃ¼nÃ¼ baÅŸlatan gerÃ§ek mantÄ±k gelecek.
    // Ã–rneÄŸin: meta_engine.run_meta_evolution_cycle(); (zaten QTimer ile Ã§aÄŸrÄ±lÄ±yor, belki farklÄ± bir baÅŸlatma mekanizmasÄ±)
    // veya sequence_manager.startCollectingData(); gibi.
}

// YENÄ°: SimÃ¼lasyonu durdurma metodu
void EngineIntegration::stopCoreSimulation() {
    LOG(LogLevel::INFO, "EngineIntegration: Core simulation stopped.");
    // TODO: Burada Cerebrum Lux'Ä±n ana simÃ¼lasyon dÃ¶ngÃ¼sÃ¼nÃ¼ durduran gerÃ§ek mantÄ±k gelecek.
    // Ã–rneÄŸin: meta_engine.stopMetaEvolution(); veya sequence_manager.stopCollectingData(); gibi.
}

// YENÄ°: KullanÄ±cÄ± komutunu iÅŸleme metodu
void EngineIntegration::processUserCommand(const std::string& command) {
    LOG(LogLevel::INFO, "EngineIntegration: Processing user command: '" << command << "'");
    // TODO: Burada gelen komutu analiz edip Cerebrum Lux'Ä±n ilgili modÃ¼llerine yÃ¶nlendirme mantÄ±ÄŸÄ± gelecek.
    // Ã–rneÄŸin:
    // if (command == "optimize performance") {
    //     meta_engine.set_meta_goal(AIGoal::OptimizePerformance);
    // } else if (command == "learn faster") {
    //     learning_module.adjustLearningRate(0.1f);
    // }
    // NlpProcessor veya IntentAnalyzer gibi modÃ¼ller de burada kullanÄ±labilir.
} 
--- C:\Users\aib\CerebrumLux\src\gui\engine_integration.h --- 
#ifndef ENGINE_INTEGRATION_H
#define ENGINE_INTEGRATION_H

#include <string>
#include <vector>
#include "../learning/KnowledgeBase.h" // KnowledgeBase iÃ§in
#include "../learning/LearningModule.h" // LearningModule iÃ§in
#include "../meta/meta_evolution_engine.h" // MetaEvolutionEngine iÃ§in
#include "../data_models/sequence_manager.h" // SequenceManager iÃ§in
#include "DataTypes.h" // SimulationData iÃ§in


// Ä°leri bildirimler
// class MetaEvolutionEngine; // Zaten dahil edildi
// class SequenceManager;   // Zaten dahil edildi
// class LearningModule;    // Zaten dahil edildi
// class KnowledgeBase;     // Zaten dahil edildi

class EngineIntegration {
public:
    // Mevcut kurucu
    EngineIntegration(MetaEvolutionEngine& meta_engine, SequenceManager& sequence_manager,
                      LearningModule& learning_module, KnowledgeBase& kb);

    // Mevcut getter'lar
    MetaEvolutionEngine& getMetaEngine() { return meta_engine; }
    SequenceManager& getSequenceManager() { return sequence_manager; }
    LearningModule& getLearningModule() { return learning_module; }
    KnowledgeBase& getKnowledgeBase() { return kb; }

    // YENÄ°: SimÃ¼lasyonu baÅŸlatma/durdurma ve komut iÅŸleme metotlarÄ±
    void startCoreSimulation();
    void stopCoreSimulation();
    void processUserCommand(const std::string& command);

private:
    MetaEvolutionEngine& meta_engine;
    SequenceManager& sequence_manager;
    LearningModule& learning_module;
    KnowledgeBase& kb;
};

#endif // ENGINE_INTEGRATION_H 
--- C:\Users\aib\CerebrumLux\src\gui\MainWindow.cpp --- 
#include "MainWindow.h"
#include <QTimer>
#include <iostream>
#include <QStringList> 
#include <QDebug> 
#include "../core/logger.h" 
#include "../learning/capsule.h" 
#include <iomanip> 
#include <sstream> 
#include <nlohmann/json.hpp> // JSON ayrÄ±ÅŸtÄ±rma iÃ§in

// OpenSSL iÃ§in gerekli baÅŸlÄ±klar (Sadece EVP_CIPHER_iv_length iÃ§in gerekli olanÄ± bÄ±rakÄ±ldÄ±)
#include <openssl/evp.h>    

// Panel baÅŸlÄ±k dosyalarÄ±nÄ± burada dahil ediyoruz
#include "panels/SimulationPanel.h"
#include "panels/LogPanel.h" 
#include "panels/GraphPanel.h" 
#include "panels/CapsuleTransferPanel.h" // YENÄ°: CapsuleTransferPanel dahil edildi
#include "../gui/engine_integration.h" 
#include "../core/utils.h" // base64_encode iÃ§in utils.h'yi de dahil edelim

// Capsule'dan SimulationData'ya basit bir dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼
SimulationData convertCapsuleToSimulationData(const Capsule& capsule) {
    SimulationData data;
    data.id = capsule.id; 
    data.value = capsule.confidence; 
    return data;
}


// Constructor
MainWindow::MainWindow(EngineIntegration& eng, LearningModule& learn, QWidget* parent)
    : QMainWindow(parent), engine(eng), learningModule(learn)
{
    // Q_DECLARE_METATYPE ile kaydedilen tÃ¼rleri sinyal/slot sisteminde kullanabilmek iÃ§in
    // qRegisterMetaType Ã§aÄŸrÄ±sÄ± burada yapÄ±labilir.
    qRegisterMetaType<IngestResult>("IngestResult");
    qRegisterMetaType<IngestReport>("IngestReport");

    // Paneller
    tabWidget = new QTabWidget(this);
    simulationPanel = new SimulationPanel(this);
    logPanel = new LogPanel(this);
    graphPanel = new GraphPanel(this);
    capsuleTransferPanel = new CapsuleTransferPanel(this); // YENÄ°: CapsuleTransferPanel oluÅŸturuldu

    tabWidget->addTab(simulationPanel, "Simulation");
    tabWidget->addTab(logPanel, "Log");
    tabWidget->addTab(graphPanel, "Graph");
    tabWidget->addTab(capsuleTransferPanel, "Capsule Transfer"); // YENÄ°: Panele eklendi

    setCentralWidget(tabWidget);

    // GUI gÃ¼ncelleme timer
    connect(&update_timer, &QTimer::timeout, this, &MainWindow::updateGui);
    update_timer.start(500); 

    // SimulationPanel sinyallerini MainWindow'daki slot'lara baÄŸla
    connect(simulationPanel, &SimulationPanel::commandEntered, this, &MainWindow::onSimulationCommandEntered);
    // DÃ¼zeltilmiÅŸ baÄŸlantÄ±lar: SimulationPanel'in kendi sinyallerine baÄŸlanÄ±yoruz
    connect(simulationPanel, &SimulationPanel::startSimulation, this, &MainWindow::onStartSimulationTriggered);
    connect(simulationPanel, &SimulationPanel::stopSimulation, this, &MainWindow::onStopSimulationTriggered);

    // YENÄ°: CapsuleTransferPanel sinyallerini MainWindow'daki slot'lara baÄŸla
    connect(capsuleTransferPanel, &CapsuleTransferPanel::ingestCapsuleRequest, this, &MainWindow::onIngestCapsuleRequest);
    connect(capsuleTransferPanel, &CapsuleTransferPanel::fetchWebCapsuleRequest, this, &MainWindow::onFetchWebCapsuleRequest);

    LOG(LogLevel::INFO, "MainWindow: SimulationPanel and CapsuleTransferPanel signals connected.");
}

// YÄ±kÄ±cÄ±
MainWindow::~MainWindow() {
    // Paneller QObject hiyerarÅŸisi tarafÄ±ndan otomatik yÃ¶netilir.
}

// GUI gÃ¼ncelleme metodu
void MainWindow::updateGui() {
    std::vector<Capsule> capsules_for_sim = engine.getKnowledgeBase().search_by_topic("StepSimulation"); 
    std::vector<SimulationData> simulation_data_vec;
    for (const auto& cap : capsules_for_sim) {
        simulation_data_vec.push_back(convertCapsuleToSimulationData(cap)); 
    }
    simulationPanel->updatePanel(simulation_data_vec);

    auto capsules_for_graph = learningModule.search_by_topic("StepSimulation"); 
    if (!capsules_for_graph.empty()) {
        double latestValue = capsules_for_graph.back().confidence; 
        graphPanel->updateGraph(static_cast<size_t>(latestValue));
        LOG_DEFAULT(LogLevel::DEBUG, "MainWindow: GraphPanel updated with value: " << latestValue);
    } else {
        LOG_DEFAULT(LogLevel::DEBUG, "MainWindow: No 'StepSimulation' capsules found for GraphPanel. Setting value to 0.");
        graphPanel->updateGraph(0); 
    }

    LOG_DEFAULT(LogLevel::DEBUG, "[GUI] GÃ¼ncelleme..."); 
    qDebug() << "[Qt GUI] GÃ¼ncelleme..."; 

    auto results = learningModule.getKnowledgeBase().semantic_search("Qt6", 2); 
    if (!results.empty()) {
        LOG_DEFAULT(LogLevel::INFO, "[GUI] HatÄ±rlanan bilgi: " << results[0].content);
        qDebug() << "[Qt GUI] HatÄ±rlanan bilgi: " << QString::fromStdString(results[0].content);
    }
}

// SimulationPanel sinyalleri iÃ§in slot implementasyonlarÄ±
void MainWindow::onSimulationCommandEntered(const QString& command) {
    LOG(LogLevel::INFO, "MainWindow: Received simulation command: " << command.toStdString());
    engine.processUserCommand(command.toStdString());
}

void MainWindow::onStartSimulationTriggered() {
    LOG(LogLevel::INFO, "MainWindow: Received start simulation signal.");
    engine.startCoreSimulation();
}

void MainWindow::onStopSimulationTriggered() {
    LOG(LogLevel::INFO, "MainWindow: Received stop simulation signal.");
    engine.stopCoreSimulation();
}

// YENÄ°: CapsuleTransferPanel sinyalleri iÃ§in slot implementasyonlarÄ±
void MainWindow::onIngestCapsuleRequest(const QString& capsuleJson, const QString& signature, const QString& senderId) {
    LOG_DEFAULT(LogLevel::INFO, "MainWindow: Received ingest capsule request from GUI. Sender: " << senderId.toStdString());
    
    try {
        nlohmann::json j = nlohmann::json::parse(capsuleJson.toStdString());
        Capsule incoming_capsule = Capsule::fromJson(j);

        // LearningModule'den kapsÃ¼lÃ¼ iÅŸle
        IngestReport report = learningModule.ingest_envelope(incoming_capsule, signature.toStdString(), senderId.toStdString());
        
        // Raporu CapsuleTransferPanel'e geri gÃ¶nder
        capsuleTransferPanel->displayIngestReport(report);

    } catch (const nlohmann::json::parse_error& e) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "MainWindow: JSON ayrÄ±ÅŸtÄ±rma hatasÄ±: " << e.what());
        IngestReport error_report;
        error_report.result = IngestResult::UnknownError;
        error_report.message = "JSON parsing failed: " + std::string(e.what());
        error_report.source_peer_id = senderId.toStdString();
        error_report.timestamp = std::chrono::system_clock::now();
        capsuleTransferPanel->displayIngestReport(error_report);
    } catch (const std::exception& e) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "MainWindow: KapsÃ¼l yutma sÄ±rasÄ±nda beklenmeyen hata: " << e.what());
        IngestReport error_report;
        error_report.result = IngestResult::UnknownError;
        error_report.message = "Unexpected error during capsule ingestion: " + std::string(e.what());
        error_report.source_peer_id = senderId.toStdString();
        error_report.timestamp = std::chrono::system_clock::now();
        capsuleTransferPanel->displayIngestReport(error_report);
    }
}

void MainWindow::onFetchWebCapsuleRequest(const QString& query) {
    LOG_DEFAULT(LogLevel::INFO, "MainWindow: Received fetch web capsule request from GUI. Query: " << query.toStdString());
    // LearningModule'den web'den kapsÃ¼l Ã§ekme iÅŸlemini baÅŸlat
    learningModule.learnFromWeb(query.toStdString());

    // BaÅŸarÄ±lÄ± olduÄŸunu varsayan basit bir rapor (gerÃ§ekte learnFromWeb bir rapor dÃ¶ndÃ¼rmez)
    IngestReport dummy_report;
    dummy_report.result = IngestResult::Success;
    dummy_report.message = "Web'den kapsÃ¼l Ã§ekme iÅŸlemi baÅŸlatÄ±ldÄ± (simÃ¼le edildi).";
    dummy_report.source_peer_id = "WebFetcher";
    dummy_report.original_capsule.id = "web_fetch_" + query.toStdString().substr(0, std::min(static_cast<size_t>(10), static_cast<size_t>(query.length())));
    dummy_report.timestamp = std::chrono::system_clock::now();
    capsuleTransferPanel->displayIngestReport(dummy_report);
} 
--- C:\Users\aib\CerebrumLux\src\gui\MainWindow.h --- 
#ifndef MAINWINDOW_H
#define MAINWINDOW_H

#pragma once
#include <QMainWindow>
#include <QTabWidget>
#include <QTimer>

class SimulationPanel; 
class LogPanel;      
class GraphPanel;    
class CapsuleTransferPanel; // YENÄ°: CapsuleTransferPanel iÃ§in ileri bildirim

class EngineIntegration; 
class LearningModule;    

class MainWindow : public QMainWindow
{
    Q_OBJECT
public:
    MainWindow(EngineIntegration& engine, LearningModule& learner, QWidget* parent = nullptr);
    ~MainWindow();

    LogPanel* getLogPanel() const { return logPanel; }
    CapsuleTransferPanel* getCapsuleTransferPanel() const { return capsuleTransferPanel; } // YENÄ°: Getter eklendi

private slots:
    void updateGui();
    void onSimulationCommandEntered(const QString& command);
    void onStartSimulationTriggered();
    void onStopSimulationTriggered();

    // YENÄ°: CapsuleTransferPanel'den gelen sinyaller iÃ§in slotlar
    void onIngestCapsuleRequest(const QString& capsuleJson, const QString& signature, const QString& senderId);
    void onFetchWebCapsuleRequest(const QString& query);

private:
    EngineIntegration& engine;
    LearningModule& learningModule; 
                                    
    QTabWidget* tabWidget;
    SimulationPanel* simulationPanel;
    LogPanel* logPanel;
    GraphPanel* graphPanel;
    CapsuleTransferPanel* capsuleTransferPanel; // YENÄ°: Panel Ã¼yesi
    QTimer update_timer;
};

#endif // MAINWINDOW_H 
--- C:\Users\aib\CerebrumLux\src\gui\panels\CapsuleTransferPanel.cpp --- 
#include "CapsuleTransferPanel.h"
#include <QDateTime> // IngestReport timestamp iÃ§in
#include "../../core/logger.h" // Loglama iÃ§in
#include <QDebug> // Debug Ã§Ä±ktÄ±larÄ± iÃ§in

CapsuleTransferPanel::CapsuleTransferPanel(QWidget* parent) : QWidget(parent)
{
    mainLayout = new QVBoxLayout(this);

    // 1. JSON GiriÅŸ AlanÄ±
    jsonInputTextEdit = new QTextEdit(this);
    jsonInputTextEdit->setPlaceholderText("Enter Capsule JSON here...");
    mainLayout->addWidget(jsonInputTextEdit);

    // 2. Ä°mza ve GÃ¶nderen ID AlanlarÄ± ile Ingest Butonu
    ingestControlsLayout = new QHBoxLayout();
    signatureLineEdit = new QLineEdit(this);
    signatureLineEdit->setPlaceholderText("Enter Signature (Base64)");
    senderIdLineEdit = new QLineEdit(this);
    senderIdLineEdit->setPlaceholderText("Enter Sender ID");
    ingestCapsuleButton = new QPushButton("Ingest Capsule", this);

    ingestControlsLayout->addWidget(signatureLineEdit);
    ingestControlsLayout->addWidget(senderIdLineEdit);
    ingestControlsLayout->addWidget(ingestCapsuleButton);
    mainLayout->addLayout(ingestControlsLayout);

    // 3. Web Sorgu AlanÄ± ve Fetch Butonu
    fetchWebControlsLayout = new QHBoxLayout();
    webQueryLineEdit = new QLineEdit(this);
    webQueryLineEdit->setPlaceholderText("Enter Web Search Query for Capsule");
    fetchFromWebButton = new QPushButton("Fetch from Web", this);

    fetchWebControlsLayout->addWidget(webQueryLineEdit);
    fetchWebControlsLayout->addWidget(fetchFromWebButton);
    mainLayout->addLayout(fetchWebControlsLayout);

    // 4. Ingest Raporu GÃ¶sterim AlanÄ±
    ingestReportTextEdit = new QTextEdit(this);
    ingestReportTextEdit->setReadOnly(true);
    ingestReportTextEdit->setPlaceholderText("Ingest Report will appear here...");
    mainLayout->addWidget(ingestReportTextEdit);

    setLayout(mainLayout);

    // Sinyal-Slot BaÄŸlantÄ±larÄ±
    connect(ingestCapsuleButton, &QPushButton::clicked, this, &CapsuleTransferPanel::onIngestCapsuleClicked);
    connect(fetchFromWebButton, &QPushButton::clicked, this, &CapsuleTransferPanel::onFetchFromWebClicked);

    // IngestReport'u Qt'nin meta sistemine kaydet (DataTypes.h'de zaten yapÄ±ldÄ±)
    // qRegisterMetaType<IngestReport>("IngestReport"); // Zaten DataTypes.h iÃ§inde Q_DECLARE_METATYPE ile bildirilmiÅŸti
    // Ancak sinyal/slot baÄŸlantÄ±larÄ±nda argÃ¼man olarak kullanÄ±labilmesi iÃ§in qRegisterMetaType<IngestReport>() Ã§aÄŸrÄ±sÄ± da uygun bir yerde yapÄ±lmalÄ±.
    // main.cpp'de QApplication kurulduktan sonra veya MainWindow constructor'Ä±nda olabilir.
    
    LOG_DEFAULT(LogLevel::INFO, "CapsuleTransferPanel: Initialized.");
}

void CapsuleTransferPanel::onIngestCapsuleClicked()
{
    QString capsuleJson = jsonInputTextEdit->toPlainText();
    QString signature = signatureLineEdit->text();
    QString senderId = senderIdLineEdit->text();

    if (capsuleJson.isEmpty()) {
        ingestReportTextEdit->append(QDateTime::currentDateTime().toString("HH:mm:ss") + " [ERROR] Capsule JSON cannot be empty.");
        LOG_DEFAULT(LogLevel::WARNING, "CapsuleTransferPanel: Ingest Capsule JSON input is empty.");
        return;
    }

    LOG_DEFAULT(LogLevel::INFO, "CapsuleTransferPanel: Emitting ingestCapsuleRequest for sender: " << senderId.toStdString());
    emit ingestCapsuleRequest(capsuleJson, signature, senderId);
}

void CapsuleTransferPanel::onFetchFromWebClicked()
{
    QString query = webQueryLineEdit->text();

    if (query.isEmpty()) {
        ingestReportTextEdit->append(QDateTime::currentDateTime().toString("HH:mm:ss") + " [ERROR] Web query cannot be empty.");
        LOG_DEFAULT(LogLevel::WARNING, "CapsuleTransferPanel: Fetch from Web query input is empty.");
        return;
    }

    LOG_DEFAULT(LogLevel::INFO, "CapsuleTransferPanel: Emitting fetchWebCapsuleRequest for query: " << query.toStdString());
    emit fetchWebCapsuleRequest(query);
}

void CapsuleTransferPanel::displayIngestReport(const IngestReport& report)
{
    QString timestamp = QDateTime::fromSecsSinceEpoch(std::chrono::system_clock::to_time_t(report.timestamp)).toString("HH:mm:ss");
    QString reportMsg = QString("%1 [REPORT] Source: %2, ID: %3, Result: %4, Message: %5")
                            .arg(timestamp)
                            .arg(QString::fromStdString(report.source_peer_id))
                            .arg(QString::fromStdString(report.original_capsule.id))
                            .arg(static_cast<int>(report.result))
                            .arg(QString::fromStdString(report.message));
    
    // Processed capsule content'ini de ekleyelim
    if (report.result == IngestResult::Success || report.result == IngestResult::SanitizationNeeded) {
        reportMsg += "\n    Processed Content: " + QString::fromStdString(report.processed_capsule.content.substr(0, std::min((size_t)200, report.processed_capsule.content.length()))) + "...";
    }

    ingestReportTextEdit->append(reportMsg);
    LOG_DEFAULT(LogLevel::INFO, "CapsuleTransferPanel: Displaying ingest report for capsule ID: " << report.original_capsule.id);
} 
--- C:\Users\aib\CerebrumLux\src\gui\panels\CapsuleTransferPanel.h --- 
#ifndef CAPSULETRANSFERPANEL_H
#define CAPSULETRANSFERPANEL_H

#include <QWidget>
#include <QTextEdit>
#include <QLineEdit>
#include <QPushButton>
#include <QVBoxLayout> // Main layout
#include <QHBoxLayout> // For buttons and input fields
#include "../../learning/LearningModule.h" // IngestReport iÃ§in

// Forward declarations for Qt classes
// (QTextEdit, QLineEdit, QPushButton, QVBoxLayout, QHBoxLayout zaten yukarÄ±da dahil edildi)

class CapsuleTransferPanel : public QWidget
{
    Q_OBJECT
public:
    explicit CapsuleTransferPanel(QWidget* parent = nullptr);

signals:
    // KapsÃ¼l yutma isteÄŸi iÃ§in sinyal
    void ingestCapsuleRequest(const QString& capsuleJson, const QString& signature, const QString& senderId);
    // Web'den kapsÃ¼l Ã§ekme isteÄŸi iÃ§in sinyal
    void fetchWebCapsuleRequest(const QString& query);

public slots:
    // ingest_envelope'dan gelen raporu gÃ¶stermek iÃ§in slot
    void displayIngestReport(const IngestReport& report);

private slots:
    // UI etkileÅŸimleri iÃ§in slotlar
    void onIngestCapsuleClicked();
    void onFetchFromWebClicked();

private:
    // UI ElemanlarÄ±
    QTextEdit* jsonInputTextEdit;
    QLineEdit* signatureLineEdit;
    QLineEdit* senderIdLineEdit;
    QPushButton* ingestCapsuleButton;
    QLineEdit* webQueryLineEdit;
    QPushButton* fetchFromWebButton;
    QTextEdit* ingestReportTextEdit;

    // Layout'lar
    QVBoxLayout* mainLayout;
    QHBoxLayout* ingestControlsLayout;
    QHBoxLayout* fetchWebControlsLayout;
};

#endif // CAPSULETRANSFERPANEL_H 
--- C:\Users\aib\CerebrumLux\src\gui\panels\GraphPanel.cpp --- 
#include "GraphPanel.h"
#include <QtCharts/QChart>
#include <QtCharts/QChartView>
#include <QtCharts/QLineSeries>
#include <QVBoxLayout>
#include <QDebug> // YENÄ°: QDebug iÃ§in eklendi
#include <QValueAxis> // YENÄ°: QValueAxis iÃ§in eklendi (chart->axisX/Y()->setRange kullanmak iÃ§in)


GraphPanel::GraphPanel(QWidget *parent) : QWidget(parent)
{
    series = new QLineSeries(this);
    chart = new QChart();
    chart->addSeries(series);
    chart->createDefaultAxes();
    chart->setTitle("Simulation Graph");

    // X ve Y eksenlerini doÄŸru tÃ¼re cast etmek iÃ§in
    if (chart->axes(Qt::Horizontal).count() > 0) {
        auto axisX = qobject_cast<QValueAxis*>(chart->axes(Qt::Horizontal).at(0));
        if (axisX) {
            axisX->setTitleText("Zaman/AdÄ±m");
            axisX->setLabelFormat("%d");
        }
    }
    if (chart->axes(Qt::Vertical).count() > 0) {
        auto axisY = qobject_cast<QValueAxis*>(chart->axes(Qt::Vertical).at(0));
        if (axisY) {
            axisY->setTitleText("DeÄŸer");
            axisY->setLabelFormat("%.1f");
        }
    }


    chartView = new QChartView(chart, this);
    chartView->setRenderHint(QPainter::Antialiasing);

    auto layout = new QVBoxLayout(this);
    layout->addWidget(chartView);
    setLayout(layout);
}

void GraphPanel::addDataPoint(double x, double y)
{
    series->append(x, y);
}

// YENÄ°: Grafik gÃ¼ncelleme metodu implementasyonu
void GraphPanel::updateGraph(size_t value)
{
    // Mevcut grafiÄŸe yeni bir veri noktasÄ± ekleyelim.
    // X ekseni iÃ§in basitÃ§e mevcut nokta sayÄ±sÄ±nÄ± kullanabiliriz.
    // Y ekseni iÃ§in gelen 'value' parametresini kullanÄ±rÄ±z.
    double x_value = series->count(); // Mevcut nokta sayÄ±sÄ±
    double y_value = static_cast<double>(value); // Gelen deÄŸeri Y ekseni deÄŸeri olarak kullan

    series->append(x_value, y_value);

    // Grafik aralÄ±ÄŸÄ±nÄ± otomatik olarak gÃ¼ncelle
    if (chart->axes(Qt::Horizontal).count() > 0) {
        auto axisX = qobject_cast<QValueAxis*>(chart->axes(Qt::Horizontal).at(0));
        if (axisX) {
            axisX->setRange(0, series->count());
        }
    }
    
    // Y ekseni iÃ§in min/max deÄŸerlerini otomatik ayarla veya sabit tut
    if (series->count() > 0 && chart->axes(Qt::Vertical).count() > 0) {
        double minY = y_value, maxY = y_value;
        for (int i = 0; i < series->count(); ++i) {
            QPointF point = series->at(i);
            if (point.y() < minY) minY = point.y();
            if (point.y() > maxY) maxY = point.y();
        }
        auto axisY = qobject_cast<QValueAxis*>(chart->axes(Qt::Vertical).at(0));
        if (axisY) {
            // Sadece tek bir nokta varsa min/max aynÄ± olacaÄŸÄ±ndan biraz boÅŸluk bÄ±rak
            if (minY == maxY) { 
                axisY->setRange(minY - 1.0, maxY + 1.0);
            } else {
                axisY->setRange(minY - (maxY - minY) * 0.1, maxY + (maxY - minY) * 0.1); // %10 boÅŸluk
            }
        }
    }

    // Qt debug Ã§Ä±ktÄ±sÄ±
    qDebug() << "[GraphPanel] Grafik gÃ¼ncellendi: (" << x_value << ", " << y_value << ")";
} 
--- C:\Users\aib\CerebrumLux\src\gui\panels\GraphPanel.h --- 
#ifndef GRAPHPANEL_H
#define GRAPHPANEL_H

#include <QWidget>
#include <QtCharts/QChart>
#include <QtCharts/QChartView>
#include <QtCharts/QLineSeries>
#include "../engine_integration.h" // LogData ve GraphData iÃ§in
#include "DataTypes.h" 

class GraphPanel : public QWidget
{
    Q_OBJECT
public:
    explicit GraphPanel(QWidget *parent = nullptr);
    void addDataPoint(double x, double y);
    void updateGraph(size_t value); // YENÄ°: Grafik gÃ¼ncelleme metodu

private:
    QChart* chart;
    QChartView* chartView;
    QLineSeries* series;
};

#endif // GRAPHPANEL_H 
--- C:\Users\aib\CerebrumLux\src\gui\panels\LogPanel.cpp --- 
#include "LogPanel.h"
#include <QVBoxLayout> 
#include <QLineEdit>   
#include <QTextCharFormat> 
#include <QTextCursor>     
#include <QScrollBar> // YENÄ°: KaydÄ±rma Ã§ubuÄŸuna eriÅŸim iÃ§in

LogPanel::LogPanel(QWidget* parent) : QWidget(parent)
{
    mainLayout = new QVBoxLayout(this); 

    searchLineEdit = new QLineEdit(this); 
    searchLineEdit->setPlaceholderText("Search logs...");
    mainLayout->addWidget(searchLineEdit); 

    logArea = new QTextEdit(this);
    logArea->setReadOnly(true); 
    mainLayout->addWidget(logArea);

    setLayout(mainLayout); 

    connect(searchLineEdit, &QLineEdit::textChanged, this, &LogPanel::onSearchTextChanged);
}

void LogPanel::updatePanel(const QStringList& logs)
{
    // Gelen loglarÄ± dahili buffer'a ekle
    allLogsBuffer.append(logs);

    // Arama metni boÅŸ deÄŸilse, filtreleme yap
    if (!searchLineEdit->text().isEmpty()) {
        onSearchTextChanged(searchLineEdit->text()); // Mevcut arama metnine gÃ¶re yeniden filtrele
    } else {
        // Arama metni boÅŸsa, tÃ¼m yeni loglarÄ± doÄŸrudan append et
        // allLogsBuffer'Ä± temizleyip yeniden inÅŸa etmek yerine, sadece yeni gelenleri ekleyelim
        // Bu daha performanslÄ±dÄ±r.
        for (const QString& log : logs) {
            logArea->append(log);
        }
        // En alta kaydÄ±r
        logArea->verticalScrollBar()->setValue(logArea->verticalScrollBar()->maximum());
    }
}

// Arama kutusundaki metin deÄŸiÅŸtiÄŸinde tetiklenen slot
void LogPanel::onSearchTextChanged(const QString& searchText)
{
    logArea->clear(); // QTextEdit'i temizle

    if (searchText.isEmpty()) {
        // Arama metni boÅŸsa, tÃ¼m loglarÄ± gÃ¶ster
        for (const QString& log : allLogsBuffer) {
            logArea->append(log);
        }
    } else {
        // Arama metni varsa, sadece eÅŸleÅŸen loglarÄ± gÃ¶ster
        for (const QString& log : allLogsBuffer) {
            if (log.contains(searchText, Qt::CaseInsensitive)) { // BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarsÄ±z arama
                logArea->append(log); 
            }
        }
    }

    // Her filtreleme/arama sonrasÄ± en alta kaydÄ±r
    logArea->verticalScrollBar()->setValue(logArea->verticalScrollBar()->maximum());
} 
--- C:\Users\aib\CerebrumLux\src\gui\panels\LogPanel.h --- 
#ifndef LOGPANEL_H
#define LOGPANEL_H

#include <QWidget>
#include <QTextEdit> 
#include <QStringList> 
#include <QLineEdit> // YENÄ°: Arama kutusu iÃ§in
#include <QVBoxLayout> // YENÄ°: DÃ¼zenleme iÃ§in (eÄŸer henÃ¼z yoksa)

#include "../engine_integration.h" 

class LogPanel : public QWidget
{
    Q_OBJECT 
public:
    explicit LogPanel(QWidget* parent = nullptr);
    void updatePanel(const QStringList& logs); // Mevcut metot

    QTextEdit* getLogTextEdit() const { return logArea; }

private slots:
    // YENÄ°: Arama kutusundaki metin deÄŸiÅŸtiÄŸinde Ã§aÄŸrÄ±lacak slot
    void onSearchTextChanged(const QString& searchText);

private:
    QTextEdit* logArea; 
    QLineEdit* searchLineEdit; // YENÄ°: Arama kutusu
    QStringList allLogsBuffer; // YENÄ°: TÃ¼m loglarÄ± tutacak dahili buffer (filtreleme iÃ§in)
    QVBoxLayout* mainLayout; // YENÄ°: LogPanel'in ana dÃ¼zeni
};

#endif // LOGPANEL_H 
--- C:\Users\aib\CerebrumLux\src\gui\panels\SimulationPanel.cpp --- 
#include "SimulationPanel.h"
#include <QVBoxLayout>
#include <QHBoxLayout> 
#include <QLineEdit>   
#include <QPushButton> 
#include <QTableWidget>
#include <QTableWidgetItem>
#include <QStringList>
#include "../../core/logger.h" 
#include <QDebug> // YENÄ°: qDebug iÃ§in

SimulationPanel::SimulationPanel(QWidget* parent) : QWidget(parent)
{
    layout = new QVBoxLayout(this);

    // SimÃ¼lasyon kontrol alanÄ± (QLineEdit ve dÃ¼ÄŸmeler)
    controlLayout = new QHBoxLayout();
    commandLineEdit = new QLineEdit(this);
    commandLineEdit->setPlaceholderText("Enter simulation command...");
    startButton = new QPushButton("Start Simulation", this);
    stopButton = new QPushButton("Stop Simulation", this);

    controlLayout->addWidget(commandLineEdit);
    controlLayout->addWidget(startButton);
    controlLayout->addWidget(stopButton);

    layout->addLayout(controlLayout); 

    table = new QTableWidget(this);
    table->setColumnCount(2);
    table->setHorizontalHeaderLabels(QStringList() << "ID" << "Value"); // "Step" yerine "ID" yapÄ±ldÄ±
    layout->addWidget(table);
    setLayout(layout);

    // Sinyal-Slot baÄŸlantÄ±larÄ±
    // connect(commandLineEdit, &QLineEdit::returnPressed, this, &SimulationPanel::onCommandLineEditReturnPressed); // ESKÄ° BAÄžLANTI (Yorum satÄ±rÄ±)
    // YENÄ° TEÅžHÄ°S BAÄžLANTISI: Alternatif sinyal veya string tabanlÄ± baÄŸlantÄ± dene
    // Ã–nce QLineEdit::returnPressed'in hala Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol edelim.
    // EÄŸer bu iÅŸe yaramazsa, QLineEdit::editingFinished'i deneyebiliriz.

    // Qt 5 (ve 6) iÃ§in Ã¶nerilen yÃ¶ntem:
    // connect(commandLineEdit, &QLineEdit::returnPressed, this, &SimulationPanel::onCommandLineEditReturnPressed);

    // EÄŸer yukarÄ±daki yÃ¶ntem iÅŸe yaramÄ±yorsa, string tabanlÄ± eski yÃ¶ntemi deneyelim (MOC sorunlarÄ±nÄ± atlatmak iÃ§in)
    // Bu, MOC'un doÄŸru Ã§alÄ±ÅŸmadÄ±ÄŸÄ± durumlarda yardÄ±mcÄ± olabilir.
    bool connection_result = connect(commandLineEdit, SIGNAL(returnPressed()), this, SLOT(onCommandLineEditReturnPressed()));
    if (!connection_result) {
        qDebug() << "WARNING: QLineEdit::returnPressed connection failed in SimulationPanel constructor!";
    } else {
        qDebug() << "DEBUG: QLineEdit::returnPressed connected successfully in SimulationPanel constructor.";
    }

    connect(startButton, &QPushButton::clicked, this, &SimulationPanel::onStartSimulationClicked);
    connect(stopButton, &QPushButton::clicked, this, &SimulationPanel::onStopSimulationClicked);

    LOG_DEFAULT(LogLevel::INFO, "SimulationPanel: Initialized with input and control buttons.");
    qDebug() << "DEBUG: SimulationPanel constructor finished.";
}

void SimulationPanel::updatePanel(const std::vector<SimulationData>& data)
{
    table->setRowCount(static_cast<int>(data.size()));
    for (size_t i = 0; i < data.size(); ++i) {
        table->setItem(i, 0, new QTableWidgetItem(QString::fromStdString(data[i].id))); // ArtÄ±k string atamasÄ± doÄŸru
        table->setItem(i, 1, new QTableWidgetItem(QString::number(data[i].value)));
    }
}

// Slot implementasyonlarÄ±
void SimulationPanel::onCommandLineEditReturnPressed() {
    qDebug() << "DEBUG: SimulationPanel::onCommandLineEditReturnPressed slot triggered. (via qDebug)"; // YENÄ° TEÅžHÄ°S LOGU
    LOG_DEFAULT(LogLevel::DEBUG, "SimulationPanel: onCommandLineEditReturnPressed slot triggered."); 
    QString command = commandLineEdit->text();
    qDebug() << "DEBUG: SimulationPanel: CommandLineEdit text: '" << command << "' (isEmpty: " << command.isEmpty() << ")"; // YENÄ° TEÅžHÄ°S LOGU
    LOG_DEFAULT(LogLevel::DEBUG, "SimulationPanel: CommandLineEdit text: '" << command.toStdString() << "' (isEmpty: " << command.isEmpty() << ")"); 

    if (!command.isEmpty()) {
        LOG_DEFAULT(LogLevel::INFO, "SimulationPanel: Command entered: " << command.toStdString());
        emit commandEntered(command); 
        commandLineEdit->clear(); 
    } else {
        LOG_DEFAULT(LogLevel::WARNING, "SimulationPanel: Command entered was empty."); 
    }
}

void SimulationPanel::onStartSimulationClicked() {
    qDebug() << "DEBUG: SimulationPanel: Start Simulation button clicked. (via qDebug)";
    LOG_DEFAULT(LogLevel::INFO, "SimulationPanel: Start Simulation button clicked.");
    emit startSimulation(); 
}

void SimulationPanel::onStopSimulationClicked() {
    qDebug() << "DEBUG: SimulationPanel: Stop Simulation button clicked. (via qDebug)";
    LOG_DEFAULT(LogLevel::INFO, "SimulationPanel: Stop Simulation button clicked.");
    emit stopSimulation(); 
} 
--- C:\Users\aib\CerebrumLux\src\gui\panels\SimulationPanel.h --- 
#ifndef SIMULATIONPANEL_H
#define SIMULATIONPANEL_H

#include <QWidget>
#include <vector>
#include "../DataTypes.h" // SimulationData burada tanÄ±mlÄ±

// Forward declarations for Qt classes
class QTableWidget;
class QVBoxLayout;
class QHBoxLayout;  // YENÄ°: DÃ¼ÄŸmeler iÃ§in
class QLineEdit;    // YENÄ°: Metin giriÅŸi iÃ§in
class QPushButton;  // YENÄ°: DÃ¼ÄŸmeler iÃ§in

class SimulationPanel : public QWidget
{
    Q_OBJECT
public:
    explicit SimulationPanel(QWidget* parent = nullptr);
    void updatePanel(const std::vector<SimulationData>& data);

signals:
    // YENÄ°: KullanÄ±cÄ±dan alÄ±nan komutu dÄ±ÅŸarÄ±ya iletmek iÃ§in sinyal
    void commandEntered(const QString& command);
    // YENÄ°: SimÃ¼lasyonu baÅŸlatma sinyali
    void startSimulation();
    // YENÄ°: SimÃ¼lasyonu durdurma sinyali
    void stopSimulation();

private slots:
    // YENÄ°: KullanÄ±cÄ± metin girdisi tamamladÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lacak slot
    void onCommandLineEditReturnPressed();
    // YENÄ°: SimÃ¼lasyon baÅŸlat dÃ¼ÄŸmesine basÄ±ldÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lacak slot
    void onStartSimulationClicked();
    // YENÄ°: SimÃ¼lasyon durdur dÃ¼ÄŸmesine basÄ±ldÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lacak slot
    void onStopSimulationClicked();

private:
    // UI elemanlarÄ±
    QTableWidget* table;
    QVBoxLayout* layout;

    // YENÄ° UI elemanlarÄ±
    QLineEdit* commandLineEdit;    // KullanÄ±cÄ±dan komut almak iÃ§in
    QPushButton* startButton;      // SimÃ¼lasyonu baÅŸlatma dÃ¼ÄŸmesi
    QPushButton* stopButton;       // SimÃ¼lasyonu durdurma dÃ¼ÄŸmesi
    QHBoxLayout* controlLayout;    // DÃ¼ÄŸmeleri ve giriÅŸ alanÄ±nÄ± dÃ¼zenlemek iÃ§in
};

#endif // SIMULATIONPANEL_H 
--- C:\Users\aib\CerebrumLux\src\learning\Capsule.h --- 
#pragma once
#include <string>
#include <vector>
#include <nlohmann/json.hpp>
#include <chrono> // For std::chrono::system_clock::time_point

struct Capsule {
    std::string id;                          // YENÄ°: ID artÄ±k string
    float trust_score;                       // YENÄ°: GÃ¼ven skoru
    std::chrono::system_clock::time_point timestamp_utc; // YENÄ°: UTC zaman damgasÄ±
    std::vector<std::string> keywords;       // YENÄ°: Anahtar kelimeler
    float estimated_cost;                    // YENÄ°: Tahmini maliyet
    std::string plain_text_summary;          // YENÄ°: DÃ¼z metin Ã¶zeti
    std::string cryptofig_blob_base64;       // YENÄ°: Kriptofig blob'unun Base64 kodu
    std::string signature_base64;            // YENÄ°: Ä°mzanÄ±n Base64 kodu
    std::string encryption_iv_base64;        // YENÄ°: Åžifreleme IV'sinin Base64 kodu

    // Mevcut alanlar (bazÄ±larÄ±nÄ±n tipi deÄŸiÅŸti)
    std::string content;             // Orijinal iÃ§erik (plain text)
    std::string source;              // Kaynak (manual, web vs.)
    std::string topic;               // Konu baÅŸlÄ±ÄŸÄ±
    std::string encrypted_content;   // Cryptofig ile ÅŸifrelenmiÅŸ iÃ§erik (artÄ±k raw, base64 blob'u ile farklÄ±laÅŸacak)
    std::vector<float> embedding;    // Embedding vektÃ¶rÃ¼
    float confidence;                // GÃ¼ven skoru

    // JSONâ€™a serialize
    nlohmann::json toJson() const {
        // time_point'u ISO 8601 formatÄ±nda string'e dÃ¶nÃ¼ÅŸtÃ¼rme
        std::time_t tt = std::chrono::system_clock::to_time_t(timestamp_utc);
        std::tm tm = *std::gmtime(&tt); // UTC iÃ§in gmtime
        std::stringstream ss;
        ss << std::put_time(&tm, "%Y-%m-%dT%H:%M:%SZ");
        std::string timestamp_str = ss.str();

        return {
            {"id", id},
            {"trust_score", trust_score},
            {"timestamp_utc", timestamp_str},
            {"keywords", keywords},
            {"estimated_cost", estimated_cost},
            {"plain_text_summary", plain_text_summary},
            {"cryptofig_blob_base64", cryptofig_blob_base64},
            {"signature_base64", signature_base64},
            {"encryption_iv_base64", encryption_iv_base64},
            {"content", content},
            {"source", source},
            {"topic", topic},
            {"encrypted_content", encrypted_content},
            {"embedding", embedding},
            {"confidence", confidence}
        };
    }

    // JSONâ€™dan deserialize
    static Capsule fromJson(const nlohmann::json& j) {
        Capsule c;
        c.id = j.value("id", "");
        c.trust_score = j.value("trust_score", 0.0f);
        
        // ISO 8601 formatÄ±ndan time_point'a dÃ¶nÃ¼ÅŸtÃ¼rme
        std::string timestamp_str = j.value("timestamp_utc", "");
        if (!timestamp_str.empty()) {
            std::tm tm = {};
            std::stringstream ss(timestamp_str);
            ss >> std::get_time(&tm, "%Y-%m-%dT%H:%M:%SZ");
            if (!ss.fail()) {
                c.timestamp_utc = std::chrono::system_clock::from_time_t(std::mktime(&tm));
            }
        }

        c.keywords = j.value("keywords", std::vector<std::string>{});
        c.estimated_cost = j.value("estimated_cost", 0.0f);
        c.plain_text_summary = j.value("plain_text_summary", "");
        c.cryptofig_blob_base64 = j.value("cryptofig_blob_base64", "");
        c.signature_base64 = j.value("signature_base64", "");
        c.encryption_iv_base64 = j.value("encryption_iv_base64", "");

        c.content = j.value("content", "");
        c.source = j.value("source", "");
        c.topic = j.value("topic", "");
        c.encrypted_content = j.value("encrypted_content", "");
        c.embedding = j.value("embedding", std::vector<float>{});
        c.confidence = j.value("confidence", 0.0f);
        return c;
    }
}; 
--- C:\Users\aib\CerebrumLux\src\learning\KnowledgeBase.cpp --- 
#include "KnowledgeBase.h"
#include <fstream>
#include <nlohmann/json.hpp>
#include <cmath>
#include <algorithm> // std::sort, std::remove_if iÃ§in
#include <chrono>    // KapsÃ¼l zaman damgasÄ± iÃ§in (toJson/fromJson'da kullanÄ±lÄ±yor, burada dolaylÄ±)
#include "../core/logger.h" // LOG_DEFAULT iÃ§in
#include "../core/utils.h" // hash_string gibi yardÄ±mcÄ±lar iÃ§in (gerekliyse)


// YENÄ°: VarsayÄ±lan bilgi tabanÄ± dosyasÄ± adÄ±
const std::string DEFAULT_KNOWLEDGE_BASE_FILE = "knowledge_base.json"; 
const std::string QUARANTINE_KNOWLEDGE_BASE_FILE = "quarantine_knowledge_base.json"; // YENÄ°: Karantina dosyasÄ±

// Basit fake embedding hesaplayÄ±cÄ± (gerÃ§ek model entegre edilebilir)
std::vector<float> KnowledgeBase::computeEmbedding(const std::string& text) const {
    std::vector<float> emb(16, 0.0f); // 16 boyutlu kÃ¼Ã§Ã¼k vektÃ¶r
    for (size_t i = 0; i < text.size(); i++) {
        emb[i % 16] += static_cast<float>(text[i]) / 255.0f;
    }
    return emb;
}

float KnowledgeBase::cosineSimilarity(const std::vector<float>& a, const std::vector<float>& b) const {
    float dot = 0, normA = 0, normB = 0;
    if (a.empty() || b.empty() || a.size() != b.size()) {
        return 0.0f; // Boyut uyuÅŸmazlÄ±ÄŸÄ± durumunda 0 dÃ¶ndÃ¼r
    }
    for (size_t i = 0; i < a.size(); i++) {
        dot += a[i] * b[i];
        normA += a[i] * a[i];
        normB += b[i] * b[i];
    }
    float denominator = std::sqrt(normA) * std::sqrt(normB);
    if (denominator < 1e-6) return 0.0f; // SÄ±fÄ±ra bÃ¶lme hatasÄ±nÄ± Ã¶nle
    return dot / denominator;
}

// addCapsule -> add_capsule
void KnowledgeBase::add_capsule(const Capsule& capsule) {
    Capsule c = capsule;
    c.embedding = computeEmbedding(c.content);
    capsules.push_back(c);
    LOG_DEFAULT(LogLevel::INFO, "KnowledgeBase: KapsÃ¼l eklendi. ID: " << c.id << ", Konu: " << c.topic);
}

// findSimilar -> semantic_search
std::vector<Capsule> KnowledgeBase::semantic_search(const std::string& query, int top_k) const { // CONST EKLENDÄ°
    std::vector<float> q_emb = computeEmbedding(query);
    std::vector<std::pair<float, Capsule>> scored;

    for (const auto& c : capsules) {
        float sim = cosineSimilarity(q_emb, c.embedding);
        scored.push_back({sim, c});
    }

    std::sort(scored.begin(), scored.end(), [](auto& a, auto& b) {
        return a.first > b.first;
    });

    std::vector<Capsule> results;
    for (int i = 0; i < top_k && i < (int)scored.size(); i++) {
        results.push_back(scored[i].second);
    }
    LOG_DEFAULT(LogLevel::DEBUG, "KnowledgeBase: Semantik arama tamamlandÄ±. Sorgu: '" << query << "', SonuÃ§ sayÄ±sÄ±: " << results.size());
    return results;
}

// getCapsulesByTopic -> search_by_topic
std::vector<Capsule> KnowledgeBase::search_by_topic(const std::string& topic) const {
    std::vector<Capsule> filtered_capsules;
    for (const auto& capsule : capsules) {
        if (capsule.topic == topic) {
            filtered_capsules.push_back(capsule);
        }
    }
    LOG_DEFAULT(LogLevel::DEBUG, "KnowledgeBase: Konuya gÃ¶re arama tamamlandÄ±. Konu: '" << topic << "', SonuÃ§ sayÄ±sÄ±: " << filtered_capsules.size());
    return filtered_capsules;
}

// YENÄ°: Capsule ID'ye gÃ¶re arama metodu eklendi
std::optional<Capsule> KnowledgeBase::find_capsule_by_id(const std::string& id) const {
    for (const auto& capsule : capsules) {
        if (capsule.id == id) {
            return capsule;
        }
    }
    for (const auto& capsule : quarantined_capsules) { // Karantinadaki kapsÃ¼ller de kontrol edilir
        if (capsule.id == id) {
            return capsule;
        }
    }
    LOG_DEFAULT(LogLevel::WARNING, "KnowledgeBase: ID ile kapsÃ¼l bulunamadÄ±: " << id);
    return std::nullopt;
}

// YENÄ°: Metin ÅŸifreleme metodu implementasyonu (basit XOR)
std::string KnowledgeBase::encrypt(const std::string& data) const {
    std::string encrypted_data = data;
    char key = 0x5A; // Basit bir XOR anahtarÄ± (01011010)
    for (char &c : encrypted_data) {
        c ^= key;
    }
    return encrypted_data;
}

// YENÄ°: Metin ÅŸifre Ã§Ã¶zme metodu implementasyonu (basit XOR)
std::string KnowledgeBase::decrypt(const std::string& encrypted_data) const {
    // XOR iÅŸlemi kendi tersidir, bu yÃ¼zden aynÄ± fonksiyonu kullanabiliriz
    return encrypt(encrypted_data);
}

// YENÄ°: KapsÃ¼lÃ¼ karantinaya al
bool KnowledgeBase::quarantine_capsule(const std::string& capsule_id) {
    auto it = std::remove_if(capsules.begin(), capsules.end(), [&](const Capsule& c){
        return c.id == capsule_id;
    });

    if (it != capsules.end()) {
        quarantined_capsules.insert(quarantined_capsules.end(), std::make_move_iterator(it), std::make_move_iterator(capsules.end()));
        capsules.erase(it, capsules.end());
        LOG_DEFAULT(LogLevel::WARNING, "KnowledgeBase: KapsÃ¼l karantinaya alÄ±ndÄ±. ID: " << capsule_id);
        save(DEFAULT_KNOWLEDGE_BASE_FILE);
        save_quarantined_capsules(); // Karantina kapsÃ¼llerini de kaydet
        return true;
    }
    LOG_DEFAULT(LogLevel::WARNING, "KnowledgeBase: Karantinaya alÄ±nacak kapsÃ¼l bulunamadÄ±. ID: " << capsule_id);
    return false;
}

// YENÄ°: Karantinadaki kapsÃ¼lÃ¼ geri al
bool KnowledgeBase::revert_capsule(const std::string& capsule_id) {
    auto it = std::remove_if(quarantined_capsules.begin(), quarantined_capsules.end(), [&](const Capsule& c){
        return c.id == capsule_id;
    });

    if (it != quarantined_capsules.end()) {
        capsules.insert(capsules.end(), std::make_move_iterator(it), std::make_move_iterator(quarantined_capsules.end()));
        quarantined_capsules.erase(it, quarantined_capsules.end());
        LOG_DEFAULT(LogLevel::INFO, "KnowledgeBase: Karantinadaki kapsÃ¼l geri alÄ±ndÄ±. ID: " << capsule_id);
        save(DEFAULT_KNOWLEDGE_BASE_FILE);
        save_quarantined_capsules(); // Karantina kapsÃ¼llerini de kaydet
        return true;
    }
    LOG_DEFAULT(LogLevel::WARNING, "KnowledgeBase: Geri alÄ±nacak kapsÃ¼l karantinada bulunamadÄ±. ID: " << capsule_id);
    return false;
}

// YENÄ°: Karantinadaki kapsÃ¼lleri kaydetme
void KnowledgeBase::save_quarantined_capsules() const {
    nlohmann::json j;
    for (const auto& c : quarantined_capsules) {
        j.push_back(c.toJson());
    }
    std::ofstream f(QUARANTINE_KNOWLEDGE_BASE_FILE);
    if (f.is_open()) {
        f << j.dump(2);
        LOG_DEFAULT(LogLevel::INFO, "KnowledgeBase: Karantinadaki kapsÃ¼ller kaydedildi: " << QUARANTINE_KNOWLEDGE_BASE_FILE);
    } else {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "KnowledgeBase: Karantina kapsÃ¼l dosyasÄ± aÃ§Ä±lamadÄ±: " << QUARANTINE_KNOWLEDGE_BASE_FILE);
    }
}

// YENÄ°: Karantinadaki kapsÃ¼lleri yÃ¼kleme
void KnowledgeBase::load_quarantined_capsules() {
    std::ifstream f(QUARANTINE_KNOWLEDGE_BASE_FILE);
    if (!f.is_open()) {
        LOG_DEFAULT(LogLevel::WARNING, "KnowledgeBase: Karantinadaki kapsÃ¼l dosyasÄ± bulunamadÄ±, boÅŸ olarak baÅŸlatÄ±lÄ±yor: " << QUARANTINE_KNOWLEDGE_BASE_FILE);
        return;
    }
    nlohmann::json j;
    try {
        f >> j;
        quarantined_capsules.clear();
        for (auto& el : j) {
            quarantined_capsules.push_back(Capsule::fromJson(el));
        }
        LOG_DEFAULT(LogLevel::INFO, "KnowledgeBase: Karantinadaki kapsÃ¼ller yÃ¼klendi: " << QUARANTINE_KNOWLEDGE_BASE_FILE << ", SayÄ±: " << quarantined_capsules.size());
    } catch (const nlohmann::json::parse_error& e) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "KnowledgeBase: Karantina JSON dosyasÄ± ayrÄ±ÅŸtÄ±rma hatasÄ±: " << e.what());
    } catch (const std::exception& e) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "KnowledgeBase: Karantina kapsÃ¼llerini yÃ¼klerken hata oluÅŸtu: " << e.what());
    }
}

// Parametresiz save metodu implementasyonu
void KnowledgeBase::save() const {
    save(DEFAULT_KNOWLEDGE_BASE_FILE); // DiÄŸer save metodunu Ã§aÄŸÄ±rÄ±r
    save_quarantined_capsules(); // Karantinadaki kapsÃ¼lleri de kaydet
}

void KnowledgeBase::save(const std::string& filename) const {
    nlohmann::json j;
    for (const auto& c : capsules) {
        j.push_back(c.toJson());
    }
    std::ofstream f(filename);
    if (f.is_open()) {
        f << j.dump(2);
        LOG_DEFAULT(LogLevel::INFO, "KnowledgeBase: Bilgi tabanÄ± kaydedildi: " << filename);
    } else {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "KnowledgeBase: Bilgi tabanÄ± dosyasÄ± aÃ§Ä±lamadÄ±: " << filename);
    }
}

void KnowledgeBase::load(const std::string& filename) {
    std::ifstream f(filename);
    if (!f.is_open()) {
        LOG_DEFAULT(LogLevel::WARNING, "KnowledgeBase: Bilgi tabanÄ± dosyasÄ± bulunamadÄ±, boÅŸ olarak baÅŸlatÄ±lÄ±yor: " << filename);
        return;
    }
    nlohmann::json j;
    try {
        f >> j;
        capsules.clear();
        for (auto& el : j) {
            capsules.push_back(Capsule::fromJson(el));
        }
        LOG_DEFAULT(LogLevel::INFO, "KnowledgeBase: Bilgi tabanÄ± yÃ¼klendi: " << filename << ", SayÄ±: " << capsules.size());
    } catch (const nlohmann::json::parse_error& e) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "KnowledgeBase: JSON dosyasÄ± ayrÄ±ÅŸtÄ±rma hatasÄ±: " << e.what());
    } catch (const std::exception& e) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "KnowledgeBase: KapsÃ¼lleri yÃ¼klerken hata oluÅŸtu: " << e.what());
    }
    load_quarantined_capsules(); // Karantinadaki kapsÃ¼lleri de yÃ¼kle
} 
--- C:\Users\aib\CerebrumLux\src\learning\KnowledgeBase.h --- 
#pragma once
#include "Capsule.h"
#include <vector>
#include <string>
#include <optional> // YENÄ°: find_capsule_by_id iÃ§in

class KnowledgeBase {
public:
    // Metot isimlendirmeleri gÃ¼ncellendi
    void add_capsule(const Capsule& capsule); // addCapsule -> add_capsule
    std::vector<Capsule> semantic_search(const std::string& query, int top_k = 3) const; // findSimilar -> semantic_search, const eklendi
    std::vector<Capsule> search_by_topic(const std::string& topic) const; // getCapsulesByTopic -> search_by_topic
    
    // YENÄ°: Capsule ID'ye gÃ¶re arama metodu eklendi
    std::optional<Capsule> find_capsule_by_id(const std::string& id) const;

    // Karantina ve geri alma metotlarÄ± eklendi
    bool quarantine_capsule(const std::string& capsule_id);
    bool revert_capsule(const std::string& capsule_id);

    // Kaydetme/YÃ¼kleme metotlarÄ±
    void save(const std::string& filename) const;
    void load(const std::string& filename);
    void save() const; // Parametresiz save metodu

    // Åžifreleme metodu (ÅŸimdilik basit XOR, LearningModule'de gÃ¼Ã§lendirilecek)
    std::string encrypt(const std::string& data) const;
    std::string decrypt(const std::string& encrypted_data) const; // YENÄ°: Decrypt metodu eklendi

    // Embedding hesaplama metodunu public ve CONST yapÄ±yoruz
    std::vector<float> computeEmbedding(const std::string& text) const; // CONST EKLENDÄ°
    float cosineSimilarity(const std::vector<float>& a, const std::vector<float>& b) const; // CONST EKLENDÄ°

    // Karantinadaki kapsÃ¼lleri kaydetme/yÃ¼kleme bildirimleri
    void save_quarantined_capsules() const; 
    void load_quarantined_capsules();     

private:
    std::vector<Capsule> capsules;
    std::vector<Capsule> quarantined_capsules; // Karantinaya alÄ±nan kapsÃ¼ller
}; 
--- C:\Users\aib\CerebrumLux\src\learning\LearningModule.cpp --- 
#include "LearningModule.h" 
#include <iostream>
#include <algorithm> 
#include "../core/logger.h" 
#include "../learning/WebFetcher.h" 
#include "../core/utils.h" 
#include "../external/nlohmann/json.hpp" 

// OpenSSL BaÅŸlÄ±klarÄ± (Bu dosya iÃ§inde OpenSSL API'leri doÄŸrudan kullanÄ±lacak)
#include <openssl/crypto.h> 
#include <openssl/ssl.h>    
#include <openssl/evp.h>    
#include <openssl/rand.h>   
#include <openssl/err.h>    
#include <openssl/bio.h>    
#include <openssl/buffer.h> 
// #include <openssl/ed25519.h> // Yorum satÄ±rÄ± kalÄ±yor

// YENÄ°: UnicodeSanitizer ve StegoDetector baÅŸlÄ±k dosyalarÄ±
#include "UnicodeSanitizer.h"
#include "StegoDetector.h"

// KapsÃ¼l ID sayacÄ±nÄ± string ID'lere uyarlamak iÃ§in (isteÄŸe baÄŸlÄ±)
static unsigned int s_learning_module_capsule_id_counter = 0;

// ================================================================
// base64_encode_internal ve base64_decode_internal implementasyonlarÄ±
// ================================================================

std::string LearningModule::base64_encode_internal(const std::string& in) const {
    BIO *b64, *bmem;
    BUF_MEM *bptr;

    b64 = BIO_new(BIO_f_base64());
    bmem = BIO_new(BIO_s_mem());
    b64 = BIO_push(b64, bmem);
    BIO_set_flags(b64, BIO_FLAGS_BASE64_NO_NL); 
    BIO_write(b64, in.data(), static_cast<int>(in.size()));
    BIO_flush(b64);

    char *data;
    long len = BIO_get_mem_data(bmem, &data); 
    std::string out(data, len);

    BIO_free_all(b64);
    return out;
}

std::string LearningModule::base64_decode_internal(const std::string& in) const {
    BIO *b64, *bmem;
    char* buffer = nullptr;
    size_t length = 0;

    b64 = BIO_new(BIO_f_base64());
    bmem = BIO_new_mem_buf(in.data(), static_cast<int>(in.size())); 
    b64 = BIO_push(b64, bmem);
    BIO_set_flags(b64, BIO_FLAGS_BASE64_NO_NL);

    length = in.length();
    buffer = (char*)OPENSSL_malloc(length + 1); 
    if (!buffer) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Base64 decode iÃ§in bellek ayrÄ±lamadÄ±.");
        return "";
    }
    
    int decoded_len = BIO_read(b64, buffer, static_cast<int>(length));
    if (decoded_len < 0) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Base64 kod Ã§Ã¶zme hatasÄ±.");
        OPENSSL_free(buffer);
        BIO_free_all(b64);
        return "";
    }
    buffer[decoded_len] = '\0'; 

    std::string out(buffer, decoded_len);
    OPENSSL_free(buffer);
    BIO_free_all(b64);
    return out;
}

// ================================================================
// Yeni public virtual Base64 string metotlarÄ±nÄ±n implementasyonu
// ================================================================

std::string LearningModule::base64_encode_string(const std::string& data) const {
    return this->base64_encode_internal(data);
}

std::string LearningModule::base64_decode_string(const std::string& data) const {
    return this->base64_decode_internal(data);
}

// ================================================================

// Kurucu
LearningModule::LearningModule(KnowledgeBase& kb) 
    : knowledgeBase(kb),
      unicodeSanitizer(std::make_unique<UnicodeSanitizer>()), 
      stegoDetector(std::make_unique<StegoDetector>())      
{
    LOG_DEFAULT(LogLevel::INFO, "LearningModule: Initialized.");
}

// YÄ±kÄ±cÄ±
LearningModule::~LearningModule() {
    LOG_DEFAULT(LogLevel::INFO, "LearningModule: Destructor called.");
}

void LearningModule::learnFromText(const std::string& text,
                                   const std::string& source,
                                   const std::string& topic,
                                   float confidence)
{
    Capsule c;
    c.id = "capsule_" + std::to_string(++s_learning_module_capsule_id_counter); 
    c.topic = topic;
    c.source = source;
    c.content = text; 
    c.confidence = confidence;
    c.plain_text_summary = text.substr(0, std::min((size_t)100, text.length())) + "...";
    c.timestamp_utc = std::chrono::system_clock::now();
    
    c.embedding = this->compute_embedding(c.content); 
    c.cryptofig_blob_base64 = this->cryptofig_encode(c.embedding); 

    std::string my_aes_key = this->get_aes_key_for_peer("Self"); 
    std::string iv = this->generate_random_bytes(EVP_CIPHER_iv_length(EVP_aes_256_gcm())); 
    c.encryption_iv_base64 = this->base64_encode_string(iv); // Yeni public metot kullanÄ±ldÄ±
    c.encrypted_content = this->aes_gcm_encrypt(c.content, my_aes_key, iv); 

    // Ed25519 fonksiyonlarÄ± yorum satÄ±rÄ± yapÄ±ldÄ±ÄŸÄ± iÃ§in burada da simÃ¼le ediyoruz
    // std::string my_private_key = this->get_my_private_key(); 
    // c.signature_base64 = this->ed25519_sign(c.encrypted_content, my_private_key); 
    c.signature_base64 = "valid_signature_placeholder"; // GeÃ§ici simÃ¼lasyon

    knowledgeBase.add_capsule(c); 
    knowledgeBase.save(); 
    LOG_DEFAULT(LogLevel::INFO, "LearningModule: Learned from text. Topic: " << topic << ", ID: " << c.id);
}

void LearningModule::learnFromWeb(const std::string& query) {
    WebFetcher fetcher;
    auto results = fetcher.search(query);

    for (auto& r : results) {
        learnFromText(r.content, r.source, query, 0.9f);
    }
    LOG_DEFAULT(LogLevel::INFO, "LearningModule: Learned from web query: " << query);
}

std::vector<Capsule> LearningModule::search_by_topic(const std::string& topic) const {
    return knowledgeBase.search_by_topic(topic);
}

KnowledgeBase& LearningModule::getKnowledgeBase() {
    return knowledgeBase;
}

const KnowledgeBase& LearningModule::getKnowledgeBase() const {
    return knowledgeBase;
}


void LearningModule::process_ai_insights(const std::vector<AIInsight>& insights) {
    LOG_DEFAULT(LogLevel::INFO, "[LearningModule] AI Insights isleniyor: " << insights.size() << " adet iÃ§gÃ¶rÃ¼.");
    for (const auto& insight : insights) {
        Capsule c;
        c.id = "insight_" + std::to_string(++s_learning_module_capsule_id_counter); 
        c.content = insight.observation; 
        c.source = "AIInsightsEngine";
        c.topic = "AI Insight"; 
        c.confidence = insight.urgency; 
        c.plain_text_summary = insight.observation.substr(0, std::min((size_t)100, insight.observation.length())) + "...";
        c.timestamp_utc = std::chrono::system_clock::now();
        
        c.embedding = this->compute_embedding(c.content); 
        c.cryptofig_blob_base64 = this->cryptofig_encode(c.embedding); 

        std::string my_aes_key = this->get_aes_key_for_peer("Self"); 
        std::string iv = this->generate_random_bytes(EVP_CIPHER_iv_length(EVP_aes_256_gcm())); 
        c.encryption_iv_base64 = this->base64_encode_string(iv); // Yeni public metot kullanÄ±ldÄ±
        c.encrypted_content = this->aes_gcm_encrypt(c.content, my_aes_key, iv); 

        // Ed25519 fonksiyonlarÄ± yorum satÄ±rÄ± yapÄ±ldÄ±ÄŸÄ± iÃ§in burada da simÃ¼le ediyoruz
        // std::string my_private_key = this->get_my_private_key();
        // c.signature_base64 = this->ed25519_sign(c.encrypted_content, my_private_key);
        c.signature_base64 = "valid_signature_placeholder"; // GeÃ§ici simÃ¼lasyon

        knowledgeBase.add_capsule(c); 
        LOG_DEFAULT(LogLevel::INFO, "[LearningModule] KnowledgeBase'e iÃ§gÃ¶rÃ¼ kapsÃ¼lÃ¼ eklendi: " << c.content.substr(0, std::min((size_t)30, c.content.length())) << "..., ID: " << c.id);
    }
    knowledgeBase.save(); 
}

IngestReport LearningModule::ingest_envelope(const Capsule& envelope, const std::string& signature, const std::string& sender_id) {
    IngestReport report;
    report.original_capsule = envelope;
    report.timestamp = std::chrono::system_clock::now();
    report.source_peer_id = sender_id;
    report.processed_capsule = envelope; 

    LOG_DEFAULT(LogLevel::INFO, "LearningModule: Ingesting envelope from " << sender_id << " with ID: " << envelope.id << "...");

    if (!this->verify_signature(report.processed_capsule, signature, sender_id)) { 
        report.result = IngestResult::InvalidSignature;
        report.message = "Signature verification failed.";
        this->audit_log_append(report); 
        knowledgeBase.quarantine_capsule(report.processed_capsule.id); 
        return report;
    }
    LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: Signature verified for capsule ID: " << envelope.id);

    Capsule decrypted_capsule = this->decrypt_payload(report.processed_capsule); 
    if (decrypted_capsule.content.empty() && !report.processed_capsule.encrypted_content.empty()) { 
        report.result = IngestResult::DecryptionFailed;
        report.message = "Payload decryption failed.";
        this->audit_log_append(report); 
        knowledgeBase.quarantine_capsule(report.processed_capsule.id); 
        return report;
    }
    report.processed_capsule = decrypted_capsule; 
    LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: Payload decrypted for capsule ID: " << envelope.id);

    if (!this->schema_validate(report.processed_capsule)) { 
        report.result = IngestResult::SchemaMismatch;
        report.message = "Capsule schema mismatch.";
        this->audit_log_append(report); 
        knowledgeBase.quarantine_capsule(report.processed_capsule.id); 
        return report;
    }
    LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: Schema validated for capsule ID: " << envelope.id);

    Capsule sanitized_capsule = this->sanitize_unicode(report.processed_capsule); 
    if (sanitized_capsule.content != report.processed_capsule.content) { 
        report.result = IngestResult::SanitizationNeeded; 
        report.message = "Unicode sanitization applied.";
        report.processed_capsule = sanitized_capsule; 
        LOG_DEFAULT(LogLevel::INFO, "LearningModule: Unicode sanitization applied to capsule ID: " << envelope.id);
    } else {
        LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: Unicode sanitation not needed for capsule ID: " << envelope.id);
    }
    
    if (this->run_steganalysis(report.processed_capsule)) { 
        report.result = IngestResult::SteganographyDetected;
        report.message = "Steganography detected in capsule content.";
        this->audit_log_append(report); 
        knowledgeBase.quarantine_capsule(report.processed_capsule.id); 
        return report;
    }
    LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: Steganography check passed for capsule ID: " << envelope.id);

    if (!this->sandbox_analysis(report.processed_capsule)) { 
        report.result = IngestResult::SandboxFailed;
        report.message = "Sandbox analysis indicated potential threat.";
        this->audit_log_append(report); 
        knowledgeBase.quarantine_capsule(report.processed_capsule.id); 
        return report;
    }
    LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: Sandbox analysis passed for capsule ID: " << envelope.id);

    if (!this->corroboration_check(report.processed_capsule)) { 
        report.result = IngestResult::CorroborationFailed;
        report.message = "Corroboration check failed against existing knowledge.";
        this->audit_log_append(report); 
        knowledgeBase.quarantine_capsule(report.processed_capsule.id); 
        return report;
    }
    LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: Corroboration check passed for capsule ID: " << envelope.id);

    knowledgeBase.add_capsule(report.processed_capsule); 
    knowledgeBase.save(); 
    report.result = IngestResult::Success;
    report.message = "Capsule ingested successfully.";
    this->audit_log_append(report); 
    LOG_DEFAULT(LogLevel::INFO, "LearningModule: Capsule ingested successfully from " << sender_id << ", ID: " << envelope.id);
    return report;
}

bool LearningModule::verify_signature(const Capsule& capsule, const std::string& signature, const std::string& sender_id) const {
    if (sender_id == "Self") { 
        return true;
    }

    if (capsule.signature_base64.empty()) { 
        LOG_DEFAULT(LogLevel::WARNING, "LearningModule: Signature missing in capsule ID: " << capsule.id << " from " << sender_id);
        return false;
    }

    // Ed25519 doÄŸrulamasÄ±nÄ± ÅŸimdilik simÃ¼le ediyoruz
    // std::string message_to_verify = capsule.encrypted_content;
    // std::string signature_bytes = this->base64_decode_string(capsule.signature_base64); // Yeni public metot
    // std::string public_key_bytes = this->get_public_key_for_peer(sender_id); 
    // return this->ed25519_verify(message_to_verify, signature_bytes, public_key_bytes); 
    
    // GeÃ§ici olarak sadece gelen signature ile "valid_signature" stringini karÅŸÄ±laÅŸtÄ±rÄ±yoruz.
    return signature == "valid_signature"; 
}

Capsule LearningModule::decrypt_payload(const Capsule& encrypted_capsule) const {
    Capsule decrypted = encrypted_capsule;

    if (encrypted_capsule.encrypted_content.empty()) {
        LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: Encrypted content is empty for capsule ID: " << encrypted_capsule.id << ". Assuming plain text.");
        decrypted.content = encrypted_capsule.content; 
        return decrypted;
    }

    std::string aes_key = this->get_aes_key_for_peer(encrypted_capsule.source); 
    std::string iv = this->base64_decode_string(encrypted_capsule.encryption_iv_base64); // Yeni public metot

    decrypted.content = this->aes_gcm_decrypt(encrypted_capsule.encrypted_content, aes_key, iv); 

    if (decrypted.content.empty() && !encrypted_capsule.encrypted_content.empty()) {
        LOG_DEFAULT(LogLevel::WARNING, "LearningModule: Decryption resulted in empty content for capsule ID: " << encrypted_capsule.id);
    }
    return decrypted;
}

bool LearningModule::schema_validate(const Capsule& capsule) const { 
    bool valid = !capsule.id.empty() && !capsule.content.empty() && !capsule.source.empty() && !capsule.topic.empty() && 
                 !capsule.cryptofig_blob_base64.empty() && !capsule.signature_base64.empty() && !capsule.encryption_iv_base64.empty();

    if (!valid) {
        LOG_DEFAULT(LogLevel::WARNING, "LearningModule: Schema validation failed for capsule ID: " << capsule.id << ". Missing required fields.");
    }
    return valid;
}

Capsule LearningModule::sanitize_unicode(const Capsule& capsule) const { 
    Capsule sanitized_capsule = capsule;
    if (this->unicodeSanitizer) { 
        sanitized_capsule.content = this->unicodeSanitizer->sanitize(capsule.content); 
        if (sanitized_capsule.content != capsule.content) {
            LOG_DEFAULT(LogLevel::INFO, "LearningModule: Unicode sanitization changed content for capsule ID: " << capsule.id);
        }
    } else {
        LOG_DEFAULT(LogLevel::WARNING, "LearningModule: UnicodeSanitizer not available for sanitization for capsule ID: " << capsule.id);
    }
    return sanitized_capsule;
}

bool LearningModule::run_steganalysis(const Capsule& capsule) const { 
    if (this->stegoDetector) { 
        if (this->stegoDetector->detectSteganography(capsule.content)) { 
            LOG_DEFAULT(LogLevel::WARNING, "LearningModule: Steganography detected in capsule ID: " << capsule.id);
            return true;
        }
    } else {
        LOG_DEFAULT(LogLevel::WARNING, "LearningModule: StegoDetector not available for steganalysis for capsule ID: " << capsule.id);
    }
    return false;
}

bool LearningModule::sandbox_analysis(const Capsule& capsule) const { 
    if (capsule.content.find("malware_signature") != std::string::npos ||
        capsule.content.find("exploit_code") != std::string::npos) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "LearningModule: Sandbox analysis detected potential threat in capsule ID: " << capsule.id);
        return false; 
    }
    return true; 
}

bool LearningModule::corroboration_check(const Capsule& capsule) const { 
    auto similar_capsules = knowledgeBase.semantic_search(capsule.content, 1); 
    if (!similar_capsules.empty() && similar_capsules[0].confidence > 0.95f && similar_capsules[0].id != capsule.id) { 
        LOG_DEFAULT(LogLevel::WARNING, "LearningModule: Corroboration check found highly similar existing knowledge for capsule ID: " << capsule.id << ". Similar to existing capsule ID: " << similar_capsules[0].id);
    }
    return true; 
}

void LearningModule::audit_log_append(const IngestReport& report) const { 
    LOG_DEFAULT(LogLevel::WARNING, "LearningModule: Ingest Audit Report - Result: " << static_cast<int>(report.result) 
                                      << ", Message: " << report.message 
                                      << ", Source Peer: " << report.source_peer_id 
                                      << ", Original Capsule ID: " << report.original_capsule.id);
}

// Kriptografik ve Embedding AltyapÄ±sÄ± ImplementasyonlarÄ± (Ä°skeletler)

std::vector<float> LearningModule::compute_embedding(const std::string& text) const {
    LOG_DEFAULT(LogLevel::DEBUG, "LearningModule: compute_embedding (KnowledgeBase'den) Ã§aÄŸrÄ±ldÄ±.");
    return knowledgeBase.computeEmbedding(text); 
}

std::string LearningModule::cryptofig_encode(const std::vector<float>& cryptofig_vector) const {
    nlohmann::json j = cryptofig_vector;
    std::string serialized_cryptofig = j.dump();
    return this->base64_encode_internal(serialized_cryptofig); // this-> eklendi
}

std::vector<float> LearningModule::cryptofig_decode_base64(const std::string& base64_cryptofig_blob) const {
    std::string serialized_cryptofig = this->base64_decode_internal(base64_cryptofig_blob); // this-> eklendi
    try {
        nlohmann::json j = nlohmann::json::parse(serialized_cryptofig);
        return j.get<std::vector<float>>();
    } catch (const nlohmann::json::parse_error& e) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "LearningModule: cryptofig_decode_base64 JSON ayrÄ±ÅŸtÄ±rma hatasÄ±: " << e.what());
        return {};
    }
}

std::string LearningModule::aes_gcm_encrypt(const std::string& plaintext, const std::string& key, const std::string& iv) const {
    EVP_CIPHER_CTX *ctx;
    int len;
    int ciphertext_len;

    int max_len = plaintext.length() + EVP_CIPHER_block_size(EVP_aes_256_gcm()) + 16;
    unsigned char* ciphertext_buf = (unsigned char*)OPENSSL_malloc(max_len);
    unsigned char* tag_buf = (unsigned char*)OPENSSL_malloc(16); 

    if (!ciphertext_buf || !tag_buf) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "AES-GCM encrypt iÃ§in bellek ayrÄ±lamadÄ±.");
        OPENSSL_free(ciphertext_buf);
        OPENSSL_free(tag_buf);
        return "";
    }

    if (!(ctx = EVP_CIPHER_CTX_new())) {
        ERR_print_errors_fp(stderr);
        OPENSSL_free(ciphertext_buf);
        OPENSSL_free(tag_buf);
        return "";
    }

    if (1 != EVP_EncryptInit_ex(ctx, EVP_aes_256_gcm(), NULL, NULL, NULL)) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(ciphertext_buf);
        OPENSSL_free(tag_buf);
        return "";
    }

    if (1 != EVP_CIPHER_CTX_ctrl(ctx, EVP_CTRL_GCM_SET_IVLEN, (int)iv.length(), NULL)) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(ciphertext_buf);
        OPENSSL_free(tag_buf);
        return "";
    }

    if (1 != EVP_EncryptInit_ex(ctx, NULL, NULL, (const unsigned char*)key.c_str(), (const unsigned char*)iv.c_str())) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(ciphertext_buf);
        OPENSSL_free(tag_buf); 
        return "";
    }

    if (1 != EVP_EncryptUpdate(ctx, ciphertext_buf, &len, (const unsigned char*)plaintext.c_str(), static_cast<int>(plaintext.length()))) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(ciphertext_buf);
        OPENSSL_free(tag_buf);
        return "";
    }
    ciphertext_len = len;

    if (1 != EVP_EncryptFinal_ex(ctx, ciphertext_buf + len, &len)) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(ciphertext_buf);
        OPENSSL_free(tag_buf);
        return "";
    }
    ciphertext_len += len;

    if (1 != EVP_CIPHER_CTX_ctrl(ctx, EVP_CTRL_GCM_GET_TAG, 16, tag_buf)) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(ciphertext_buf);
        OPENSSL_free(tag_buf);
        return "";
    }

    EVP_CIPHER_CTX_free(ctx);

    std::string result((char*)ciphertext_buf, ciphertext_len);
    result.append((char*)tag_buf, 16); 

    OPENSSL_free(ciphertext_buf);
    OPENSSL_free(tag_buf);
    return this->base64_encode_internal(result); // this-> eklendi
}

std::string LearningModule::aes_gcm_decrypt(const std::string& ciphertext_base64, const std::string& key, const std::string& iv) const {
    std::string combined_data = this->base64_decode_internal(ciphertext_base64); // this-> eklendi

    size_t tag_len = 16; 
    if (combined_data.length() < tag_len) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "AES-GCM decrypt: GeÃ§ersiz ciphertext uzunluÄŸu (tag eksik).");
        return "";
    }

    std::string ciphertext_str = combined_data.substr(0, combined_data.length() - tag_len);
    std::string tag_str = combined_data.substr(combined_data.length() - tag_len);

    EVP_CIPHER_CTX *ctx;
    int len;
    int plaintext_len;

    unsigned char* plaintext_buf = (unsigned char*)OPENSSL_malloc(ciphertext_str.length() + EVP_CIPHER_block_size(EVP_aes_256_gcm()));
    if (!plaintext_buf) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "AES-GCM decrypt iÃ§in bellek ayrÄ±lamadÄ±.");
        return "";
    }

    if (!(ctx = EVP_CIPHER_CTX_new())) {
        ERR_print_errors_fp(stderr);
        OPENSSL_free(plaintext_buf);
        return "";
    }

    if (1 != EVP_DecryptInit_ex(ctx, EVP_aes_256_gcm(), NULL, NULL, NULL)) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(plaintext_buf);
        return "";
    }

    if (1 != EVP_CIPHER_CTX_ctrl(ctx, EVP_CTRL_GCM_SET_IVLEN, (int)iv.length(), NULL)) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(plaintext_buf);
        return "";
    }

    if (1 != EVP_DecryptInit_ex(ctx, NULL, NULL, (const unsigned char*)key.c_str(), (const unsigned char*)iv.c_str())) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(plaintext_buf);
        return "";
    }

    if (1 != EVP_DecryptUpdate(ctx, plaintext_buf, &len, (const unsigned char*)ciphertext_str.c_str(), static_cast<int>(ciphertext_str.length()))) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(plaintext_buf);
        return "";
    }
    plaintext_len = len;

    if (1 != EVP_CIPHER_CTX_ctrl(ctx, EVP_CTRL_GCM_SET_TAG, (int)tag_str.length(), (void*)tag_str.c_str())) {
        ERR_print_errors_fp(stderr);
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(plaintext_buf);
        return "";
    }

    if (1 != EVP_DecryptFinal_ex(ctx, plaintext_buf + len, &len)) {
        ERR_print_errors_fp(stderr); 
        EVP_CIPHER_CTX_free(ctx);
        OPENSSL_free(plaintext_buf);
        return "";
    }
    plaintext_len += len;

    EVP_CIPHER_CTX_free(ctx);

    std::string result((char*)plaintext_buf, plaintext_len);
    OPENSSL_free(plaintext_buf);
    return result;
}

// Ed25519 ile ilgili fonksiyonlar ÅŸimdilik yorum satÄ±rÄ±
// std::string LearningModule::ed25519_sign(const std::string& message, const std::string& private_key) const { /* ... */ }
// bool LearningModule::ed25519_verify(const std::string& message, const std::string& signature_base64, const std::string& public_key) const { /* ... */ }

std::string LearningModule::generate_random_bytes(size_t length) const {
    unsigned char* buffer = (unsigned char*)OPENSSL_malloc(length);
    if (!buffer) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "RAND_bytes iÃ§in bellek ayrÄ±lamadÄ±.");
        return "";
    }
    if (1 != RAND_bytes(buffer, static_cast<int>(length))) {
        ERR_print_errors_fp(stderr);
        OPENSSL_free(buffer);
        return "";
    }
    std::string random_data((char*)buffer, length);
    OPENSSL_free(buffer);
    return random_data;
}

std::string LearningModule::get_aes_key_for_peer(const std::string& peer_id) const {
    if (peer_id == "Self") {
        return std::string(32, 'S'); 
    }
    return std::string(32, 'A'); 
}

std::string LearningModule::get_public_key_for_peer(const std::string& peer_id) const {
    // Normalde Ed25519 public key uzunluÄŸu 32'dir
    if (peer_id == "Self") {
        return std::string(DUMMY_ED25519_PUBKEY_LEN, 'P'); 
    } else if (peer_id == "Test_Peer_A") {
        return std::string(DUMMY_ED25519_PUBKEY_LEN, 'A'); 
    } else if (peer_id == "Unauthorized_Peer") {
        return std::string(DUMMY_ED25519_PUBKEY_LEN, 'U'); 
    } else if (peer_id == "Suspicious_Source") {
        return std::string(DUMMY_ED25519_PUBKEY_LEN, 'X'); 
    } else if (peer_id == "Dirty_Source") {
        return std::string(DUMMY_ED25519_PUBKEY_LEN, 'D'); 
    }
    return std::string(DUMMY_ED25519_PUBKEY_LEN, 'K'); 
}

std::string LearningModule::get_my_private_key() const {
    // Normalde Ed25519 private key uzunluÄŸu 64'tÃ¼r (32 byte seed + 32 byte public key)
    return std::string(DUMMY_ED25519_PRIVKEY_LEN, 'M'); 
}

std::string LearningModule::get_my_public_key() const {
    return std::string(DUMMY_ED25519_PUBKEY_LEN, 'P'); 
} 
--- C:\Users\aib\CerebrumLux\src\learning\LearningModule.h --- 
#ifndef LEARNINGMODULE_H
#define LEARNINGMODULE_H

#include <string>
#include <vector> 
#include <map> 
#include <chrono> 

#include "KnowledgeBase.h"
#include "../communication/ai_insights_engine.h" 

// YENÄ°: KapsÃ¼l iÅŸleme sonucunu belirten enum
enum class IngestResult {
    Success,
    InvalidSignature,
    DecryptionFailed,
    SchemaMismatch,
    SanitizationNeeded,
    SteganographyDetected,
    SandboxFailed,
    CorroborationFailed,
    UnknownError,
    Ignored // Ã–rneÄŸin, zaten mevcut bir kapsÃ¼l iÃ§in
};

// YENÄ°: KapsÃ¼l iÅŸleme raporu
struct IngestReport {
    Capsule original_capsule; // Orijinal kapsÃ¼l
    Capsule processed_capsule; // Ä°ÅŸlenmiÅŸ/deÄŸiÅŸtirilmiÅŸ kapsÃ¼l
    IngestResult result;      // Ä°ÅŸlem sonucu
    std::string message;      // DetaylÄ± mesaj
    std::string source_peer_id; // KapsÃ¼lÃ¼n geldiÄŸi peer ID'si
    std::chrono::system_clock::time_point timestamp; // Ä°ÅŸlem zamanÄ±
    std::map<std::string, std::string> diagnostics; // Ek teÅŸhis bilgileri
};

// YENÄ°: Ä°leri bildirimler (aÅŸaÄŸÄ±da sÄ±nÄ±f tanÄ±mlarÄ±nÄ± yapacaÄŸÄ±mÄ±z iÃ§in)
class UnicodeSanitizer;
class StegoDetector;

// GeÃ§ici olarak Ed25519 sabitleri tanÄ±mlanÄ±yor, OpenSSL bulunana kadar
#define DUMMY_ED25519_PRIVKEY_LEN 64 
#define DUMMY_ED25519_PUBKEY_LEN 32  
#define DUMMY_ED25519_SIG_LEN   64   

class LearningModule {
public:
    LearningModule(KnowledgeBase& kb);
    ~LearningModule(); 

    void learnFromText(const std::string& text,
                       const std::string& source,
                       const std::string& topic,
                       float confidence = 1.0f);

    void learnFromWeb(const std::string& query); 

    virtual std::vector<Capsule> search_by_topic(const std::string& topic) const; 

    void process_ai_insights(const std::vector<AIInsight>& insights);

    virtual KnowledgeBase& getKnowledgeBase(); 
    virtual const KnowledgeBase& getKnowledgeBase() const; 

    IngestReport ingest_envelope(const Capsule& envelope, const std::string& signature, const std::string& sender_id);

    virtual std::vector<float> compute_embedding(const std::string& text) const; 
    virtual std::string cryptofig_encode(const std::vector<float>& cryptofig_vector) const; 
    virtual std::vector<float> cryptofig_decode_base64(const std::string& base64_cryptofig_blob) const; 
    virtual std::string aes_gcm_encrypt(const std::string& plaintext, const std::string& key, const std::string& iv) const; 
    virtual std::string aes_gcm_decrypt(const std::string& ciphertext, const std::string& key, const std::string& iv) const; 
    // virtual std::string ed25519_sign(const std::string& message, const std::string& private_key) const; 
    // virtual bool ed25519_verify(const std::string& message, const std::string& signature, const std::string& public_key) const; 
    virtual std::string generate_random_bytes(size_t length) const; 

    virtual std::string get_aes_key_for_peer(const std::string& peer_id) const;
    virtual std::string get_public_key_for_peer(const std::string& peer_id) const; 
    virtual std::string get_my_private_key() const;                               
    virtual std::string get_my_public_key() const;                                

    // YENÄ°: String iÃ§in public Base64 encode/decode metotlarÄ±
    virtual std::string base64_encode_string(const std::string& data) const; // YENÄ° PUBLIC VIRTUAL METOT
    virtual std::string base64_decode_string(const std::string& data) const; // YENÄ° PUBLIC VIRTUAL METOT

private:
    KnowledgeBase& knowledgeBase;

    std::unique_ptr<UnicodeSanitizer> unicodeSanitizer;
    std::unique_ptr<StegoDetector> stegoDetector;       

    // ingest_envelope pipeline'Ä± iÃ§indeki Ã¶zel metodlar
    bool verify_signature(const Capsule& capsule, const std::string& signature, const std::string& sender_id) const;
    Capsule decrypt_payload(const Capsule& encrypted_capsule) const;
    bool schema_validate(const Capsule& capsule) const;
    Capsule sanitize_unicode(const Capsule& capsule) const;
    bool run_steganalysis(const Capsule& capsule) const;
    bool sandbox_analysis(const Capsule& capsule) const;
    bool corroboration_check(const Capsule& capsule) const;
    void audit_log_append(const IngestReport& report) const; 

    // Base64 kodlama/kod Ã§Ã¶zme fonksiyonlarÄ± LearningModule'Ã¼n private Ã¼yeleri
    std::string base64_encode_internal(const std::string& in) const; 
    std::string base64_decode_internal(const std::string& in) const; 
};

#endif // LEARNINGMODULE_H 
--- C:\Users\aib\CerebrumLux\src\learning\StegoDetector.cpp --- 
// src/learning/StegoDetector.cpp
#include "StegoDetector.h"
#include "../core/logger.h" 
#include <string> 
#include <numeric>   // std::accumulate iÃ§in
#include <cmath>     // std::log2 iÃ§in
#include <map>       // Frekans analizi iÃ§in
#include <string_view> // YENÄ°: U+200B gibi karakterler iÃ§in

// Unicode sanitizer'dan benzer dÃ¶nÃ¼ÅŸÃ¼m fonksiyonlarÄ± kullanÄ±labilir veya doÄŸrudan char32_t olarak kontrol edilebilir.
// En temiz yaklaÅŸÄ±m, bu karakterleri UTF-8 bayt dizileri olarak tanÄ±mlamaktÄ±r.
// Ancak StegoDetector string ile Ã§alÄ±ÅŸÄ±yorsa, UTF-8 string iÃ§inde bu bayt dizilerini aramak daha doÄŸru olur.

bool StegoDetector::detectSteganography(const std::string& data) const {
    // Heuristik 1: Belirli anahtar kelimelerin varlÄ±ÄŸÄ± (Ã¶nceden vardÄ±, korunuyor)
    if (data.find("hidden_message_tag") != std::string::npos ||
        data.find("stego_payload_marker") != std::string::npos ||
        data.find("encoded_data_start") != std::string::npos) {
        LOG_DEFAULT(LogLevel::WARNING, "StegoDetector: Detected suspicious keywords in data.");
        return true;
    }

    // Heuristik 2: Normalde beklenmeyen yÃ¼ksek oranda gÃ¶rÃ¼nmez karakterler veya boÅŸluklar (Ã¶nceden vardÄ±, geliÅŸtirildi)
    size_t zero_width_char_count = 0;
    size_t non_printable_except_whitespace_count = 0;
    size_t total_chars_approx = data.length(); // UTF-8'de karakter sayÄ±sÄ± deÄŸil, bayt sayÄ±sÄ±dÄ±r.

    // UTF-8 string iÃ§inde sÄ±fÄ±r geniÅŸlikli karakterlerin bayt dizilerini arama
    // Bunlar genellikle tek bayt deÄŸildir ve bu ÅŸekilde kontrol edilmelidir.
    const std::string_view ZERO_WIDTH_SPACE = "\xE2\x80\x8B"; // U+200B
    const std::string_view ZERO_WIDTH_NON_JOINER = "\xE2\x80\x8C"; // U+200C
    const std::string_view ZERO_WIDTH_JOINER = "\xE2\x80\x8D"; // U+200D
    const std::string_view BYTE_ORDER_MARK_UTF8 = "\xEF\xBB\xBF"; // U+FEFF

    size_t current_pos = 0;
    while ((current_pos = data.find(ZERO_WIDTH_SPACE.data(), current_pos, ZERO_WIDTH_SPACE.length())) != std::string::npos) {
        zero_width_char_count++;
        current_pos += ZERO_WIDTH_SPACE.length();
    }
    current_pos = 0; // Reset for next search
    while ((current_pos = data.find(ZERO_WIDTH_NON_JOINER.data(), current_pos, ZERO_WIDTH_NON_JOINER.length())) != std::string::npos) {
        zero_width_char_count++;
        current_pos += ZERO_WIDTH_NON_JOINER.length();
    }
    current_pos = 0;
    while ((current_pos = data.find(ZERO_WIDTH_JOINER.data(), current_pos, ZERO_WIDTH_JOINER.length())) != std::string::npos) {
        zero_width_char_count++;
        current_pos += ZERO_WIDTH_JOINER.length();
    }
    current_pos = 0;
    while ((current_pos = data.find(BYTE_ORDER_MARK_UTF8.data(), current_pos, BYTE_ORDER_MARK_UTF8.length())) != std::string::npos) {
        zero_width_char_count++;
        current_pos += BYTE_ORDER_MARK_UTF8.length();
    }

    // BasÄ±labilir olmayan ASCII karakterler (0-31, 127) ve C1 kontrol karakterleri (128-159)
    for (char c : data) {
        if ((static_cast<unsigned char>(c) >= 0x00 && static_cast<unsigned char>(c) <= 0x1F) ||
            (static_cast<unsigned char>(c) >= 0x7F && static_cast<unsigned char>(c) <= 0x9F)) {
            non_printable_except_whitespace_count++;
        }
    }

    // Zero-width karakterlerin yÃ¼ksek oranÄ±
    if (total_chars_approx > 0 && (float)zero_width_char_count / total_chars_approx > 0.005f) { // %0.5'ten fazla sÄ±fÄ±r geniÅŸlikli karakter
        LOG_DEFAULT(LogLevel::WARNING, "StegoDetector: Detected high ratio of zero-width characters (UTF-8).");
        return true;
    }

    // Genel olarak yazdÄ±rÄ±lamayan karakterlerin (boÅŸluklar hariÃ§) yÃ¼ksek oranÄ±
    // Bu, tek baytlÄ±k ASCII kontrol karakterleri iÃ§in iyi Ã§alÄ±ÅŸÄ±r.
    // Unicode kontrol karakterleri iÃ§in daha sofistike bir UTF-8 ayrÄ±ÅŸtÄ±rmasÄ± veya std::u32string gerekir.
    if (total_chars_approx > 0 && (float)non_printable_except_whitespace_count / total_chars_approx > 0.01f) { // %1'den fazla yazdÄ±rÄ±lamayan karakter
        LOG_DEFAULT(LogLevel::WARNING, "StegoDetector: Detected high ratio of non-printable ASCII/C1 control characters.");
        return true;
    }

    // Heuristik 3: Entropi kontrolÃ¼ (Ã¶nceden vardÄ±, korunuyor)
    if (total_chars_approx > 50) { 
        std::map<char, int> char_counts;
        for (char c : data) {
            char_counts[c]++;
        }

        double entropy = 0.0;
        for (auto const& [key, val] : char_counts) {
            double probability = (double)val / total_chars_approx;
            entropy -= probability * std::log2(probability);
        }

        if (entropy < 2.0 || entropy > 6.5) { 
            LOG_DEFAULT(LogLevel::WARNING, "StegoDetector: Detected unusual entropy (low or high). Entropy: " << entropy);
            return true;
        }
    }

    // Heuristik 4: Anahtar kelimeler ve anlamsal anormallikler (Ã¶nceden vardÄ±, korunuyor)
    if (data.find("execute_command") != std::string::npos ||
        data.find("system_call") != std::string::npos ||
        data.find("inject_code") != std::string::npos) {
        LOG_DEFAULT(LogLevel::WARNING, "StegoDetector: Detected suspicious command-like keywords.");
        return true;
    }

    return false;
} 
--- C:\Users\aib\CerebrumLux\src\learning\StegoDetector.h --- 
#ifndef STEGODETECTOR_H
#define STEGODETECTOR_H

#include <string>
#include <vector> 

class StegoDetector {
public:
    StegoDetector() = default;

    // Verilen metin veya veri iÃ§inde steganografi belirtileri tespit eder.
    // Bu ilk versiyonda basit heuristikler kullanacak.
    bool detectSteganography(const std::string& data) const;

private:
    // YardÄ±mcÄ± metodlar (gelecekte eklenebilir)
    // float analyzeFrequencyDistribution(const std::string& data) const;
    // bool checkForSuspiciousPatterns(const std::string& data) const;
};

#endif // STEGODETECTOR_H 
--- C:\Users\aib\CerebrumLux\src\learning\UnicodeSanitizer.cpp --- 
#include "UnicodeSanitizer.h"
#include <algorithm> 
#include <locale>    
#include <codecvt>   // std::wstring_convert iÃ§in
#include "../core/logger.h" 
#include <string_view> // YENÄ°: std::string_view iÃ§in (Zero-width karakter kontrolÃ¼)

// Unicode karakterlerle daha iyi Ã§alÄ±ÅŸmak iÃ§in basit bir utf8 -> u32string -> utf8 dÃ¶nÃ¼ÅŸÃ¼mÃ¼
// C++17'de std::wstring_convert deprecated olmasÄ±na raÄŸmen, genel uyumluluk iÃ§in ÅŸimdilik kullanÄ±labilir.
// Daha saÄŸlam bir Ã§Ã¶zÃ¼m iÃ§in https://github.com/lemire/FastWithd gibi kÃ¼tÃ¼phaneler veya manuel UTF-8 ayrÄ±ÅŸtÄ±rma tercih edilebilir.
std::u32string utf8_to_u32(const std::string& utf8_str) {
    try {
        std::wstring_convert<std::codecvt_utf8<char32_t>, char32_t> converter;
        return converter.from_bytes(utf8_str);
    } catch (const std::range_error& e) {
        LOG_DEFAULT(LogLevel::WARNING, "UTF-8'den u32'ye dÃ¶nÃ¼ÅŸÃ¼mde hata: " << e.what());
        return {}; // Hata durumunda boÅŸ dÃ¶ndÃ¼r
    }
}

std::string u32_to_utf8(const std::u32string& u32_str) {
    try {
        std::wstring_convert<std::codecvt_utf8<char32_t>, char32_t> converter;
        return converter.to_bytes(u32_str);
    } catch (const std::range_error& e) {
        LOG_DEFAULT(LogLevel::WARNING, "u32'den UTF-8'e dÃ¶nÃ¼ÅŸÃ¼mde hata: " << e.what());
        return ""; // Hata durumunda boÅŸ dÃ¶ndÃ¼r
    }
}


std::string UnicodeSanitizer::sanitize(const std::string& text) const {
    std::string original_text = text;
    std::u32string u32_text = utf8_to_u32(original_text);

    if (u32_text.empty() && !original_text.empty()) { // DÃ¶nÃ¼ÅŸÃ¼m baÅŸarÄ±sÄ±z olduysa
        LOG_DEFAULT(LogLevel::WARNING, "UnicodeSanitizer: UTF-8'den u32'ye dÃ¶nÃ¼ÅŸÃ¼m baÅŸarÄ±sÄ±z oldu. Geriye dÃ¼ÅŸÃ¼ÅŸ yapÄ±lÄ±yor (sadece ASCII karakter kontrolÃ¼).");
        // Geriye dÃ¶nÃ¼k uyumluluk veya hata durumunda sadece ASCII kontrolÃ¼ yap
        original_text.erase(std::remove_if(original_text.begin(), original_text.end(), 
                                        [](unsigned char c){ return !std::isprint(c) && !std::isspace(c); }), 
                         original_text.end());
        if (original_text != text) {
            LOG_DEFAULT(LogLevel::INFO, "UnicodeSanitizer: Fallback sanitization applied. Original size: " << text.length() << ", New size: " << original_text.length());
        }
        return original_text;
    }

    std::u32string sanitized_u32_text;
    sanitized_u32_text.reserve(u32_text.length());

    for (char32_t c : u32_text) {
        // Heuristik 1: SÄ±fÄ±r geniÅŸlikli karakterleri (Zero Width Joiner, Zero Width Space, vb.) kaldÄ±r
        // Unicode standardÄ±nda "Format" kategori C (Control) veya "Separator, Space" Zs (Space separator) iÃ§inde yer alabilir.
        // Ã–zellikle dikkat edilmesi gerekenler: U+200B (Zero Width Space), U+200C (Zero Width Non-Joiner), U+200D (Zero Width Joiner)
        // AyrÄ±ca kontrol karakterleri (U+0000-U+001F, U+007F-U+009F gibi)
        if (c == U'\u200B' || c == U'\u200C' || c == U'\u200D' || 
            (c >= U'\u0000' && c <= U'\u001F') || // ASCII kontrol karakterleri
            (c >= U'\u007F' && c <= U'\u009F') || // C1 kontrol karakterleri
            c == U'\uFEFF') // Byte Order Mark (BOM)
        {
            // Bu karakterleri atla
            continue;
        }

        // Heuristik 2: Normalde metin iÃ§inde beklenmeyen, gÃ¶rsel olarak kafa karÄ±ÅŸtÄ±rÄ±cÄ± (confusable) karakterleri kaldÄ±r
        // Bu Ã§ok geniÅŸ bir kategori olup, kapsamlÄ± bir listeye ihtiyaÃ§ duyar.
        // Åžimdilik sadece birkaÃ§ Ã¶rneÄŸi ele alalÄ±m:
        // Ã–rneÄŸin: Tam geniÅŸlikli Latin karakterler (normal ASCII Latin karakterleri gibi gÃ¶rÃ¼nen ancak farklÄ± geniÅŸlikte olanlar)
        // U+FF01-U+FF5E (Fullwidth ASCII variants)
        if ((c >= U'\uFF01' && c <= U'\uFF5E')) { 
            // Bu karakterleri normal ASCII karÅŸÄ±lÄ±klarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme veya kaldÄ±rma seÃ§eneÄŸi.
            // Åžimdilik kaldÄ±rma.
            continue;
        }

        // GeÃ§erli ve korunmasÄ± gereken karakterleri ekle
        sanitized_u32_text.push_back(c);
    }

    std::string sanitized_text = u32_to_utf8(sanitized_u32_text);

    if (sanitized_text != original_text) {
        LOG_DEFAULT(LogLevel::INFO, "UnicodeSanitizer: Sanitized content. Original size: " << original_text.length() << ", New size: " << sanitized_text.length());
    }

    return sanitized_text;
} 
--- C:\Users\aib\CerebrumLux\src\learning\UnicodeSanitizer.h --- 
#ifndef UNICODESANITIZER_H
#define UNICODESANITIZER_H

#include <string>

class UnicodeSanitizer {
public:
    UnicodeSanitizer() = default;

    // Metindeki potansiyel olarak sorunlu veya gizli Unicode karakterlerini temizler.
    std::string sanitize(const std::string& text) const;

private:
    // YardÄ±mcÄ± metodlar (gelecekte eklenebilir)
    // bool isControlChar(char32_t c) const;
    // bool isConfusableChar(char32_t c) const;
};

#endif // UNICODESANITIZER_H 
--- C:\Users\aib\CerebrumLux\src\learning\WebFetcher.cpp --- 
#include "WebFetcher.h"
#include <iostream>

std::vector<WebResult> WebFetcher::search(const std::string& query) {
    std::vector<WebResult> results;

    // Burada gerÃ§ek web API entegrasyonu yapÄ±labilir (Google API, Forum API)
    // Åžimdilik placeholder:
    WebResult r1;
    r1.content = "Web iÃ§erik Ã¶rneÄŸi 1: " + query;
    r1.source = "https://example.com/source1";
    results.push_back(r1);

    WebResult r2;
    r2.content = "Web iÃ§erik Ã¶rneÄŸi 2: " + query;
    r2.source = "https://example.com/source2";
    results.push_back(r2);

    return results;
}
 
--- C:\Users\aib\CerebrumLux\src\learning\WebFetcher.h --- 
#ifndef WEBFETCHER_H
#define WEBFETCHER_H

#include <string>
#include <vector>

struct WebResult {
    std::string content;
    std::string source;
};

class WebFetcher {
public:
    WebFetcher() = default;

    // Basit arama fonksiyonu; placeholder
    virtual std::vector<WebResult> search(const std::string& query); // DÃœZELTÄ°LDÄ°: virtual eklendi
};

#endif // WEBFETCHER_H 
--- C:\Users\aib\CerebrumLux\src\meta\meta_evolution_engine.cpp --- 
#include "meta_evolution_engine.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/logger.h"        // LOG makrosu iÃ§in
#include "../core/utils.h"         // intent_to_string, goal_to_string vb. iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence'in tam tanÄ±mÄ± iÃ§in
#include <iostream>                // Debug Ã§Ä±ktÄ±larÄ± iÃ§in
#include <numeric>                 // std::accumulate iÃ§in (gerekliyse)
#include <algorithm>               // std::min/max iÃ§in (gerekliyse)
#include <chrono>                  // YENÄ°: AIInsight timestamp iÃ§in
#include <string>                  // YENÄ°: std::to_string iÃ§in
#include <iomanip>                 // std::setprecision iÃ§in
#include "../communication/ai_insights_engine.h" // YENÄ°: AIInsight tanÄ±mÄ± iÃ§in (Gerekli olduÄŸu iÃ§in tekrar ekleniyor)
#include "../core/enums.h"         // AIAction iÃ§in

// === MetaEvolutionEngine Implementasyonlari ===

// Kurucu - LearningModule referansÄ± alacak ÅŸekilde gÃ¼ncellendi
MetaEvolutionEngine::MetaEvolutionEngine(
    IntentAnalyzer& analyzer_ref,
    IntentLearner& learner_ref,
    PredictionEngine& predictor_ref,
    GoalManager& goal_manager_ref,
    CryptofigProcessor& cryptofig_processor_ref,
    AIInsightsEngine& insights_engine_ref,
    LearningModule& learning_module_ref
) : 
    analyzer(analyzer_ref),
    learner(learner_ref),
    predictor(predictor_ref),
    goal_manager(goal_manager_ref),
    cryptofig_processor(cryptofig_processor_ref),
    insights_engine(insights_engine_ref),
    learning_module(learning_module_ref), // YENÄ°: LearningModule referansÄ± baÅŸlatÄ±ldÄ±
    current_meta_goal(AIGoal::SelfImprovement), // VarsayÄ±lan meta-hedef: Kendi Kendini GeliÅŸtirmek
    current_adherence_score(1.0f) // BaÅŸlangÄ±Ã§ta tam baÄŸlÄ±lÄ±k varsayÄ±mÄ±
{
    // Temel prensipleri baÅŸlat
    core_principles.push_back({"Ultra-Verimlilik", 0.9f});
    core_principles.push_back({"Adaptiflik", 0.8f});
    core_principles.push_back({"Esneklik", 0.7f});
    core_principles.push_back({"ModÃ¼lerlik", 0.7f});
    core_principles.push_back({"Veri Ekonomisi", 0.6f});
    // DiÄŸer prensipler eklenebilir

    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: BaÅŸlatÄ±ldÄ±. VarsayÄ±lan meta-hedef: " << goal_to_string(current_meta_goal) << ". LearningModule entegrasyonu iÃ§in Ã¶n hazÄ±rlÄ±k yapÄ±ldÄ±.");
}

// Ana kendini geliÅŸtirme dÃ¶ngÃ¼sÃ¼nÃ¼ orkestre eder
void MetaEvolutionEngine::run_meta_evolution_cycle(const DynamicSequence& current_sequence) {
    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: Meta-evrim dÃ¶ngÃ¼sÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...");
    
    // 1. Prensip BaÄŸlÄ±lÄ±ÄŸÄ±nÄ± DeÄŸerlendir
    evaluate_principles_adherence(current_sequence);
    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: Mevcut prensip baÄŸlÄ±lÄ±k skoru: " << current_adherence_score);

    // 2. Meta-Hedef Ä°lerlemesini Kontrol Et
    if (check_meta_goal_progress()) {
        LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: Meta-hedef (" << goal_to_string(current_meta_goal) << ") Ã¼zerinde ilerleme kaydedildi.");
        // Ä°lerlemeye gÃ¶re yeni bir meta-hedef belirlenebilir veya mevcut hedef pekiÅŸtirilebilir.
    } else {
        LOG_DEFAULT(LogLevel::WARNING, "MetaEvolutionEngine: Meta-hedef (" << goal_to_string(current_meta_goal) << ") Ã¼zerinde istenen ilerleme kaydedilemedi.");
        // GeliÅŸimi hÄ±zlandÄ±rmak iÃ§in ek stratejiler devreye alÄ±nabilir.
    }

    // YENÄ°: LearningModule'e gÃ¼ncel iÃ§gÃ¶rÃ¼leri iÅŸle
    // Bu metodun AIInsightsEngine'da generate_insights() olarak tanÄ±mlÄ± olduÄŸunu varsayÄ±yoruz.
    learning_module.process_ai_insights(insights_engine.generate_insights(current_sequence));

    // ACÄ°L Ã–NCELÄ°K: GraphPanel'e AnlamlÄ± Veri Besleme iÃ§in AIInsight oluÅŸtur
    static size_t simulatedStepCount = 0;
    simulatedStepCount++;

    // AIInsight struct'Ä± sadece observation, suggested_action, urgency alÄ±yor.
    // GraphPanel iÃ§in deÄŸeri urgency alanÄ±na yerleÅŸtiriyoruz.
    // "StepSimulation" topic'i LearningModule tarafÄ±ndan Capsule oluÅŸturulurken ayarlanmalÄ±.
    AIInsight insight(
        "Simulating meta-evolution step: " + std::to_string(simulatedStepCount), // observation
        AIAction::None, // DÃ¼zeltildi: AIAction::Monitor yerine AIAction::None kullanÄ±ldÄ±
        static_cast<float>(simulatedStepCount % 100) // urgency (GraphPanel iÃ§in kullanÄ±lacak deÄŸer)
    );

    // LearningModule'Ã¼n process_ai_insights metodu, AIInsight'Ä± alÄ±p Capsule'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼rken,
    // muhtemelen topic'i ve diÄŸer meta verileri de belirleyecek.
    // Bu durumda, AIInsight'Ä±n urgency'sini Capsule'Ä±n confidence/value alanÄ±na aktaracaÄŸÄ±nÄ± varsayÄ±yoruz.
    learning_module.process_ai_insights({insight});

    // Log mesajÄ±ndaki 'value' yerine 'urgency' kullanÄ±ldÄ±
    LOG_DEFAULT(LogLevel::DEBUG, "MetaEvolutionEngine: Generated 'StepSimulation' insight with urgency " << insight.urgency);

    // 3. Mimariyi Kriptofig Olarak Analiz Et ve Ayarlamalar Ã–ner
    analyze_architecture_cryptofig(current_sequence);
    propose_architectural_adjustment(current_sequence);

    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: Meta-evrim dÃ¶ngÃ¼sÃ¼ tamamlandÄ±.");
}

// AI'Ä±n temel prensiplere ne kadar baÄŸlÄ± olduÄŸunu deÄŸerlendirir
void MetaEvolutionEngine::evaluate_principles_adherence(const DynamicSequence& current_sequence) {
    LOG_DEFAULT(LogLevel::DEBUG, "MetaEvolutionEngine: Prensip baÄŸlÄ±lÄ±ÄŸÄ± deÄŸerlendiriliyor...");
    float total_weighted_score = 0.0f;
    float total_importance = 0.0f;

    // Ã–rnek: "Ultra-Verimlilik" prensibi iÃ§in deÄŸerlendirme
    // DÃ¼ÅŸÃ¼k CPU/RAM kullanÄ±mÄ±, hÄ±zlÄ± yanÄ±t sÃ¼releri gibi metriklerle iliÅŸkilendirilebilir.
    // Åžimdilik basitleÅŸtirilmiÅŸ bir simÃ¼lasyon yapalÄ±m.
    float efficiency_score = 0.0f;
    if (current_sequence.avg_keystroke_interval > 0.0f && current_sequence.avg_keystroke_interval < 200000.0f) { // YÃ¼ksek yazÄ±m hÄ±zÄ±
        efficiency_score = 0.7f;
    } else {
        efficiency_score = 0.3f;
    }
    // Network aktivitesi de verimliliÄŸi etkileyebilir
    if (current_sequence.network_activity_level > 10000.0f && current_sequence.current_network_active) { 
        efficiency_score *= 0.8f; // YÃ¼ksek aÄŸ aktivitesi verimliliÄŸi dÃ¼ÅŸÃ¼rebilir
    }

    // "Adaptiflik" prensibi iÃ§in deÄŸerlendirme
    // AI'Ä±n farklÄ± niyetlere veya durumlara ne kadar hÄ±zlÄ± adapte olduÄŸuyla iliÅŸkilendirilebilir.
    // Åžimdilik, tahmin motorunun geÃ§miÅŸ performansÄ± gibi bir metrik kullanabiliriz.
    float adaptability_score = 0.0f;
    // PredictionEngine'dan veya IntentLearner'dan adaptasyon metrikleri alÄ±nabilir.
    // Ã–rneÄŸin: learner.get_learning_rate() ne kadar hÄ±zlÄ± deÄŸiÅŸiyor?
    adaptability_score = learner.get_learning_rate() * 5.0f; // Ã–ÄŸrenme oranÄ± yÃ¼ksekse daha adaptif varsayalÄ±m
    adaptability_score = std::min(1.0f, adaptability_score);

    // Her prensip iÃ§in skorlarÄ± topla
    for (const auto& principle : core_principles) {
        float principle_current_score = 0.0f;
        if (principle.name == "Ultra-Verimlilik") {
            principle_current_score = efficiency_score;
        } else if (principle.name == "Adaptiflik") {
            principle_current_score = adaptability_score;
        } else {
            principle_current_score = 0.5f; // DiÄŸerleri iÃ§in varsayÄ±lan orta skor
        }
        total_weighted_score += principle_current_score * principle.importance_score;
        total_importance += principle.importance_score;
    }

    if (total_importance > 0.0f) {
        current_adherence_score = total_weighted_score / total_importance;
    } else {
        current_adherence_score = 0.0f;
    }
    LOG_DEFAULT(LogLevel::DEBUG, "MetaEvolutionEngine: Prensip baÄŸlÄ±lÄ±ÄŸÄ± deÄŸerlendirmesi tamamlandÄ±. Skor: " << current_adherence_score);
}

// Genel prensip baÄŸlÄ±lÄ±k skorunu dÃ¶ndÃ¼rÃ¼r
float MetaEvolutionEngine::calculate_overall_adherence() const {
    return current_adherence_score;
}

// Potansiyel bir deÄŸiÅŸikliÄŸin etkisini simÃ¼le eder
float MetaEvolutionEngine::simulate_change_impact(const std::string& proposed_change_description) const {
    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: DeÄŸiÅŸiklik etkisi simÃ¼le ediliyor: '" << proposed_change_description << "'");
    // Bu, karmaÅŸÄ±k bir simÃ¼lasyon motoru gerektiren kritik bir metod olacaktÄ±r.
    // Ã–rneÄŸin, belirli bir kod deÄŸiÅŸikliÄŸinin performans, enerji tÃ¼ketimi veya adaptasyon Ã¼zerindeki etkisini tahmin edebiliriz.
    // Åžimdilik, basit bir rastgele veya kural tabanlÄ± tahmin dÃ¶ndÃ¼relim.
    if (proposed_change_description.find("performans") != std::string::npos) {
        return 0.8f; // Performans artÄ±ÅŸÄ± Ã¶ngÃ¶rÃ¼lebilir
    } else if (proposed_change_description.find("bug") != std::string::npos) {
        return 0.3f; // Hata dÃ¼zeltme, ancak baÅŸka sorunlar yaratabilir
    }
    return 0.5f; // NÃ¶tr etki
}

// AI iÃ§in meta-hedef belirler
void MetaEvolutionEngine::set_meta_goal(AIGoal new_meta_goal) {
    current_meta_goal = new_meta_goal;
    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: Yeni meta-hedef ayarlandÄ±: " << goal_to_string(current_meta_goal));
}

// Meta-hedefe ulaÅŸma ilerlemesini kontrol eder
bool MetaEvolutionEngine::check_meta_goal_progress() const {
    LOG_DEFAULT(LogLevel::DEBUG, "MetaEvolutionEngine: Meta-hedef ilerlemesi kontrol ediliyor: " << goal_to_string(current_meta_goal));
    // Bu metod, current_meta_goal'a ulaÅŸmak iÃ§in AI'Ä±n ne kadar ilerleme kaydettiÄŸini deÄŸerlendirir.
    // Ã–rneÄŸin, AIGoal::SelfImprovement ise, IntentLearner'Ä±n veya PredictionEngine'Ä±n hata oranlarÄ± dÃ¼ÅŸÃ¼yor mu?
    if (current_meta_goal == AIGoal::SelfImprovement) {
        // Basit bir Ã¶rnek: Ã–ÄŸrenme oranÄ± artÄ±yorsa veya hata oranÄ± dÃ¼ÅŸÃ¼yorsa ilerleme var diyelim.
        // Daha gerÃ§ekÃ§i bir senaryo iÃ§in AIInsightsEngine'dan metrikler alÄ±nabilir.
        if (learner.get_learning_rate() > 0.05f) { // YÃ¼ksek Ã¶ÄŸrenme oranÄ± bir ilerleme iÅŸareti olabilir
            return true;
        }
    }
    // DiÄŸer meta-hedefler iÃ§in benzer mantÄ±klar eklenebilir.
    return false; // Åžimdilik varsayÄ±lan: ilerleme yok
}

// Mevcut AI mimarisini kriptofig olarak analiz eder
void MetaEvolutionEngine::analyze_architecture_cryptofig(const DynamicSequence& current_sequence) {
    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: AI mimarisi kriptofig olarak analiz ediliyor...");
    // Bu metod, AI'Ä±n kendi iÃ§ yapÄ±sÄ±nÄ± ve davranÄ±ÅŸÄ±nÄ± "kriptofigler" aracÄ±lÄ±ÄŸÄ±yla temsil etmesini saÄŸlar.
    // Ã–rneÄŸin, farklÄ± modÃ¼llerin (analyzer, learner, predictor) birbirleriyle olan etkileÅŸimleri,
    // aÄŸÄ±rlÄ±k daÄŸÄ±lÄ±mlarÄ± veya Ã¶ÄŸrenme eÄŸrileri kriptofig olarak kodlanabilir.
    // Åžimdilik, sadece mevcut sequence'in latent kriptofig'ini kullanarak bir loglama yapalÄ±m.
    if (!current_sequence.latent_cryptofig_vector.empty()) {
        std::stringstream ss;
        ss << std::fixed << std::setprecision(2);
        ss << "MetaEvolutionEngine: Mevcut mimari kriptofig (latent): [";
        for (size_t i = 0; i < current_sequence.latent_cryptofig_vector.size(); ++i) {
            ss << current_sequence.latent_cryptofig_vector[i];
            if (i + 1 < current_sequence.latent_cryptofig_vector.size()) ss << ", ";
        }
        ss << "]";
        LOG_DEFAULT(LogLevel::DEBUG, ss.str());
    } else {
        LOG_DEFAULT(LogLevel::WARNING, "MetaEvolutionEngine: Mimari analizi iÃ§in latent kriptofig bulunamadÄ±.");
    }
}

// Kriptofig analizine gÃ¶re mimari ayarlamalar Ã¶nerir
void MetaEvolutionEngine::propose_architectural_adjustment(const DynamicSequence& current_sequence) {
    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: Mimari ayarlamalar Ã¶neriliyor...");
    // Bu metod, analyze_architecture_cryptofig'den elde edilen iÃ§gÃ¶rÃ¼lere dayanarak
    // AI'Ä±n kendi mimarisinde yapÄ±sal veya algoritmik deÄŸiÅŸiklikler Ã¶nerebilir.
    // Ã–rneÄŸin, belirli bir niyet ÅŸablonunun aÄŸÄ±rlÄ±klarÄ±nÄ±n ayarlanmasÄ±,
    // bir Ã¶ÄŸrenme hÄ±zÄ±nÄ±n deÄŸiÅŸtirilmesi veya hatta yeni bir modÃ¼lÃ¼n entegrasyonu gibi.
    
    // Basit bir Ã¶rnek: EÄŸer prensip baÄŸlÄ±lÄ±k skoru dÃ¼ÅŸÃ¼kse, adaptasyon prensibini vurgula
    if (current_adherence_score < 0.6f) {
        LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: DÃ¼ÅŸÃ¼k prensip baÄŸlÄ±lÄ±k skoru nedeniyle 'Adaptiflik' prensibine odaklanma Ã¶neriliyor.");
        LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: Ã–neri: IntentLearner'Ä±n Ã¶ÄŸrenme hÄ±zÄ±nÄ± artÄ±rÄ±n veya PredictionEngine'Ä±n adaptasyon parametrelerini gÃ¶zden geÃ§irin.");
    }
    // TODO: Daha karmaÅŸÄ±k Ã¶neri mekanizmalarÄ± eklenecek
} 
--- C:\Users\aib\CerebrumLux\src\meta\meta_evolution_engine.h --- 
#ifndef CEREBRUM_LUX_META_EVOLUTION_ENGINE_H
#define CEREBRUM_LUX_META_EVOLUTION_ENGINE_H

#include <string>   // std::string iÃ§in
#include <vector>   // std::vector iÃ§in
#include <map>      // std::map iÃ§in (gerekliyse)

#include "../core/enums.h"         // Enumlar (AIGoal) iÃ§in

// Cerebrum Lux modÃ¼llerinin baÅŸlÄ±k dosyalarÄ± iÃ§in TAM TANIMLAR (referans Ã¼yeleri iÃ§in)
// Bu dosyalar doÄŸrudan #include edilmelidir, Ã§Ã¼nkÃ¼ MetaEvolutionEngine bu sÄ±nÄ±flara referans Ã¼yeler tutar.
#include "../brain/intent_analyzer.h"
#include "../brain/intent_learner.h"
#include "../brain/prediction_engine.h"
#include "../planning_execution/goal_manager.h"
#include "../brain/cryptofig_processor.h"
#include "../communication/ai_insights_engine.h"
#include "../learning/LearningModule.h"
#include "../learning/KnowledgeBase.h"  // KnowledgeBase de LearningModule aracÄ±lÄ±ÄŸÄ±yla eriÅŸildiÄŸi iÃ§in tam tanÄ±m gerekli.
#include "../data_models/dynamic_sequence.h" // DynamicSequence'in tam tanÄ±mÄ± iÃ§in
#include "../data_models/sequence_manager.h" // YENÄ°: SequenceManager'Ä±n tam tanÄ±mÄ± iÃ§in eklendi (run_self_simulation metodu iÃ§in)


// Proje prensiplerini temsil eden yapÄ±
struct ProjectPrinciple {
    std::string name;
    float importance_score; // 0.0 - 1.0 arasÄ±, prensibin ne kadar kritik olduÄŸunu belirtir
};

// *** MetaEvolutionEngine: Cerebrum Lux'Ä±n meta-yÃ¶netim katmanlarÄ±nÄ±n ana koordinatÃ¶rÃ¼ ***
class MetaEvolutionEngine {
public:
    // Kurucu
    MetaEvolutionEngine(
        IntentAnalyzer& analyzer_ref,
        IntentLearner& learner_ref,
        PredictionEngine& predictor_ref,
        GoalManager& goal_manager_ref,
        CryptofigProcessor& cryptofig_processor_ref,
        AIInsightsEngine& insights_engine_ref,
        LearningModule& learning_module_ref
    );

    // Genel Metotlar (BoÅŸ implementasyonlu bildirimler)
    void run_meta_evolution_cycle(const DynamicSequence& current_sequence); // Ana kendini geliÅŸtirme dÃ¶ngÃ¼sÃ¼nÃ¼ orkestre eder
    void evaluate_principles_adherence(const DynamicSequence& current_sequence); // AI'Ä±n temel prensiplere ne kadar baÄŸlÄ± olduÄŸunu deÄŸerlendirir
    float calculate_overall_adherence() const; // Genel prensip baÄŸlÄ±lÄ±k skorunu dÃ¶ndÃ¼rÃ¼r
    float simulate_change_impact(const std::string& proposed_change_description) const; // Potansiyel bir deÄŸiÅŸikliÄŸin etkisini simÃ¼le eder
    void set_meta_goal(AIGoal new_meta_goal); // AI iÃ§in meta-hedef belirler
    bool check_meta_goal_progress() const; // Meta-hedefe ulaÅŸma ilerlemesini kontrol eder
    void analyze_architecture_cryptofig(const DynamicSequence& current_sequence); // Mevcut AI mimarisini kriptofig olarak analiz eder
    void propose_architectural_adjustment(const DynamicSequence& current_sequence); // Kriptofig analizine gÃ¶re mimari ayarlamalar Ã¶nerir

    // YENÄ°: Kendi kendini simÃ¼lasyon metodunun bildirimi
    void run_self_simulation(int rounds, SequenceManager& seq_manager); 

private:
    // BaÄŸÄ±mlÄ±lÄ±klar (diÄŸer AI bileÅŸenlerine referanslar)
    IntentAnalyzer& analyzer;
    IntentLearner& learner;
    PredictionEngine& predictor;
    GoalManager& goal_manager;
    CryptofigProcessor& cryptofig_processor;
    AIInsightsEngine& insights_engine;
    LearningModule& learning_module; // YENÄ°

    // Meta-yÃ¶netim iÃ§in Ã¶zel Ã¼yeler
    std::vector<ProjectPrinciple> core_principles; // ProjectPrinciple artÄ±k tanÄ±mlÄ±
    AIGoal current_meta_goal; // AIGoal artÄ±k tanÄ±mlÄ± (enums.h'den)
    float current_adherence_score; // Mevcut prensip baÄŸlÄ±lÄ±k skoru

    // YardÄ±mcÄ± metotlar (ÅŸimdilik bildirimleri yok, sonra eklenecek)
    // void initialize_core_principles();
    // void update_meta_goal_based_on_adherence();
};

#endif // CEREBRUM_LUX_META_EVOLUTION_ENGINE_H 
--- C:\Users\aib\CerebrumLux\src\meta\meta_evolution_engine_sim.cpp --- 
// File: src/meta/meta_evolution_engine_sim.cpp
#include "meta_evolution_engine.h"
#include "../core/logger.h"
#include "../data_models/dynamic_sequence.h"
#include "../data_models/sequence_manager.h"
#include "../core/utils.h" // EKLENDÄ°: SafeRNG iÃ§in
#include <chrono>
#include <thread>
#include <sstream>

// === MetaEvolutionEngine ImplementasyonlarÄ± ===
// run_self_simulation metodunun implementasyonu
void MetaEvolutionEngine::run_self_simulation(int rounds, SequenceManager& seq_manager) {
    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: self-simulation baÅŸlatÄ±lÄ±yor. rounds=" << rounds);
    
    std::uniform_real_distribution<float> u01(0.0f, 1.0f);
    std::uniform_real_distribution<float> interval_ms(20000.0f, 250000.0f); // microseconds candidate
    std::uniform_real_distribution<float> alpha_ratio(0.0f, 1.0f);

    for (int r = 0; r < rounds; ++r) {
        try {
            // 1) Create a synthetic DynamicSequence with randomized but plausible features
            DynamicSequence seq;
            seq.avg_keystroke_interval = interval_ms(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
            seq.alphanumeric_ratio = alpha_ratio(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
            seq.current_battery_percentage = static_cast<unsigned char>(20 + int(u01(SafeRNG::get_instance().get_generator()) * 80)); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
            seq.current_battery_charging = (u01(SafeRNG::get_instance().get_generator()) > 0.7f); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
            seq.statistical_features_vector = std::vector<float>(cryptofig_processor.get_autoencoder().INPUT_DIM, 0.0f);


            // Fill features with random small numbers
            for (size_t i = 0; i < seq.statistical_features_vector.size(); ++i) {
                seq.statistical_features_vector[i] = u01(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
            }

            // 2) Process via cryptofig processor to get latent vector (if available)
            try {
                cryptofig_processor.process_sequence(seq, /*learning_rate=*/0.001f);
            } catch (const std::exception& e) {
                LOG_DEFAULT(LogLevel::WARNING, "MetaEvolutionEngine: cryptofig_processor threw during process_sequence: " << e.what());
            } catch (...) {
                LOG_DEFAULT(LogLevel::WARNING, "MetaEvolutionEngine: cryptofig_processor threw during process_sequence (unknown exception).");
            }

            // 3) Analyze intent via analyzer
            UserIntent predicted_intent = analyzer.analyze_intent(seq);
            AbstractState predicted_state = learner.infer_abstract_state(seq_manager.get_signal_buffer_copy());

            // 4) Let insights engine produce insights
            auto insights = insights_engine.generate_insights(seq);

            // 5) Evaluate / update meta-goals via goal manager
            goal_manager.evaluate_and_set_goal(seq);

            // 6) Optionally propose a minor architecture parameter suggestion (example: adjust learning rate)
            AIGoal current_goal = goal_manager.get_current_goal();
            if (seq.current_battery_percentage < 30 && current_goal == AIGoal::OptimizeProductivity) {
                LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: Ã¶neri -> pil zayÄ±f, performans-tabanlÄ± hedefe geÃ§ici kÄ±sÄ±tlama Ã¶neriliyor.");
            }

            // 7) Optionally run a simulated small adaptation
            if (u01(SafeRNG::get_instance().get_generator()) > 0.98f) { // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
                LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: (sim) Ã¶neri -> kÃ¼Ã§Ã¼k yapÄ±landÄ±rma deÄŸiÅŸikliÄŸi adaylandÄ± (insan onayÄ± gerekir).");
            }

            // 8) Wait a short, configurable interval so long-running simulation doesn't hog CPU
            std::this_thread::sleep_for(std::chrono::milliseconds(20));
        } catch (const std::exception& e) {
            LOG_DEFAULT(LogLevel::WARNING, "MetaEvolutionEngine::run_self_simulation istisna: " << e.what());
        } catch (...) {
            LOG_DEFAULT(LogLevel::WARNING, "MetaEvolutionEngine::run_self_simulation bilinmeyen istisna.");
        }
    }
    LOG_DEFAULT(LogLevel::INFO, "MetaEvolutionEngine: self-simulation tamamlandi.");
} 
--- C:\Users\aib\CerebrumLux\src\planning_execution\goal_manager.cpp --- 
#include "goal_manager.h" 
#include "../core/logger.h"
#include "../core/utils.h" // goal_to_string iÃ§in
#include "../data_models/dynamic_sequence.h"
#include "../communication/ai_insights_engine.h"
#include "../brain/intent_analyzer.h"
#include "../brain/autoencoder.h"
#include <vector>
#include <algorithm>
#include <iostream> // std::cout, std::cerr iÃ§in
#include <sstream>

// === GoalManager Implementasyonlari ===
GoalManager::GoalManager(AIInsightsEngine& insights_engine_ref) : current_goal(AIGoal::OptimizeProductivity), insights_engine(insights_engine_ref) {}

AIGoal GoalManager::get_current_goal() const {
    return current_goal;
}

void GoalManager::set_current_goal(AIGoal new_goal) {
    if (current_goal != new_goal) {
        current_goal = new_goal;
        LOG_DEFAULT(LogLevel::INFO, "[AI-Hedef] Yeni hedef ayarlandi: " << goal_to_string(new_goal));
    }
}

// Dinamik hedef belirleme fonksiyonu
void GoalManager::evaluate_and_set_goal(const DynamicSequence& current_sequence) {
    LOG_DEFAULT(LogLevel::DEBUG, "GoalManager::evaluate_and_set_goal: Dinamik hedef belirleme basladi.\n");
    std::vector<AIInsight> insights = insights_engine.generate_insights(current_sequence);

    // En yÃ¼ksek aciliyetli iÃ§gÃ¶rÃ¼ye gÃ¶re hedef belirle
    float max_urgency = 0.0f;
    AIAction critical_action = AIAction::None;

    for (const auto& insight : insights) {
        if (insight.urgency > max_urgency) {
            max_urgency = insight.urgency;
            critical_action = insight.suggested_action;
        }
    }

    UserIntent analyzed_current_intent = insights_engine.get_analyzer().analyze_intent(current_sequence);

    if (max_urgency > 0.7f && critical_action == AIAction::SuggestSelfImprovement) {
        set_current_goal(AIGoal::SelfImprovement);
    } else if (current_sequence.current_battery_percentage < 20 && !current_sequence.current_battery_charging) {
        set_current_goal(AIGoal::MaximizeBatteryLife);
    }
    else if (current_sequence.current_network_active && current_sequence.network_activity_level == 0 && current_sequence.statistical_features_vector.size() == CryptofigAutoencoder::INPUT_DIM && insights_engine.calculate_autoencoder_reconstruction_error(current_sequence.statistical_features_vector) > 0.5f) {
        set_current_goal(AIGoal::ReduceDistractions); 
    } else if (analyzed_current_intent == UserIntent::IdleThinking && current_sequence.mouse_movement_intensity / 500.0f > 0.2f && current_sequence.network_activity_level / 15000.0f > 0.2f) { 
        set_current_goal(AIGoal::ReduceDistractions);
    }
    else {
        set_current_goal(AIGoal::OptimizeProductivity);
    }
    LOG_DEFAULT(LogLevel::DEBUG, "GoalManager::evaluate_and_set_goal: Dinamik hedef belirleme bitti. Mevcut hedef: " << static_cast<int>(current_goal) << "\n");
}
 
--- C:\Users\aib\CerebrumLux\src\planning_execution\goal_manager.h --- 
#ifndef CEREBRUM_LUX_GOAL_MANAGER_H
#define CEREBRUM_LUX_GOAL_MANAGER_H

#include <string> // For wstring
#include "../core/enums.h"               // Enumlar iÃ§in
#include "../core/utils.h"               // LOG iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in ileri bildirim
#include "../communication/ai_insights_engine.h" // AIInsightsEngine iÃ§in ileri bildirim
#include "../brain/intent_analyzer.h" // IntentAnalyzer iÃ§in ileri bildirim

// Ä°leri bildirimler
class AIInsightsEngine;
struct DynamicSequence;
class IntentAnalyzer;

// *** GoalManager: AI'Ä±n hedeflerini yonetir ***
class GoalManager {
public:
    GoalManager(AIInsightsEngine& insights_engine_ref); 
    GoalManager(); // For tooling 
    virtual AIGoal get_current_goal() const; // Eklendi: virtual
    void set_current_goal(AIGoal goal);
    void evaluate_and_set_goal(const DynamicSequence& current_sequence); // Dinamik hedef belirleme
private:
    AIGoal current_goal = AIGoal::OptimizeProductivity; 
    AIInsightsEngine& insights_engine; // AIInsightsEngine referansÄ±
    // IntentAnalyzer'a doÄŸrudan eriÅŸim insights_engine Ã¼zerinden yapÄ±lmalÄ±, burada tutulmasÄ±na gerek yok.
};

#endif // CEREBRUM_LUX_GOAL_MANAGER_H 
--- C:\Users\aib\CerebrumLux\src\planning_execution\planner.cpp --- 
#include "planner.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/logger.h"
#include "../core/utils.h"       // intent_to_string
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in
#include "../brain/intent_analyzer.h" // IntentAnalyzer iÃ§in
#include "../brain/prediction_engine.h" // PredictionEngine iÃ§in
#include "../communication/ai_insights_engine.h" // AIInsightsEngine iÃ§in
#include "../planning_execution/goal_manager.h" // GoalManager iÃ§in (gerekliyse, Ã§apraz baÄŸÄ±mlÄ±lÄ±k olabilir)
#include <algorithm> // std::min/max iÃ§in
#include <iostream>  // std::cout, std::cerr iÃ§in
#include <sstream>   // std::stringstream iÃ§in

// === ActionPlanStep Implementasyonu ===
ActionPlanStep::ActionPlanStep(AIAction act, UserIntent intent, const std::string& desc)
    : action(act), triggered_by_intent(intent), description(desc) {}

// === Planner Implementasyonlari ===
Planner::Planner(IntentAnalyzer& analyzer_ref, SuggestionEngine& suggester_ref,
            GoalManager& goal_manager_ref, PredictionEngine& predictor_ref,
            AIInsightsEngine& insights_engine_ref)
    : analyzer(analyzer_ref), suggester(suggester_ref), goal_manager(goal_manager_ref),
      predictor(predictor_ref), insights_engine(insights_engine_ref) {}

std::vector<ActionPlanStep> Planner::create_action_plan(UserIntent current_intent, AbstractState current_abstract_state, AIGoal current_goal, const DynamicSequence& sequence) const {
    std::vector<ActionPlanStep> plan;

    // AIInsightsEngine'dan gelen Ã¶nerileri kontrol et ve Ã¶ncelik ver
    std::vector<AIInsight> insights = insights_engine.generate_insights(sequence);
    for (const auto& insight : insights) {
        if (insight.suggested_action == AIAction::SuggestSelfImprovement && insight.urgency > 0.5f) { // YÃ¼ksek aciliyetli kendi kendini geliÅŸtirme Ã¶nerileri
            std::stringstream ss;
            ss << "[AI-Icgoru]: " << insight.observation << " (Aciliyet: " << static_cast<int>(insight.urgency * 100) << "%)";
            plan.emplace_back(AIAction::SuggestSelfImprovement, current_intent, ss.str());
        }
    }

    // EÄŸer ana hedef kendi kendini geliÅŸtirmeyse, diÄŸer planlarÄ± bypass et ve sadece buna odaklan
    if (current_goal == AIGoal::SelfImprovement) {
        if (plan.empty()) { // EÄŸer zaten iÃ§gÃ¶rÃ¼den bir plan oluÅŸmadÄ±ysa, genel bir kendi kendini geliÅŸtirme planÄ± sun
            plan.emplace_back(AIAction::SuggestSelfImprovement, current_intent, "Åžu anda temel hedefim kendimi geliÅŸtirmek. Bu konuda bana nasÄ±l yardÄ±mcÄ± olabilirsiniz?");
            plan.emplace_back(AIAction::SuggestSelfImprovement, current_intent, "Ã–ÄŸrenme performansÄ±mÄ± artÄ±rmak iÃ§in daha fazla veri analiz etmem gerekiyor.");
        }
        return plan; // Sadece kendi kendini geliÅŸtirme planÄ±nÄ± dÃ¶ndÃ¼r
    }

    if (current_goal == AIGoal::OptimizeProductivity) {
        std::vector<ActionPlanStep> productivity_plan = _plan_for_productivity(current_intent, current_abstract_state, sequence);
        plan.insert(plan.end(), productivity_plan.begin(), productivity_plan.end());
    } else if (current_goal == AIGoal::MaximizeBatteryLife) {
        std::vector<ActionPlanStep> battery_plan = _plan_for_battery_life(current_intent, current_abstract_state, sequence);
        plan.insert(plan.end(), battery_plan.begin(), battery_plan.end());
    } else if (current_goal == AIGoal::ReduceDistractions) {
        if (current_abstract_state == AbstractState::Distracted || current_intent == UserIntent::IdleThinking) {
            plan.emplace_back(AIAction::MuteNotifications, current_intent, "Dikkat daÄŸÄ±tÄ±cÄ±larÄ± azaltmak iÃ§in tÃ¼m bildirimleri sessize al.");
            plan.emplace_back(AIAction::DimScreen, current_intent, "OdaklanmayÄ± artÄ±rmak iÃ§in ekranÄ± karart.");
            plan.emplace_back(AIAction::LaunchApplication, current_intent, "OdaklanmanÄ±zÄ± artÄ±rmak iÃ§in ana uygulamanÄ±zÄ± tekrar aÃ§Ä±n.");
        } else {
            plan.emplace_back(AIAction::None, current_intent, "Dikkat daÄŸÄ±tÄ±cÄ±larÄ± azaltmaya yÃ¶nelik Ã¶zel bir eylem Ã¶nerisi yok.");
        }
    } 
    // YENÄ° HEDEF PLANLARI
    else if (current_goal == AIGoal::EnhanceCreativity) {
        if (current_intent == UserIntent::CreativeWork || current_abstract_state == AbstractState::CreativeFlow) {
            plan.emplace_back(AIAction::MuteNotifications, current_intent, "YaratÄ±cÄ±lÄ±ÄŸÄ±nÄ±zÄ± artÄ±rmak iÃ§in bildirimleri sessize alÄ±n.");
            plan.emplace_back(AIAction::SuggestBreak, current_intent, "KÄ±sa bir mola yeni fikirler getirebilir.");
        }
        else {
            plan.emplace_back(AIAction::None, current_intent, "YaratÄ±cÄ±lÄ±ÄŸÄ± artÄ±rmaya yÃ¶nelik Ã¶zel bir eylem Ã¶nerisi yok.");
        }
    } else if (current_goal == AIGoal::ImproveGamingExperience) {
        if (current_intent == UserIntent::Gaming) {
            plan.emplace_back(AIAction::OptimizeForGaming, current_intent, "Oyun deneyiminizi optimize etmek iÃ§in sistem ayarlarÄ±nÄ± dÃ¼zenle.");
            plan.emplace_back(AIAction::MuteNotifications, current_intent, "Oyun sÄ±rasÄ±nda dikkatinizi daÄŸÄ±tmamak iÃ§in bildirimleri kapat.");
        }
        else {
            plan.emplace_back(AIAction::None, current_intent, "Oyun deneyimini iyileÅŸtirmeye yÃ¶nelik Ã¶zel bir eylem Ã¶nerisi yok.");
        }
    }
    else if (current_goal == AIGoal::FacilitateResearch) {
        if (current_intent == UserIntent::Research || current_abstract_state == AbstractState::SeekingInformation) {
            plan.emplace_back(AIAction::EnableFocusMode, current_intent, "AraÅŸtÄ±rmaya odaklanmak iÃ§in Ã¶zel bir 'Odak Modu' etkinleÅŸtir.");
            plan.emplace_back(AIAction::OpenDocumentation, current_intent, "Ä°lgili dokÃ¼mantasyonu veya web kaynaklarÄ±nÄ± otomatik olarak aÃ§.");
        }
        else {
            plan.emplace_back(AIAction::None, current_intent, "AraÅŸtÄ±rmayÄ± kolaylaÅŸtÄ±rmaya yÃ¶nelik Ã¶zel bir eylem Ã¶nerisi yok.");
        }
    }
    else {
        // EÄŸer hiÃ§bir hedefe yÃ¶nelik plan oluÅŸturulmadÄ±ysa ve iÃ§gÃ¶rÃ¼ de yoksa, genel fallback planÄ±
        if (plan.empty()) { 
             plan.emplace_back(AIAction::None, current_intent, "Mevcut hedefinize yÃ¶nelik Ã¶zel bir plan oluÅŸturulamadÄ±. AI Ã¶ÄŸrenmeye devam ediyor.");
        }
    }
    
    // Genel fallback planlarÄ± (eÄŸer plan hala boÅŸsa veya sadece 'None' iÃ§eriyorsa)
    if (plan.empty() || (plan.size() == 1 && plan[0].action == AIAction::None && current_intent != UserIntent::Unknown && current_intent != UserIntent::None)) {
        plan.clear(); 
        plan.emplace_back(AIAction::None, current_intent, "AI, ogrenmeye devam ediyor. Lutfen etkilesiminize devam edin.");
        plan.emplace_back(AIAction::None, current_intent, "Belki hizli yazmaya baslamak istersiniz?");
        plan.emplace_back(AIAction::None, current_intent, "Veya bir seyleri duzenlemeye baslamak?");
    }
    return plan;
}

void Planner::execute_plan(const std::vector<ActionPlanStep>& plan) {
    if (plan.empty()) {
        LOG_DEFAULT(LogLevel::INFO, "[AI-Planlayici] Bos eylem plani.\n");
        return;
    }
    LOG_DEFAULT(LogLevel::INFO, "[AI-Planlayici] Eylem plani yurutuluyor:\n");
    for (const auto& step : plan) {
        LOG_DEFAULT(LogLevel::INFO, "  - " << step.description << " (Tetkikleyen Niyet: " << intent_to_string(step.triggered_by_intent) << ")\n");
        
        if (step.action == AIAction::DimScreen) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Ekrani karartma eylemi simule ediliyor.\n");
        } else if (step.action == AIAction::MuteNotifications) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Bildirimleri sessize alma eylemi simule ediliyor.\n");
        } else if (step.action == AIAction::LaunchApplication) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Uygulama baslatma eylemi simule ediliyor.\n");
        } else if (step.action == AIAction::SetReminder) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Hatirlatici kurma eylemi simule ediliyor.\n");
        }
        // YENÄ° EYLEMLERÄ°N SÄ°MÃœLASYONU
        else if (step.action == AIAction::SuggestBreak) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Ara verme onerisi simule ediliyor.\n");
        } else if (step.action == AIAction::OptimizeForGaming) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Oyun performansi optimizasyonu simule ediliyor.\n");
        } else if (step.action == AIAction::EnableFocusMode) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Odaklanma modu etkinlestirme simule ediliyor.\n");
        } else if (step.action == AIAction::AdjustAudioVolume) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Ses seviyesi ayari simule ediliyor.\n");
        } else if (step.action == AIAction::OpenDocumentation) {
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] DokÃ¼mantasyon acma simule ediliyor.\n");
        } else if (step.action == AIAction::SuggestSelfImprovement) { 
            LOG_DEFAULT(LogLevel::INFO, "    [AI-Eylem] Kendi kendini geliÅŸtirme Ã¶nerisi simule ediliyor: " << step.description << "\n");
        }
    }
}

std::vector<ActionPlanStep> Planner::_plan_for_productivity(UserIntent current_intent, AbstractState current_abstract_state, const DynamicSequence& sequence) const { 
    std::vector<ActionPlanStep> plan;

    if (current_intent == UserIntent::FastTyping) {
        if (sequence.network_activity_level / 15000.0f > 0.7f) { 
            plan.emplace_back(AIAction::DimScreen, current_intent, "Yuksek ag aktivitesi fark edildi, odaklanmak iÃ§in ekrani biraz karart.");
        }
        plan.emplace_back(AIAction::DisableSpellCheck, current_intent, "Hizinizi kesmemek icin yazim denetimini devre disi birak.");
        plan.emplace_back(AIAction::EnableCustomDictionary, current_intent, "Terminolojinizi kolaylastirmak icin ozel sozluk kullan.");
        plan.emplace_back(AIAction::OpenFile, current_intent, "Hizli bir sekilde yeni bir dokuman acarak uretkenligini surdur.");
        plan.emplace_back(AIAction::None, current_intent, "Harika bir hizla yaziyorsunuz! Odaginizi koruyun.");

    } else if (current_intent == UserIntent::Editing) {
        if (sequence.keystroke_variability / 1000.0f > 0.75f || sequence.control_key_frequency > 0.5f) { 
            plan.emplace_back(AIAction::ShowUndoHistory, current_intent, "Duzenleme paterninde duzensizlikler var, geri alma gecmisini kontrol et.");
        }
        plan.emplace_back(AIAction::CompareVersions, current_intent, "Duzenleme islemini tamamlamadan once versiyonlari karsilastirarak guvenlik onlemi al.");
        plan.emplace_back(AIAction::SimulateOSAction, current_intent, "Duzenleme araclarini optimize etmek icin bir OS eylemi simule et (Ã¶rneÄŸin, dosya yedekleme).");
        plan.emplace_back(AIAction::SetReminder, current_intent, "Bu gorevi bitirdiginizde hatirlatici kurun: 'Bitirildi'.");
        plan.emplace_back(AIAction::None, current_intent, "Duzenleme modundasiniz. Odaklanmanize yardimci olabilirim.");

    } else if (current_intent == UserIntent::IdleThinking) {
        if (sequence.mouse_movement_intensity / 500.0f > 0.1f || sequence.mouse_click_frequency > 0.1f || sequence.network_activity_level / 15000.0f > 0.1f) { 
            plan.emplace_back(AIAction::MuteNotifications, current_intent, "Dusunme/ara verme modundayken dikkat dagiticilari azaltmak icin bildirimleri sessize al.");
            plan.emplace_back(AIAction::DimScreen, current_intent, "Odaklanmayi artirmak icin ekrani karart.");
        }
        plan.emplace_back(AIAction::SetReminder, current_intent, "Dusunme suren bittiginde seni uyarmasi icin bir hatirlatici kur.");
        plan.emplace_back(AIAction::LaunchApplication, current_intent, "Dusunme/ara verme sonrasi ihtiyac duyacagin bir uygulamayi (Ã¶rn. metin editoru) baslat.");
        plan.emplace_back(AIAction::EnableCustomDictionary, current_intent, "Dusunme sonrasi hizli yazima gecis icin ozel sozluk etkinlestiriliyor.");
        plan.emplace_back(AIAction::None, current_intent, "Su an dusunuyor gibi gorunuyorsunuz. Belki bir sonraki adimi planlayabiliriz.");
    
    } else if (current_intent == UserIntent::Programming) { 
        plan.emplace_back(AIAction::OpenDocumentation, current_intent, "Programlama modundasÄ±nÄ±z. Gerekirse ilgili dokÃ¼manlarÄ± aÃ§abilirim.");
        if (current_abstract_state == AbstractState::Debugging) {
             plan.emplace_back(AIAction::ShowUndoHistory, current_intent, "Hata ayÄ±klama yapÄ±yor gibisiniz. Geri alma geÃ§miÅŸini veya versiyonlarÄ± kontrol edelim mi?");
        }
        plan.emplace_back(AIAction::EnableFocusMode, current_intent, "OdaklanmanÄ±zÄ± saÄŸlamak iÃ§in 'Odak Modu'nu etkinleÅŸtir.");
    } else if (current_intent == UserIntent::Gaming) { 
        plan.emplace_back(AIAction::OptimizeForGaming, current_intent, "Oyun oynuyor gibisiniz. Sistem performansÄ±nÄ± oyun iÃ§in optimize edelim mi?");
        plan.emplace_back(AIAction::MuteNotifications, current_intent, "Oyun sÄ±rasÄ±nda dikkatinizi daÄŸÄ±tmamak iÃ§in bildirimleri sessize alalÄ±m.");
        plan.emplace_back(AIAction::AdjustAudioVolume, current_intent, "Oyun iÃ§in ses seviyesini optimize edelim mi?");
    } else if (current_intent == UserIntent::MediaConsumption) { 
        plan.emplace_back(AIAction::DimScreen, current_intent, "Medya tÃ¼ketiyorsunuz. EkranÄ± daha da karartarak pil tasarrufu saÄŸlayabiliriz.");
        plan.emplace_back(AIAction::MuteNotifications, current_intent, "Kesintisiz bir deneyim iÃ§in bildirimleri sessize alalÄ±m.");
        plan.emplace_back(AIAction::AdjustAudioVolume, current_intent, "Medya iÃ§in ses seviyesini ayarla.");
    } else if (current_intent == UserIntent::CreativeWork) { 
        plan.emplace_back(AIAction::EnableFocusMode, current_intent, "YaratÄ±cÄ± Ã§alÄ±ÅŸÄ±yorsunuz. Odaklanma modu ile tÃ¼m dikkat daÄŸÄ±tÄ±cÄ±larÄ± engelleyelim.");
        plan.emplace_back(AIAction::SuggestBreak, current_intent, "YaratÄ±cÄ±lÄ±ÄŸÄ±nÄ±zÄ± tazelemek iÃ§in kÄ±sa bir mola Ã¶neririm.");
    }
    else if (current_intent == UserIntent::Research) { 
        plan.emplace_back(AIAction::EnableFocusMode, current_intent, "AraÅŸtÄ±rma yapÄ±yor gibisiniz. Verimli okuma iÃ§in odak modunu etkinleÅŸtir.");
        plan.emplace_back(AIAction::OpenDocumentation, current_intent, "AraÅŸtÄ±rmanÄ±zla ilgili kaynaklarÄ± otomatik olarak aÃ§abilirim.");
    }
    else if (current_intent == UserIntent::Communication) { 
        plan.emplace_back(AIAction::MuteNotifications, current_intent, "Ä°letiÅŸim kuruyorsunuz. Gereksiz bildirimleri sessize alarak daha akÄ±cÄ± bir sohbet saÄŸlayabiliriz.");
        plan.emplace_back(AIAction::EnableCustomDictionary, current_intent, "HÄ±zlÄ± ve doÄŸru yazÄ±m iÃ§in Ã¶zel sÃ¶zlÃ¼ÄŸÃ¼ etkinleÅŸtir.");
    }
    else if (current_intent == UserIntent::Unknown) { 
        plan.emplace_back(AIAction::None, current_intent, "Mevcut niyetiniz belirsiz. Daha fazla veri toplanarak ogrenme devam ediyor.");
        plan.emplace_back(AIAction::MuteNotifications, current_intent, "Belirsiz durumda dikkat dagiticilari azaltmak faydali olabilir.");
    }
    
    if (current_abstract_state == AbstractState::Distracted || current_abstract_state == AbstractState::LowProductivity) {
        bool already_suggested_mute = false;
        bool already_suggested_dim = false;
        for(const auto& step : plan) {
            if (step.action == AIAction::MuteNotifications) already_suggested_mute = true;
            if (step.action == AIAction::DimScreen) already_suggested_dim = true;
        }
        if (!already_suggested_mute) plan.emplace_back(AIAction::MuteNotifications, current_intent, "Genel uretkenlik dusukse tum bildirimleri kapatmak iyi bir fikir olabilir.");
        if (!already_suggested_dim) plan.emplace_back(AIAction::DimScreen, current_intent, "Odaklanmayi artirmak icin ekrani karart.");
    }
    // Hardware Anomaly durumunda Ã¶zel planlar
    if (current_abstract_state == AbstractState::HardwareAnomaly) {
        plan.clear(); // DiÄŸer tÃ¼m planlarÄ± geÃ§ersiz kÄ±l, acil durum!
        plan.emplace_back(AIAction::SimulateOSAction, current_intent, "DonanÄ±m anormalliÄŸi tespit edildi! Sistem kontrolÃ¼ ve teÅŸhis baÅŸlatÄ±lÄ±yor.");
        if (sequence.current_battery_percentage < 30 && !sequence.current_battery_charging) {
            plan.emplace_back(AIAction::None, current_intent, "Kritik batarya seviyesi. LÃ¼tfen ÅŸarj cihazÄ±nÄ± takÄ±n.");
        }
        if (sequence.network_activity_level == 0 && sequence.current_network_active) {
            plan.emplace_back(AIAction::SimulateOSAction, current_intent, "AÄŸ baÄŸlantÄ±sÄ± sorunlarÄ± olabilir. BaÄŸlantÄ±larÄ± kontrol et.");
        }
    }


    if (plan.empty() || (plan.size() == 1 && plan[0].action == AIAction::None && current_intent != UserIntent::Unknown && current_intent != UserIntent::None)) {
        plan.clear(); 
        plan.emplace_back(AIAction::None, current_intent, "AI, ogrenmeye devam ediyor. Lutfen etkilesiminize devam edin.");
        plan.emplace_back(AIAction::None, current_intent, "Belki hizli yazmaya baslamak istersiniz?");
        plan.emplace_back(AIAction::None, current_intent, "Veya bir seyleri duzenlemeye baslamak?");
    }
    return plan;
}

std::vector<ActionPlanStep> Planner::_plan_for_battery_life(UserIntent current_intent, AbstractState current_abstract_state, const DynamicSequence& sequence) const { 
    std::vector<ActionPlanStep> plan; 

    if (sequence.current_battery_percentage < 25 && !sequence.current_battery_charging) {
        plan.emplace_back(AIAction::DimScreen, current_intent, "Batarya kritik seviyede, ekrani hemen karartiliyor.");
        plan.emplace_back(AIAction::MuteNotifications, current_intent, "Batarya kritik seviyede, tum bildirimler sessize aliniyor.");
        plan.emplace_back(AIAction::None, current_intent, "Lutfen sarj aletinizi takin.");
        plan.emplace_back(AIAction::SimulateOSAction, current_intent, "Kritik batarya icin OS guc tasarrufu modunu etkinlestir.");
    } else if (sequence.current_battery_percentage < 45 && !sequence.current_battery_charging) {
        plan.emplace_back(AIAction::DimScreen, current_intent, "Batarya dusuk, ekrani karartiliyor.");
        plan.emplace_back(AIAction::MuteNotifications, current_intent, "Batarya dusuk, bildirimler sessize aliniyor.");
    } else if (sequence.current_battery_charging) {
        if (sequence.avg_brightness / 255.0f > 0.7f) { 
             plan.emplace_back(AIAction::DimScreen, current_intent, "Batarya sarj oluyor ama ekran Ã§ok parlak, parlakligi azalt.");
        }
        if (sequence.network_activity_level / 10000.0f > 0.8f) { 
             plan.emplace_back(AIAction::None, current_intent, "Yuksek ag aktivitesi, batarya sarj olurken enerji tuketimini dusurmek iÃ§in dikkat et.");
        }
    }
    
    if (plan.empty()) {
        plan.emplace_back(AIAction::None, current_intent, "Batarya tasarrufu iÃ§in ozel bir eylem onerisi yok.");
    }
    return plan;
}
 
--- C:\Users\aib\CerebrumLux\src\planning_execution\planner.h --- 
#ifndef CEREBRUM_LUX_PLANNER_H
#define CEREBRUM_LUX_PLANNER_H

#include <vector>  // For std::vector
#include <string>  // For std::string (was std::wstring)
#include "../core/enums.h"         // Enumlar iÃ§in
#include "../core/utils.h"         // For convert_wstring_to_string (if needed elsewhere)
#include "../data_models/dynamic_sequence.h" // DynamicSequence iÃ§in ileri bildirim
#include "../brain/intent_analyzer.h" // IntentAnalyzer iÃ§in ileri bildirim
#include "../brain/prediction_engine.h" // PredictionEngine iÃ§in ileri bildirim
#include "../communication/suggestion_engine.h" // SuggestionEngine iÃ§in ileri bildirim
#include "../communication/ai_insights_engine.h" // AIInsightsEngine iÃ§in ileri bildirim
#include "../planning_execution/goal_manager.h" // GoalManager iÃ§in ileri bildirim

// Ä°leri bildirimler
struct DynamicSequence;
class IntentAnalyzer;
class SuggestionEngine;
class GoalManager;
class PredictionEngine;
class AIInsightsEngine;

// === ActionPlanStep: Eylem planÄ± adÄ±mÄ± ===
struct ActionPlanStep {
    AIAction action;
    UserIntent triggered_by_intent;
    std::string description; // std::wstring yerine std::string

    ActionPlanStep(AIAction act, UserIntent intent, const std::string& desc); // const std::wstring& yerine const std::string&
};

// === Planner: AI'Ä±n eylem planlarÄ±nÄ± oluÅŸturur ve yÃ¼rÃ¼tÃ¼r ===
class Planner {
public:
    Planner(IntentAnalyzer& analyzer_ref, SuggestionEngine& suggester_ref,
            GoalManager& goal_manager_ref, PredictionEngine& predictor_ref,
            AIInsightsEngine& insights_engine_ref);

    // Mevcut duruma gÃ¶re bir eylem planÄ± oluÅŸturur
    std::vector<ActionPlanStep> create_action_plan(UserIntent current_intent, AbstractState current_abstract_state, AIGoal current_goal, const DynamicSequence& sequence) const;

    // OluÅŸturulan eylem planÄ±nÄ± yÃ¼rÃ¼tÃ¼r (simÃ¼le eder)
    void execute_plan(const std::vector<ActionPlanStep>& plan);

private:
    IntentAnalyzer& analyzer;
    SuggestionEngine& suggester;
    GoalManager& goal_manager;
    PredictionEngine& predictor;
    AIInsightsEngine& insights_engine;

    // YardÄ±mcÄ± planlama fonksiyonlarÄ±
    std::vector<ActionPlanStep> _plan_for_productivity(UserIntent current_intent, AbstractState current_abstract_state, const DynamicSequence& sequence) const;
    std::vector<ActionPlanStep> _plan_for_battery_life(UserIntent current_intent, AbstractState current_abstract_state, const DynamicSequence& sequence) const;
};

#endif // CEREBRUM_LUX_PLANNER_H 
--- C:\Users\aib\CerebrumLux\src\sensors\atomic_signal.cpp --- 
#include "atomic_signal.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/enums.h" // Gerekli enum'lar iÃ§in
#include <chrono> // std::chrono iÃ§in
#include "../core/logger.h"

// === AtomicSignal Implementasyonu (Constructor) ===
AtomicSignal::AtomicSignal() :
    timestamp_us(0),
    sensor_type(SensorType::Keyboard),
    virtual_key_code(0),
    character('\0'),
    key_type(KeyType::Other), 
    event_type(KeyEventType::Press),
    pressure_estimate(0),
    mouse_x(0), mouse_y(0), mouse_button_state(0), mouse_event_type(0),
    display_brightness(0), display_on(false),
    battery_percentage(0), battery_charging(false),
    network_active(false), network_bandwidth_estimate(0),
    // Mikrofon olaylarÄ± iÃ§in yeni alanlar EKLENDÄ°
    audio_level_db(0.0f),
    audio_frequency_hz(0.0f),
    speech_detected(false),
    audio_environment_hash(0),
    // Kamera olaylarÄ± iÃ§in yeni alanlar EKLENDÄ°
    ambient_light_lux(0.0f),
    face_detected(false),
    motion_detected(false),
    object_count(0),
    emotion_hash(0),
    active_app_id_hash(0) {} 
--- C:\Users\aib\CerebrumLux\src\sensors\atomic_signal.h --- 
#ifndef CEREBRUM_LUX_ATOMIC_SIGNAL_H
#define CEREBRUM_LUX_ATOMIC_SIGNAL_H

#include <chrono> // For timestamp_us
#include <string> // For wchar_t
#include "../core/enums.h" // Enum'lar iÃ§in
#include "../core/utils.h" // For convert_wstring_to_string (if needed elsewhere)

// *** AtomicSignal: Kendi ozel 'bilgi atomumuz' ***
struct AtomicSignal {
    long long timestamp_us;           
    SensorType sensor_type;           
    
    // Klavye olaylari icin
    unsigned int virtual_key_code;    
    char character;                
    KeyType key_type;                 
    KeyEventType event_type;          
    unsigned char pressure_estimate;  

    // Fare olaylari icin (ornek)
    int mouse_x;
    int mouse_y;
    unsigned char mouse_button_state; 
    unsigned char mouse_event_type;   

    // Ekran olaylari icin (ornek)
    unsigned char display_brightness; 
    bool display_on;

    // Batarya olaylari icin (ornek)
    unsigned char battery_percentage; 
    bool battery_charging;

    // Ag olaylari icin (ornek)
    bool network_active;
    unsigned short network_bandwidth_estimate; 

    // Mikrofon olaylarÄ± iÃ§in EKLENDÄ°
    float audio_level_db;              // Ses seviyesi (dB)
    float audio_frequency_hz;          // BaskÄ±n ses frekansÄ± (Hz)
    bool speech_detected;              // KonuÅŸma algÄ±landÄ± mÄ±?
    unsigned short audio_environment_hash; // Ses ortamÄ±nÄ±n Ã¶zeti (Ã¶rn: sessiz, gÃ¼rÃ¼ltÃ¼lÃ¼, mÃ¼zik)

    // Kamera olaylarÄ± iÃ§in EKLENDÄ°
    float ambient_light_lux;           // Ortam Ä±ÅŸÄ±k seviyesi (Lux)
    bool face_detected;                // YÃ¼z algÄ±landÄ± mÄ±?
    bool motion_detected;              // Hareket algÄ±landÄ± mÄ±?
    unsigned short object_count;       // AlgÄ±lanan nesne sayÄ±sÄ±
    unsigned short emotion_hash;       // AlgÄ±lanan duygunun Ã¶zeti

    // Genel baglam
    unsigned short active_app_id_hash; 

    AtomicSignal(); // Constructor bildirimi
};

#endif // CEREBRUM_LUX_ATOMIC_SIGNAL_H 
--- C:\Users\aib\CerebrumLux\src\sensors\signal_processor.h --- 
#ifndef CEREBRUM_LUX_SIGNAL_PROCESSOR_H
#define CEREBRUM_LUX_SIGNAL_PROCESSOR_H

#include "../core/enums.h" // Enum'lar iÃ§in
#include "atomic_signal.h" // AtomicSignal iÃ§in


class AtomicSignalProcessor; // Ä°leri bildirim

// *** AtomicSignalProcessor: Ä°ÅŸletim sistemi seviyesinde sinyal yakalama iÃ§in soyut arayÃ¼z ***
// Ä°leri bildirim
class AtomicSignalProcessor {
public:
    virtual ~AtomicSignalProcessor() = default; 
    virtual AtomicSignal capture_next_signal() = 0;
    virtual bool start_capture() = 0;
    virtual void stop_capture() = 0;
    virtual unsigned short get_active_application_id_hash() = 0;
};

#endif // CEREBRUM_LUX_SIGNAL_PROCESSOR_H 
--- C:\Users\aib\CerebrumLux\src\sensors\simulated_processor.cpp --- 
#include "simulated_processor.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/utils.h"       // LOG, hash_string ve SafeRNG iÃ§in
#include <iostream>              // std::cout, std::cerr iÃ§in
#include <numeric>               // std::accumulate iÃ§in
#include <cmath>                 // std::abs iÃ§in
#include <algorithm>             // std::min, std::max, std::towlower iÃ§in
#include <chrono>                // std::chrono iÃ§in
#include <locale> // std::towlower iÃ§in (cerebrum_lux_core.cpp'den geldi)
#include "../core/logger.h"
#include <sstream>   // std::stringstream iÃ§in

// Statik daÄŸÄ±tÄ±mlar burada kalabilir, Ã§Ã¼nkÃ¼ bunlar sadece daÄŸÄ±tÄ±m aralÄ±ÄŸÄ±nÄ± tanÄ±mlar, state tutmazlar.
// SENSOR_TYPE enum'Ä±nÄ±n tam aralÄ±ÄŸÄ±nÄ± kapsayacak ÅŸekilde daÄŸÄ±tÄ±m gÃ¼ncellendi
static std::uniform_int_distribution<int> s_sensor_selection_distrib(0, static_cast<int>(SensorType::Count) - 1); 

// Mikrofon iÃ§in ek daÄŸÄ±lÄ±mlar
static std::uniform_real_distribution<float> s_audio_level_distrib(-70.0f, -10.0f); // -70dB ile -10dB arasÄ±
static std::uniform_real_distribution<float> s_audio_freq_distrib(80.0f, 8000.0f); // 80Hz ile 8kHz arasÄ±
static std::uniform_int_distribution<> s_speech_distrib(0, 5); // %16 olasÄ±lÄ±kla konuÅŸma
static std::uniform_int_distribution<unsigned short> s_audio_env_distrib(0, 3); // 0: Silent, 1: Talk, 2: Music, 3: Noise

// Kamera iÃ§in ek daÄŸÄ±lÄ±mlar
static std::uniform_real_distribution<float> s_ambient_light_distrib(10.0f, 1000.0f); // 10 Lux (karanlÄ±k) - 1000 Lux (parlak)
static std::uniform_int_distribution<> s_face_motion_distrib(0, 10); // %10 olasÄ±lÄ±kla algÄ±lama
static std::uniform_int_distribution<unsigned short> s_object_count_distrib(0, 5); // 0-5 arasÄ± nesne
static std::uniform_int_distribution<unsigned short> s_emotion_distrib(0, 5); // 0: Neutral, 1: Happy, 2: Sad, 3: Angry, etc. (Ã¶rnek) 


SimulatedAtomicSignalProcessor::SimulatedAtomicSignalProcessor() 
    : last_key_press_time_us(0),
      current_mouse_x(0), current_mouse_y(0),
      current_brightness(200),
      current_battery(100), current_charging(true),
      current_network_active(true), current_network_bandwidth(5000),
      current_audio_level_db(-60.0f), current_audio_freq_hz(0.0f), current_speech_detected(false), current_audio_env_hash(0),
      current_ambient_light_lux(200.0f), current_face_detected(false), current_motion_detected(false), current_object_count(0), current_emotion_hash(0)
      {}

bool SimulatedAtomicSignalProcessor::start_capture() {
    LOG_DEFAULT(LogLevel::INFO, "Simulasyon baslatildi. Tuslara basin (Q ile Ã§ikis).\n");
    last_key_press_time_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    return true;
}

void SimulatedAtomicSignalProcessor::stop_capture() { 
    LOG_DEFAULT(LogLevel::INFO, "Simulasyon durduruldu.\n");
}

unsigned short SimulatedAtomicSignalProcessor::get_active_application_id_hash() {
    static int call_count = 0; 
    
    call_count++;
    if (call_count % 5 == 0) { 
        std::uniform_int_distribution<> distrib_app_id(0, 5); 
        int app_choice = distrib_app_id(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        if (app_choice == 0) return hash_string("Tarayici"); 
        else if (app_choice == 1) return hash_string("MetinEditoru");
        else if (app_choice == 2) return hash_string("Terminal");
        else if (app_choice == 3) return hash_string("OyunUygulamasi");
        else if (app_choice == 4) return hash_string("VideoOynatici");
        else return hash_string("IDE"); 
    }
    return hash_string("VarsayilanUygulama"); 
}

AtomicSignal SimulatedAtomicSignalProcessor::create_keyboard_signal(char ch) {
    AtomicSignal keyboard_signal;
    long long current_time_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    keyboard_signal.timestamp_us = current_time_us; 

    keyboard_signal.active_app_id_hash = get_active_application_id_hash();
    keyboard_signal.sensor_type = SensorType::Keyboard; 
    keyboard_signal.character = ch;
    keyboard_signal.virtual_key_code = static_cast<unsigned int>(ch);
    keyboard_signal.event_type = KeyEventType::Press; 

    if (last_key_press_time_us != 0) {
        long long interval = current_time_us - last_key_press_time_us;
        interval = std::max(50000LL, std::min(1000000LL, interval)); 
        keyboard_signal.pressure_estimate = static_cast<unsigned char>(255 - (interval * 255 / 1000000LL)); 
        LOG_DEFAULT(LogLevel::DEBUG, "Klavye sinyali aralÄ±ÄŸÄ±: " << (interval / 1000.0f) << " ms, BasÄ±nÃ§: " << static_cast<int>(keyboard_signal.pressure_estimate) << "\n");
    } else {
        keyboard_signal.pressure_estimate = 128; 
    }
    last_key_press_time_us = current_time_us; 

    char lower_ch = static_cast<char>(std::tolower(static_cast<unsigned char>(ch)));
    if (std::isalpha(lower_ch) || std::isdigit(lower_ch)) { 
        keyboard_signal.key_type = KeyType::Alphanumeric;
    } else if (lower_ch == ' ') { 
        keyboard_signal.key_type = KeyType::Whitespace;
    } else if (lower_ch == '\r' || lower_ch == '\n') { 
        keyboard_signal.key_type = KeyType::Enter;
    } else if (lower_ch == '\b') { 
        keyboard_signal.key_type = KeyType::Backspace;
    } else {
        keyboard_signal.key_type = KeyType::Other;
    }

    return keyboard_signal;
}

AtomicSignal SimulatedAtomicSignalProcessor::capture_next_signal() {
    AtomicSignal signal; 

    std::uniform_int_distribution<> other_sensor_type_distrib(
        static_cast<int>(SensorType::Mouse), 
        static_cast<int>(SensorType::Camera)
    );
    int chosen_sensor_type_for_sim = other_sensor_type_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°

    LOG_DEFAULT(LogLevel::TRACE, "SimulatedAtomicSignalProcessor::capture_next_signal: Rastgele seÃ§ilen klavye dÄ±ÅŸÄ± sensor tipi: " << chosen_sensor_type_for_sim << ".\n");

    if (static_cast<SensorType>(chosen_sensor_type_for_sim) == SensorType::Mouse) { 
        signal = simulate_mouse_event();
    } else if (static_cast<SensorType>(chosen_sensor_type_for_sim) == SensorType::Display) { 
        signal = simulate_display_event();
    } else if (static_cast<SensorType>(chosen_sensor_type_for_sim) == SensorType::Battery) { 
        signal = simulate_battery_event();
    } else if (static_cast<SensorType>(chosen_sensor_type_for_sim) == SensorType::Network) { 
        signal = simulate_network_event();
    } else if (static_cast<SensorType>(chosen_sensor_type_for_sim) == SensorType::Microphone) { // Yeni mikrofon simÃ¼lasyonu
        signal = simulate_microphone_event();
    } else if (static_cast<SensorType>(chosen_sensor_type_for_sim) == SensorType::Camera) { // Yeni kamera simÃ¼lasyonu
        signal = simulate_camera_event();
    }
    else { 
        signal.sensor_type = SensorType::None;
        signal.timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
            std::chrono::high_resolution_clock::now().time_since_epoch()
        ).count();
        signal.active_app_id_hash = get_active_application_id_hash();
        LOG_DEFAULT(LogLevel::WARNING, "SimulatedAtomicSignalProcessor::capture_next_signal: Bilinmeyen veya iÅŸlenmeyen sensor tipi secildi: " << chosen_sensor_type_for_sim << ". Varsayilan 'None' sinyali donduruluyor.\n");
    }
    
    return signal;
}

AtomicSignal SimulatedAtomicSignalProcessor::simulate_mouse_event() {
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_mouse_event: Basladi.\n"); 
    AtomicSignal signal;
    signal.timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    signal.sensor_type = SensorType::Mouse;
    signal.active_app_id_hash = get_active_application_id_hash();

    std::uniform_int_distribution<> event_distrib(0, 4); 
    std::uniform_int_distribution<> coord_change_distrib_min(-10, 10); 
    std::uniform_int_distribution<> coord_change_distrib_large(-100, 100); 
    std::uniform_int_distribution<> button_distrib(0, 2); 

    signal.mouse_event_type = event_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    
    if (signal.mouse_event_type == 0 || signal.mouse_event_type == 3 || signal.mouse_event_type == 4) { 
        LOG_DEFAULT(LogLevel::DEBUG, "simulate_mouse_event: Hareket olayÄ± tespit edildi.\n"); 
        signal.mouse_event_type = 0; 
        
        int delta_x_val = coord_change_distrib_large(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        int delta_y_val = coord_change_distrib_large(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°

        if (delta_x_val == 0 && delta_y_val == 0) { 
            delta_x_val = (SafeRNG::get_instance().get_generator()() % 2 == 0 ? 1 : -1) * (coord_change_distrib_min(SafeRNG::get_instance().get_generator()) + 1); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        }
        
        current_mouse_x += delta_x_val;
        current_mouse_y += delta_y_val;

        current_mouse_x = std::max(0, std::min(1920, current_mouse_x));
        current_mouse_y = std::max(0, std::min(1080, current_mouse_y)); 
        signal.mouse_x = current_mouse_x;
        signal.mouse_y = current_mouse_y;
        LOG_DEFAULT(LogLevel::DEBUG, "Mouse Hareket Sinyali OluÅŸturuldu: x=" << signal.mouse_x << ", y=" << signal.mouse_y << ", delta=(" << delta_x_val << "," << delta_y_val << ")\n"); 
    } else if (signal.mouse_event_type == 1) { 
        LOG_DEFAULT(LogLevel::DEBUG, "simulate_mouse_event: Tiklama olayÄ± tespit edildi.\n"); 
        signal.mouse_button_state = (button_distrib(SafeRNG::get_instance().get_generator()) == 0) ? 1 : 2; // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        signal.mouse_x = current_mouse_x; 
        signal.mouse_y = current_mouse_y;
        LOG_DEFAULT(LogLevel::DEBUG, "Mouse Tiklama Sinyali OluÅŸturuldu: x=" << signal.mouse_x << ", y=" << signal.mouse_y << ", button=" << static_cast<int>(signal.mouse_button_state) << "\n"); 
    } else { 
        LOG_DEFAULT(LogLevel::DEBUG, "simulate_mouse_event: KaydÄ±rma olayÄ± tespit edildi.\n"); 
        signal.mouse_button_state = 0; 
        
        int delta_x_scroll = coord_change_distrib_min(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        int delta_y_scroll = coord_change_distrib_min(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        if (std::abs(delta_x_scroll) < 1 && std::abs(delta_y_scroll) < 1) { 
            delta_y_scroll = (SafeRNG::get_instance().get_generator()() % 2 == 0 ? 1 : -1) * (coord_change_distrib_min(SafeRNG::get_instance().get_generator()) + 1); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        }
        current_mouse_x += delta_x_scroll;
        current_mouse_y += delta_y_scroll;
        current_mouse_x = std::max(0, std::min(1920, current_mouse_x));
        current_mouse_y = std::max(0, std::min(1080, current_mouse_y));
        signal.mouse_x = current_mouse_x; 
        signal.mouse_y = current_mouse_y;
        LOG_DEFAULT(LogLevel::DEBUG, "Mouse Kaydirma Sinyali OluÅŸturuldu: x=" << signal.mouse_x << ", y=" << signal.mouse_y << "\n");
    }
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_mouse_event: Bitti. Sinyal dÃ¶ndÃ¼rÃ¼lÃ¼yor.\n"); 
    return signal;
}

AtomicSignal SimulatedAtomicSignalProcessor::simulate_display_event() {
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_display_event: Basladi.\n");
    AtomicSignal signal;
    signal.timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    signal.sensor_type = SensorType::Display;
    signal.active_app_id_hash = get_active_application_id_hash();

    std::uniform_int_distribution<> brightness_distrib(50, 255); 
    std::uniform_int_distribution<> on_off_distrib(0, 20); 

    if (on_off_distrib(SafeRNG::get_instance().get_generator()) == 0) { // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        signal.display_on = false;
        current_brightness = 0;
    } else {
        signal.display_on = true;
        current_brightness = brightness_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    }
    signal.display_brightness = current_brightness;
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_display_event: Parlaklik=" << static_cast<int>(signal.display_brightness) << ", Acik=" << (signal.display_on ? "Evet" : "Hayir") << "\n");
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_display_event: Bitti.\n");
    return signal;
}

AtomicSignal SimulatedAtomicSignalProcessor::simulate_battery_event() {
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_battery_event: Basladi.\n");
    AtomicSignal signal;
    signal.timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    signal.sensor_type = SensorType::Battery;
    signal.active_app_id_hash = get_active_application_id_hash();

    std::uniform_int_distribution<> charge_change_distrib(-2, 2); 
    std::uniform_int_distribution<> charging_change_distrib(0, 10); 

    if (charging_change_distrib(SafeRNG::get_instance().get_generator()) == 0) { // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        current_charging = !current_charging;
    }
    
    current_battery += charge_change_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    current_battery = std::max(0, std::min(100, static_cast<int>(current_battery))); 

    signal.battery_percentage = current_battery;
    signal.battery_charging = current_charging;
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_battery_event: Pil=" << static_cast<int>(signal.battery_percentage) << "%, Sarj=" << (signal.battery_charging ? "Evet" : "Hayir") << "\n");
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_battery_event: Bitti.\n");
    return signal;
}

AtomicSignal SimulatedAtomicSignalProcessor::simulate_network_event() {
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_network_event: Basladi.\n");
    AtomicSignal signal;
    signal.timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    signal.sensor_type = SensorType::Network;
    signal.active_app_id_hash = get_active_application_id_hash();

    std::uniform_int_distribution<> active_distrib(0, 5); 
    std::uniform_int_distribution<> bandwidth_distrib(1000, 10000); 
    std::uniform_int_distribution<> idle_bandwidth_distrib(0, 500); 

    if (active_distrib(SafeRNG::get_instance().get_generator()) == 0) { // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
        current_network_active = !current_network_active;
    }
    signal.network_active = current_network_active;
    if (current_network_active) {
        signal.network_bandwidth_estimate = bandwidth_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    } else {
        signal.network_bandwidth_estimate = idle_bandwidth_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    }
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_network_event: Ag aktif=" << (signal.network_active ? "Evet" : "Hayir") << ", Bant genisliÄŸi=" << signal.network_bandwidth_estimate << " Kbps\n");
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_network_event: Bitti.\n");
    return signal;
}

// Yeni: Mikrofon olaylarÄ±nÄ± simÃ¼le eder
AtomicSignal SimulatedAtomicSignalProcessor::simulate_microphone_event() {
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_microphone_event: Basladi.\n");
    AtomicSignal signal;
    signal.timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    signal.sensor_type = SensorType::Microphone;
    signal.active_app_id_hash = get_active_application_id_hash();

    // Rastgele deÄŸerler Ã¼ret ve mevcut durumu gÃ¼ncelle
    current_audio_level_db = s_audio_level_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    current_audio_freq_hz = s_audio_freq_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    current_speech_detected = (s_speech_distrib(SafeRNG::get_instance().get_generator()) == 0); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    current_audio_env_hash = s_audio_env_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°

    signal.audio_level_db = current_audio_level_db;
    signal.audio_frequency_hz = current_audio_freq_hz;
    signal.speech_detected = current_speech_detected;
    signal.audio_environment_hash = current_audio_env_hash;

    LOG_DEFAULT(LogLevel::DEBUG, "Microphone Sinyali OluÅŸturuldu: Level=" << signal.audio_level_db << "dB, Freq=" << signal.audio_frequency_hz << "Hz, KonuÅŸma=" << (signal.speech_detected ? "Evet" : "HayÄ±r") << ", Ortam=" << signal.audio_environment_hash << "\n");
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_microphone_event: Bitti.\n");
    return signal;
}

// Yeni: Kamera olaylarÄ±nÄ± simÃ¼le eder
AtomicSignal SimulatedAtomicSignalProcessor::simulate_camera_event() {
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_camera_event: Basladi.\n");
    AtomicSignal signal;
    signal.timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    signal.sensor_type = SensorType::Camera;
    signal.active_app_id_hash = get_active_application_id_hash();

    // Rastgele deÄŸerler Ã¼ret ve mevcut durumu gÃ¼ncelle
    current_ambient_light_lux = s_ambient_light_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    current_face_detected = (s_face_motion_distrib(SafeRNG::get_instance().get_generator()) == 0); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    current_motion_detected = (s_face_motion_distrib(SafeRNG::get_instance().get_generator()) == 1); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    current_object_count = s_object_count_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°
    current_emotion_hash = s_emotion_distrib(SafeRNG::get_instance().get_generator()); // DEÄžÄ°ÅžTÄ°RÄ°LDÄ°

    signal.ambient_light_lux = current_ambient_light_lux;
    signal.face_detected = current_face_detected;
    signal.motion_detected = current_motion_detected;
    signal.object_count = current_object_count;
    signal.emotion_hash = current_emotion_hash;

    LOG_DEFAULT(LogLevel::DEBUG, "Camera Sinyali OluÅŸturuldu: IÅŸÄ±k=" << signal.ambient_light_lux << "Lux, YÃ¼z=" << (signal.face_detected ? "Evet" : "HayÄ±r") << ", Hareket=" << (signal.motion_detected ? "Evet" : "HayÄ±r") << ", Nesne=" << signal.object_count << ", Duygu=" << signal.emotion_hash << "\n");
    LOG_DEFAULT(LogLevel::DEBUG, "simulate_camera_event: Bitti.\n");
    return signal;
}
 
--- C:\Users\aib\CerebrumLux\src\sensors\simulated_processor.h --- 
#ifndef CEREBRUM_LUX_SIMULATED_PROCESSOR_H
#define CEREBRUM_LUX_SIMULATED_PROCESSOR_H

#include "../core/enums.h"    // Enumlar iÃ§in
#include "atomic_signal.h"    // AtomicSignal iÃ§in
#include "signal_processor.h" // Base class iÃ§in
#include "../core/utils.h"    // hash_string ve LOG iÃ§in
#include <chrono>             // Zaman damgalarÄ± iÃ§in
#include <algorithm>          // std::min/max iÃ§in
#include <locale>             // std::towlower iÃ§in


// *** SimulatedAtomicSignalProcessor: AtomicSignalProcessor'in simÃ¼le edilmis implementasyonu ***
class SimulatedAtomicSignalProcessor : public AtomicSignalProcessor {
private:
    long long last_key_press_time_us; 
    int current_mouse_x = 0;
    int current_mouse_y = 0;
    unsigned char current_brightness = 200;
    unsigned char current_battery = 100;
    bool current_charging = true;
    bool current_network_active = true;
    unsigned short current_network_bandwidth = 5000; 

    // Mikrofon simÃ¼lasyonu iÃ§in durum deÄŸiÅŸkenleri
    float current_audio_level_db = -60.0f; // dBFS (decibels relative to full scale)
    float current_audio_freq_hz = 0.0f;
    bool current_speech_detected = false;
    unsigned short current_audio_env_hash = 0; // 0: Silent, 1: Talk, 2: Music, 3: Noise

    // Kamera simÃ¼lasyonu iÃ§in durum deÄŸiÅŸkenleri
    float current_ambient_light_lux = 200.0f; // Typical indoor lighting
    bool current_face_detected = false;
    bool current_motion_detected = false;
    unsigned short current_object_count = 0;
    unsigned short current_emotion_hash = 0; // 0: Neutral, 1: Happy, 2: Sad, etc.

public:
    SimulatedAtomicSignalProcessor();
    AtomicSignal create_keyboard_signal(char ch); 
    
    AtomicSignal capture_next_signal() override; 
    
    bool start_capture() override;
    void stop_capture() override;
    unsigned short get_active_application_id_hash() override;

    AtomicSignal simulate_mouse_event();
    AtomicSignal simulate_display_event();
    AtomicSignal simulate_battery_event();
    AtomicSignal simulate_network_event();

    // Yeni eklendi: Mikrofon ve Kamera olaylarÄ±nÄ± simÃ¼le eden metodlar
    AtomicSignal simulate_microphone_event();
    AtomicSignal simulate_camera_event();
};

#endif // CEREBRUM_LUX_SIMULATED_PROCESSOR_H 
--- C:\Users\aib\CerebrumLux\src\tools\nlp_online_trainer.cpp --- 
#include <iostream>
#include <string>
#include "communication/natural_language_processor.h"
#include "core/logger.h"

int main() {
    // Initialize logger
    Logger::get_instance().init(LogLevel::INFO);

    // Use the default constructor for NLP
    NaturalLanguageProcessor nlp;

    std::cout << "ðŸ”¹ NLP Online Trainer baÅŸlatÄ±ldÄ±." << std::endl;

    try {
        nlp.load_model("data/models/nlp_model.dat");
        LOG_DEFAULT(LogLevel::INFO, "Model baÅŸarÄ±yla yÃ¼klendi.");
    } catch (...) {
        LOG_DEFAULT(LogLevel::WARNING, "Model bulunamadÄ±, yeni model oluÅŸturulacak.");
    }

    std::string input, expected;
    while (true) {
        std::cout << "\nCÃ¼mle girin (veya 'exit' ile Ã§Ä±k): ";
        std::getline(std::cin, input);
        if (input == "exit") break;

        std::cout << "Beklenen intent girin: ";
        std::getline(std::cin, expected);
        if (expected.empty()) {
            LOG_DEFAULT(LogLevel::WARNING, "BoÅŸ intent girildi, atlanÄ±yor.");
            continue;
        }

        // ðŸ”¹ Incremental training
        nlp.trainIncremental(input, expected);
        LOG_DEFAULT(LogLevel::INFO, "Incremental training tamamlandÄ±.");

        std::string predicted = nlp.predict_intent(input);
        std::cout << "ðŸ“Œ Tahmin edilen intent: " << predicted << std::endl;

        nlp.save_model("data/models/nlp_model.dat");
        LOG_DEFAULT(LogLevel::INFO, "Model kaydedildi.");
    }

    std::cout << "âœ… EÄŸitim oturumu sona erdi." << std::endl;
    return 0;
}
 
--- C:\Users\aib\CerebrumLux\src\user\user_profile_manager.cpp --- 
#include "user_profile_manager.h" // Kendi baÅŸlÄ±k dosyasÄ±nÄ± dahil et
#include "../core/logger.h"         // LOG makrosu iÃ§in
#include "../core/utils.h"          // intent_to_string, abstract_state_to_string vb. iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence'in tam tanÄ±mÄ± iÃ§in
#include <fstream>                  // Dosya G/Ã‡ iÃ§in
#include <iostream>                 // Debug Ã§Ä±ktÄ±larÄ± iÃ§in
#include <algorithm>                // std::sort, std::find_if iÃ§in
#include <sstream>                  // std::stringstream iÃ§in


// === UserProfileManager Implementasyonlari ===

// Kurucu
UserProfileManager::UserProfileManager() : history_max_size(50) {
    // VarsayÄ±lan tercihleri baÅŸlat (isteÄŸe baÄŸlÄ±)
    set_preference("Theme", "Dark");
    set_preference("NotificationSounds", "Enabled");
    set_preference("DefaultBrowser", "Chrome");

    LOG_DEFAULT(LogLevel::INFO, "UserProfileManager: BaÅŸlatÄ±ldÄ±. VarsayÄ±lan tercihler ayarlandÄ±.\n");
}

// Tercihleri yÃ¶netme
void UserProfileManager::set_preference(const std::string& key, const std::string& value) {
    preferences[key].key = key;
    preferences[key].value = value;
    preferences[key].last_modified_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
    LOG_DEFAULT(LogLevel::DEBUG, "UserProfileManager: Tercih ayarlandÄ± - " << key << ": " << value << "\n");
}

std::string UserProfileManager::get_preference(const std::string& key, const std::string& default_value) const {
    auto it = preferences.find(key);
    if (it != preferences.end()) {
        return it->second.value;
    }
    LOG_DEFAULT(LogLevel::WARNING, "UserProfileManager: '" << key << "' tercihi bulunamadÄ±. VarsayÄ±lan deÄŸer (" << default_value << ") kullanÄ±lÄ±yor.\n");
    return default_value;
}

bool UserProfileManager::has_preference(const std::string& key) const {
    return preferences.count(key);
}

// Uygulama kullanÄ±mÄ±nÄ± gÃ¼ncelleme
void UserProfileManager::update_app_usage(unsigned short app_hash) {
    long long current_time_us = std::chrono::duration_cast<std::chrono::microseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();

    if (app_usage_data.count(app_hash)) {
        app_usage_data[app_hash].usage_count++;
        app_usage_data[app_hash].last_used_us = current_time_us;
    } else {
        app_usage_data[app_hash] = {app_hash, 1, current_time_us};
    }
    LOG_DEFAULT(LogLevel::DEBUG, "UserProfileManager: Uygulama kullanÄ±mÄ± gÃ¼ncellendi - Hash: " << app_hash << ", SayÄ±m: " << app_usage_data[app_hash].usage_count << "\n");
}

std::vector<FrequentAppInfo> UserProfileManager::get_frequent_apps(int top_n) const {
    std::vector<FrequentAppInfo> sorted_apps;
    for (const auto& pair : app_usage_data) {
        sorted_apps.push_back(pair.second);
    }
    // KullanÄ±m sayÄ±sÄ±na gÃ¶re azalan sÄ±rada sÄ±rala
    std::sort(sorted_apps.begin(), sorted_apps.end(), [](const FrequentAppInfo& a, const FrequentAppInfo& b) {
        return a.usage_count > b.usage_count;
    });

    if (top_n > 0 && sorted_apps.size() > top_n) {
        sorted_apps.resize(top_n);
    }
    return sorted_apps;
}

// Niyet ve durum geÃ§miÅŸini yÃ¶netme
void UserProfileManager::add_intent_history_entry(UserIntent intent, long long timestamp_us) {
    intent_history.push_back({intent, timestamp_us});
    trim_history(); // GeÃ§miÅŸi temizle
    LOG_DEFAULT(LogLevel::DEBUG, "UserProfileManager: Niyet geÃ§miÅŸine eklendi - Niyet: " << intent_to_string(intent) << "\n");
}

void UserProfileManager::add_state_history_entry(AbstractState state, long long timestamp_us) {
    state_history.push_back({state, timestamp_us});
    trim_history(); // GeÃ§miÅŸi temizle
    LOG_DEFAULT(LogLevel::DEBUG, "UserProfileManager: Durum geÃ§miÅŸine eklendi - Durum: " << abstract_state_to_string(state) << "\n");
}

// KullanÄ±cÄ±nÄ±n bir eyleme verdiÄŸi aÃ§Ä±k geri bildirimi kaydeder - YENÄ° IMPLEMENTASYON
void UserProfileManager::add_explicit_action_feedback(UserIntent intent, AIAction action, bool approved) {
    personalized_action_feedback[intent][action].push_back(approved);
    // Ä°steÄŸe baÄŸlÄ±: geÃ§miÅŸ boyutu kontrolÃ¼ eklenebilir
    // Ã–rneÄŸin, belirli bir niyet-eylem Ã§ifti iÃ§in sadece son N geri bildirimi tutmak.
    // if (personalized_action_feedback[intent][action].size() > feedback_history_size) {
    //     personalized_action_feedback[intent][action].erase(personalized_action_feedback[intent][action].begin());
    // }
    LOG_DEFAULT(LogLevel::DEBUG, "UserProfileManager: AÃ§Ä±k eylem geri bildirimi kaydedildi - Niyet: " << intent_to_string(intent) << ", Eylem: " << static_cast<int>(action) << ", OnaylandÄ±: " << (approved ? "Evet" : "HayÄ±r") << "\n");
}


// KiÅŸiselleÅŸtirilmiÅŸ geri bildirim dÃ¶ngÃ¼leri
float UserProfileManager::get_personalized_feedback_strength(UserIntent intent, AIAction action) const {
    auto it_intent = personalized_action_feedback.find(intent);
    if (it_intent != personalized_action_feedback.end()) {
        auto it_action = it_intent->second.find(action);
        if (it_action != it_intent->second.end() && !it_action->second.empty()) {
            float positive_count = 0.0f;
            for (bool approved : it_action->second) {
                if (approved) positive_count += 1.0f;
            }
            // Ortalama onay oranÄ± dÃ¶ndÃ¼r
            return positive_count / it_action->second.size();
        }
    }
    return 0.5f; // VarsayÄ±lan nÃ¶tr (50%)
}

// `DynamicSequence`'ten gelen verilere gÃ¶re profili gÃ¼nceller
void UserProfileManager::update_profile_from_sequence(const DynamicSequence& sequence) {
    LOG_DEFAULT(LogLevel::DEBUG, "UserProfileManager: Profil DynamicSequence'ten gÃ¼ncelleniyor...\n");
    // Uygulama kullanÄ±mÄ±nÄ± gÃ¼ncelle
    if (sequence.current_app_hash != 0) { // GeÃ§erli bir uygulama hash'i varsa
        update_app_usage(sequence.current_app_hash);
    }

    // DiÄŸer metrikleri kullanarak implicit tercihleri veya durumlarÄ± gÃ¼ncelle (Ã¶rnek)
    if (sequence.current_battery_percentage < 20 && !sequence.current_battery_charging && !has_preference("LowBatteryAction")) {
        set_preference("LowBatteryAction", "DimScreen"); // DÃ¼ÅŸÃ¼k pil seviyesinde ekranÄ± karartma tercihi
        LOG_DEFAULT(LogLevel::INFO, "UserProfileManager: Yeni tercih kaydedildi: LowBatteryAction=DimScreen\n");
    }
    // Daha fazla kiÅŸiselleÅŸtirme mantÄ±ÄŸÄ± buraya eklenebilir.
}

// GeÃ§miÅŸ listelerini temizlemek iÃ§in
void UserProfileManager::trim_history() {
    if (intent_history.size() > history_max_size) {
        intent_history.erase(intent_history.begin(), intent_history.begin() + (intent_history.size() - history_max_size));
    }
    if (state_history.size() > history_max_size) {
        state_history.erase(state_history.begin(), state_history.begin() + (state_history.size() - history_max_size));
    }
}

// Profil verilerini dosyaya kaydet
void UserProfileManager::save_profile(const std::string& filename) const {
    std::ofstream ofs(filename);
    if (!ofs.is_open()) {
        LOG_DEFAULT(LogLevel::ERR_CRITICAL, "Hata: KullanÄ±cÄ± profili dosyasÄ± yazÄ±lamadÄ±: " << filename << "\n");
        return;
    }

    // Tercihleri yaz
    ofs << "[PREFERENCES]\n";
    for (const auto& pair : preferences) {
        ofs << pair.second.key << "=" << pair.second.value << "|" << pair.second.last_modified_us << "\n";
    }

    // Uygulama kullanÄ±mÄ±nÄ± yaz
    ofs << "[APP_USAGE]\n";
    for (const auto& pair : app_usage_data) {
        ofs << pair.second.app_hash << "=" << pair.second.usage_count << "|" << pair.second.last_used_us << "\n";
    }
    
    // Niyet geÃ§miÅŸini yaz
    ofs << "[INTENT_HISTORY]\n";
    for (const auto& entry : intent_history) {
        ofs << static_cast<int>(entry.first) << "|" << entry.second << "\n";
    }

    // Durum geÃ§miÅŸini yaz
    ofs << "[STATE_HISTORY]\n";
    for (const auto& entry : state_history) {
        ofs << static_cast<int>(entry.first) << "|" << entry.second << "\n";
    }

    // KiÅŸiselleÅŸtirilmiÅŸ eylem geri bildirimini yaz
    ofs << "[PERSONALIZED_ACTION_FEEDBACK]\n";
    for (const auto& intent_pair : personalized_action_feedback) {
        ofs << static_cast<int>(intent_pair.first) << ":\n";
        for (const auto& action_pair : intent_pair.second) {
            ofs << "  " << static_cast<int>(action_pair.first) << ":";
            for (bool approved : action_pair.second) {
                ofs << (approved ? "1" : "0");
            }
            ofs << "\n";
        }
    }

    ofs.close();
    LOG_DEFAULT(LogLevel::INFO, "UserProfileManager: KullanÄ±cÄ± profili kaydedildi: " << filename << "\n");
}

// Profil verilerini dosyadan yÃ¼kle
void UserProfileManager::load_profile(const std::string& filename) {
    std::ifstream ifs(filename);
    if (!ifs.is_open()) {
        LOG_DEFAULT(LogLevel::WARNING, "UyarÄ±: KullanÄ±cÄ± profili dosyasÄ± bulunamadÄ±, varsayÄ±lan profil kullanÄ±lÄ±yor: " << filename << "\n");
        return;
    }

    preferences.clear();
    app_usage_data.clear();
    intent_history.clear();
    state_history.clear();
    personalized_action_feedback.clear();

    std::string line;
    std::string current_section;

    while (std::getline(ifs, line)) {
        if (line.empty()) continue;

        if (line.front() == '[' && line.back() == ']') {
            current_section = line;
            continue;
        }

        if (current_section == "[PREFERENCES]") {
            size_t eq_pos = line.find('=');
            size_t pipe_pos = line.find('|', eq_pos);
            if (eq_pos != std::string::npos && pipe_pos != std::string::npos) {
                std::string key = line.substr(0, eq_pos);
                std::string value = line.substr(eq_pos + 1, pipe_pos - (eq_pos + 1));
                long long timestamp = std::stoll(line.substr(pipe_pos + 1));
                preferences[key] = {key, value, timestamp};
            }
        } else if (current_section == "[APP_USAGE]") {
            size_t eq_pos = line.find('=');
            size_t pipe_pos = line.find('|', eq_pos);
            if (eq_pos != std::string::npos && pipe_pos != std::string::npos) {
                unsigned short app_hash = static_cast<unsigned short>(std::stoul(line.substr(0, eq_pos)));
                int usage_count = std::stoi(line.substr(eq_pos + 1, pipe_pos - (eq_pos + 1)));
                long long last_used_us = std::stoll(line.substr(pipe_pos + 1));
                app_usage_data[app_hash] = {app_hash, usage_count, last_used_us};
            }
        } else if (current_section == "[INTENT_HISTORY]") {
            size_t pipe_pos = line.find('|');
            if (pipe_pos != std::string::npos) {
                UserIntent intent = static_cast<UserIntent>(std::stoi(line.substr(0, pipe_pos)));
                long long timestamp = std::stoll(line.substr(pipe_pos + 1));
                intent_history.push_back({intent, timestamp});
            }
        } else if (current_section == "[STATE_HISTORY]") {
            size_t pipe_pos = line.find('|');
            if (pipe_pos != std::string::npos) {
                AbstractState state = static_cast<AbstractState>(std::stoi(line.substr(0, pipe_pos)));
                long long timestamp = std::stoll(line.substr(pipe_pos + 1));
                state_history.push_back({state, timestamp});
            }
        } else if (current_section == "[PERSONALIZED_ACTION_FEEDBACK]") {
            size_t colon_pos = line.find(':');
            if (colon_pos != std::string::npos) {
                std::string sub_line_start = line.substr(0, colon_pos);
                std::string sub_line_data = line.substr(colon_pos + 1);

                // Bu bÃ¶lÃ¼mÃ¼n intent_id'si ile baÅŸlamasÄ± beklenir (Ã¶rn: "1:")
                if (sub_line_start.find("  ") == std::string::npos) { // Niyet baÅŸlÄ±ÄŸÄ± satÄ±rÄ± (Ã¶rn: "3:")
                    UserIntent intent_id = static_cast<UserIntent>(std::stoi(sub_line_start));
                    personalized_action_feedback[intent_id] = {}; // Yeni niyet iÃ§in boÅŸ bir map baÅŸlat
                    // Bir sonraki satÄ±r veya satÄ±rlar bu niyete ait eylem geri bildirimlerini iÃ§erecektir.
                    // Okuma sÄ±rasÄ±nda `current_intent` bilgisini takip etmek iÃ§in geÃ§ici bir deÄŸiÅŸken kullanabiliriz
                    // Ancak bu karmaÅŸÄ±klÄ±ÄŸÄ± artÄ±rÄ±r. Åžimdilik bu varsayÄ±mla devam ediyoruz.
                    // Okuma sÄ±rasÄ±nda bu intent_id'yi current_loading_intent olarak saklayabiliriz.
                } else { // Eylem geri bildirimi satÄ±rÄ± (Ã¶rn: "  1:10101")
                    // En son okunan niyete ait olduÄŸunu varsayarak
                    if (!personalized_action_feedback.empty()) {
                        UserIntent last_read_intent = personalized_action_feedback.rbegin()->first;
                        int action_id = std::stoi(sub_line_start.substr(2)); // "  " kaldÄ±r
                        std::vector<bool> feedback_vector;
                        for (char c : sub_line_data) {
                            if (c == '1') feedback_vector.push_back(true);
                            else if (c == '0') feedback_vector.push_back(false);
                        }
                        personalized_action_feedback[last_read_intent][static_cast<AIAction>(action_id)] = feedback_vector;
                    }
                }
            }
        }
    }
    ifs.close();
    LOG_DEFAULT(LogLevel::INFO, "UserProfileManager: KullanÄ±cÄ± profili yÃ¼klendi: " << filename << "\n");
} 
--- C:\Users\aib\CerebrumLux\src\user\user_profile_manager.h --- 
#ifndef CEREBRUM_LUX_USER_PROFILE_MANAGER_H
#define CEREBRUM_LUX_USER_PROFILE_MANAGER_H

#include <string>   // std::string iÃ§in
#include <vector>   // std::vector iÃ§in
#include <map>      // std::map iÃ§in
#include <set>      // std::set iÃ§in (tercihler iÃ§in)
#include <chrono>   // Zaman bilgileri iÃ§in

#include "../core/enums.h"         // Enumlar iÃ§in
#include "../core/utils.h"         // hash_string vb. iÃ§in
#include "../data_models/dynamic_sequence.h" // DynamicSequence'den metrikleri almak iÃ§in

// Ä°leri bildirimler (eÄŸer baÅŸka sÄ±nÄ±flardan referans alacaksa)
// class IntentLearner; // Ã–rnek

// KullanÄ±cÄ± tercihlerini ve geÃ§miÅŸini temsil eden yapÄ±
struct UserPreference {
    std::string key;   // Ã–rneÄŸin: "DarkThemeEnabled", "NotificationSoundLevel"
    std::string value; // Ã–rneÄŸin: "true", "50"
    long long last_modified_us;
};

// SÄ±k kullanÄ±lan uygulama bilgilerini tutan yapÄ±
struct FrequentAppInfo {
    unsigned short app_hash;
    int usage_count;
    long long last_used_us;

    // std::map'te anahtar olarak kullanÄ±labilmesi iÃ§in karÅŸÄ±laÅŸtÄ±rma operatÃ¶rÃ¼ (isteÄŸe baÄŸlÄ±)
    bool operator<(const FrequentAppInfo& other) const {
        return app_hash < other.app_hash;
    }
};

// *** UserProfileManager: KullanÄ±cÄ± profilini ve tercihlerini yÃ¶netir ***
class UserProfileManager {
public:
    // Kurucu
    UserProfileManager();

    // KullanÄ±cÄ± tercihlerini yÃ¼kler ve kaydeder
    void load_profile(const std::string& filename);
    void save_profile(const std::string& filename) const;

    // Tercihleri yÃ¶netme
    void set_preference(const std::string& key, const std::string& value);
    std::string get_preference(const std::string& key, const std::string& default_value = "") const;
    bool has_preference(const std::string& key) const;

    // Uygulama kullanÄ±mÄ±nÄ± gÃ¼ncelleme
    void update_app_usage(unsigned short app_hash);
    std::vector<FrequentAppInfo> get_frequent_apps(int top_n = 5) const; // En sÄ±k kullanÄ±lan N uygulamayÄ± dÃ¶ndÃ¼rÃ¼r

    // Niyet ve durum geÃ§miÅŸini yÃ¶netme (IntentLearner ile koordineli)
    void add_intent_history_entry(UserIntent intent, long long timestamp_us);
    void add_state_history_entry(AbstractState state, long long timestamp_us);

    // KullanÄ±cÄ±nÄ±n bir eyleme verdiÄŸi aÃ§Ä±k geri bildirimi kaydeder - YENÄ°
    void add_explicit_action_feedback(UserIntent intent, AIAction action, bool approved);

    // KiÅŸiselleÅŸtirilmiÅŸ geri bildirim dÃ¶ngÃ¼leri
    // Bu, AI'Ä±n ResponseEngine veya Planner ile kiÅŸiselleÅŸtirilmiÅŸ yanÄ±tlar/planlar Ã¼retmesine yardÄ±mcÄ± olabilir.
    // Ã–rneÄŸin, belirli bir niyete veya duruma kullanÄ±cÄ±nÄ±n Ã¶nceki tepkilerini deÄŸerlendirme.
    float get_personalized_feedback_strength(UserIntent intent, AIAction action) const;

    // `DynamicSequence`'ten gelen verilere gÃ¶re profili gÃ¼nceller
    void update_profile_from_sequence(const DynamicSequence& sequence);

private:
    std::map<std::string, UserPreference> preferences;
    std::map<unsigned short, FrequentAppInfo> app_usage_data;
    std::vector<std::pair<UserIntent, long long>> intent_history; // Son N niyet
    std::vector<std::pair<AbstractState, long long>> state_history; // Son N durum

    // PekiÅŸtirmeli Ã¶ÄŸrenme benzeri, kiÅŸiselleÅŸtirilmiÅŸ eylem/niyet baÅŸarÄ± matrisi
    // KullanÄ±cÄ±nÄ±n belirli durumlarda belirli eylemlere verdiÄŸi olumlu/olumsuz geri bildirimleri depolar.
    std::map<UserIntent, std::map<AIAction, std::vector<bool>>> personalized_action_feedback; // true=approved, false=rejected
    size_t history_max_size = 50; // GeÃ§miÅŸ tutulacak maksimum eleman sayÄ±sÄ±

    // YardÄ±mcÄ± metotlar
    void trim_history(); // GeÃ§miÅŸ listelerini temizlemek iÃ§in
};

#endif // CEREBRUM_LUX_USER_PROFILE_MANAGER_H 
--- C:\Users\aib\CerebrumLux\tests\test_response_engine.cpp --- 
#include <iostream>
#include <cassert>
#include <string>
#include <vector>
#include <map>
#include <deque>
#include <fstream> 
#include <optional> 

// OpenSSL BaÅŸlÄ±klarÄ± (Sadece EVP_CIPHER_iv_length iÃ§in gerekli olanÄ± bÄ±rakÄ±ldÄ±)
#include <openssl/evp.h> 

// Project headers (use relative path from tests/)
#include "../src/communication/response_engine.h"
#include "../src/communication/ai_insights_engine.h"
#include "../src/communication/suggestion_engine.h"
#include "../src/communication/natural_language_processor.h"
#include "../src/brain/intent_analyzer.h"
#include "../src/brain/intent_learner.h"
#include "../src/brain/prediction_engine.h"
#include "../src/brain/cryptofig_processor.h"
#include "../src/brain/autoencoder.h"
#include "../src/data_models/dynamic_sequence.h"
#include "../src/data_models/sequence_manager.h" 
#include "../src/user/user_profile_manager.h"
#include "../src/planning_execution/goal_manager.h"
#include "../src/core/logger.h"
#include "../src/core/utils.h" // utils.h'de artÄ±k global base64 fonksiyonlarÄ± yok
#include "../src/learning/KnowledgeBase.h" 
#include "../src/learning/LearningModule.h" 
#include "../src/learning/Capsule.h" 
#include "../src/learning/WebFetcher.h" 

// Rastgele sayÄ± Ã¼reteci (random_device hatasÄ±nÄ± Ã¶nlemek iÃ§in sabit seed ile)
static std::mt19937 gen_test(12345); 

// GeÃ§ici olarak Ed25519 sabitleri tanÄ±mlanÄ±yor, OpenSSL bulunana kadar
#define DUMMY_ED25519_PRIVKEY_LEN 64 
#define DUMMY_ED25519_PUBKEY_LEN 32  
#define DUMMY_ED25519_SIG_LEN   64   

// === Dummy implementations for testing ===

// Dummy SequenceManager
// HATA DÃœZELTME: Base class metodlarÄ± virtual olmadÄ±ÄŸÄ± iÃ§in 'override' kaldÄ±rÄ±ldÄ±.
class DummySequenceManager : public SequenceManager {
public:
    DummySequenceManager() : SequenceManager() {}
    bool add_signal(const AtomicSignal& signal, CryptofigProcessor& cryptofig_processor) { 
        (void)signal; (void)cryptofig_processor; 
        return true;
    }
    std::deque<AtomicSignal> get_signal_buffer_copy() const { 
        return std::deque<AtomicSignal>{};
    }
    DynamicSequence& get_current_sequence_ref() { 
        static DynamicSequence dummy_seq;
        return dummy_seq;
    }
    const DynamicSequence& get_current_sequence_ref() const { 
        static DynamicSequence dummy_seq;
        return dummy_seq;
    }
};

// DummyIntentAnalyzer
class DummyIntentAnalyzer : public IntentAnalyzer {
public:
    DummyIntentAnalyzer() : IntentAnalyzer() {}
    virtual UserIntent analyze_intent(const DynamicSequence& sequence) override {
        (void)sequence; 
        if (sequence.avg_keystroke_interval > 100000.0f) return UserIntent::IdleThinking;
        if (sequence.alphanumeric_ratio > 0.8f) return UserIntent::FastTyping;
        return UserIntent::Editing;
    }
};

// DummySuggestionEngine
class DummySuggestionEngine : public SuggestionEngine {
public:
    DummySuggestionEngine(IntentAnalyzer& analyzer_ref) : SuggestionEngine(analyzer_ref) {}
    virtual AIAction suggest_action(UserIntent current_intent, AbstractState current_abstract_state, const DynamicSequence& sequence) override { 
        (void)sequence; 
        if (current_intent == UserIntent::IdleThinking) return AIAction::SuggestBreak;
        if (current_abstract_state == AbstractState::LowProductivity) return AIAction::DimScreen;
        return AIAction::None;
    }
    virtual void update_q_value(const StateKey& state, AIAction action, float reward) override { 
        (void)state; (void)action; (void)reward; 
    }
};

// DummyUserProfileManager
// HATA DÃœZELTME: Base class metodlarÄ± virtual olmadÄ±ÄŸÄ± iÃ§in 'override' kaldÄ±rÄ±ldÄ±.
class DummyUserProfileManager : public UserProfileManager {
public:
    DummyUserProfileManager() : UserProfileManager() {}
    void update_profile_from_sequence(const DynamicSequence& sequence) { 
        (void)sequence; 
    }
    void add_intent_history_entry(UserIntent intent, long long timestamp_us) { 
        (void)timestamp_us; (void)intent;
    }
    void add_state_history_entry(AbstractState state, long long timestamp_us) { 
        (void)timestamp_us; (void)state;
    }
    void add_explicit_action_feedback(UserIntent intent, AIAction action, bool approved) { 
        (void)intent; (void)action; (void)approved; 
    }
    void load_profile(const std::string& filename) { 
        (void)filename; 
    }
    void save_profile(const std::string& filename) const { 
        (void)filename; 
    }
};

// Dummy IntentLearner
// HATA DÃœZELTME: Sadece IntentLearner base class'Ä±ndaki virtual metodlar override edildi. 
// LearningModule'e ait olan ve override hatasÄ± veren metodlar bu dummy class'tan kaldÄ±rÄ±ldÄ±.
class DummyIntentLearner : public IntentLearner {
public:
    DummyIntentLearner(IntentAnalyzer& analyzer_ref, SuggestionEngine& suggester_ref, UserProfileManager& user_profile_manager_ref)
        : IntentLearner(analyzer_ref, suggester_ref, user_profile_manager_ref) {}

    virtual void process_explicit_feedback(UserIntent predicted_intent, AIAction action, bool approved, const DynamicSequence& sequence, AbstractState current_abstract_state) override {
        (void)sequence; 
        std::cout << "[DUMMY LEARNER] Acik geri bildirim: " << intent_to_string(predicted_intent)
             << ", eylem=" << static_cast<int>(action) << ", onay=" << (approved ? "Evet" : "Hayir")
             << ", durum=" << abstract_state_to_string(current_abstract_state) << "\n";
    }

    virtual AbstractState infer_abstract_state(const std::deque<AtomicSignal>& recent_signals) override {
        if (recent_signals.size() > 50) return AbstractState::HighProductivity;
        if (recent_signals.empty()) return AbstractState::None;
        return AbstractState::NormalOperation;
    }
};

// Dummy PredictionEngine
// HATA DÃœZELTME: Base class'ta virtual olmayan metodlardan 'override' kaldÄ±rÄ±ldÄ±.
class DummyPredictionEngine : public PredictionEngine {
public:
    DummyPredictionEngine(IntentAnalyzer& analyzer_ref, SequenceManager& sequence_manager_ref)
        : PredictionEngine(analyzer_ref, sequence_manager_ref) {}
    virtual UserIntent predict_next_intent(UserIntent current_intent, const DynamicSequence& sequence) const override { 
        (void)current_intent; (void)sequence; 
        return UserIntent::Unknown;
    }
    void update_state_graph(UserIntent from_intent, UserIntent to_intent, const DynamicSequence& sequence) { 
        (void)from_intent; (void)to_intent; (void)sequence; 
    }
    void save_state_graph(const std::string& filename) const { 
        (void)filename; 
    }
    void load_state_graph(const std::string& filename) {  
        (void)filename; 
    }
};

// DummyCryptofigAutoencoder
// HATA DÃœZELTME: Base class'ta virtual olmayan metodlardan 'override' kaldÄ±rÄ±ldÄ±.
class DummyCryptofigAutoencoder : public CryptofigAutoencoder {
public:
    DummyCryptofigAutoencoder() : CryptofigAutoencoder() {}
    virtual std::vector<float> encode(const std::vector<float>& input_features) const override {
        (void)input_features; 
        return {0.1f, 0.2f, 0.3f};
    }
    void save_weights(const std::string& filename) const { 
        (void)filename; 
    }
    void load_weights(const std::string& filename) {  
        (void)filename; 
    }
    virtual float calculate_reconstruction_error(const std::vector<float>& original, const std::vector<float>& reconstructed) const override {
        (void)original; (void)reconstructed; 
        return 0.0f;
    }
};

// DummyCryptofigProcessor
// HATA DÃœZELTME: Base class'ta virtual olmayan metodlardan 'override' kaldÄ±rÄ±ldÄ±.
class DummyCryptofigProcessor : public CryptofigProcessor {
public:
    DummyCryptofigProcessor(IntentAnalyzer& analyzer_ref, CryptofigAutoencoder& autoencoder_ref)
        : CryptofigProcessor(analyzer_ref, autoencoder_ref) {}

    void process_sequence(DynamicSequence& sequence, float autoencoder_learning_rate) { 
        (void)autoencoder_learning_rate; 
        sequence.latent_cryptofig_vector = {0.4f, 0.5f, 0.6f};
    }
    virtual void process_expert_cryptofig(const std::vector<float>& expert_cryptofig, IntentLearner& learner) override {
        (void)expert_cryptofig; (void)learner; 
    }
    virtual std::vector<float> generate_cryptofig_from_signals(const DynamicSequence& sequence) override {
        (void)sequence; 
        return {0.7f, 0.8f, 0.9f};
    }
    virtual const CryptofigAutoencoder& get_autoencoder() const override {
        static DummyCryptofigAutoencoder da;
        return da;
    }
    virtual CryptofigAutoencoder& get_autoencoder() override {
        static DummyCryptofigAutoencoder da;
        return da;
    }
};

// DummyAIInsightsEngine
class DummyAIInsightsEngine : public AIInsightsEngine {
public:
    DummyAIInsightsEngine(IntentAnalyzer& a, IntentLearner& l, PredictionEngine& p, CryptofigAutoencoder& ae, CryptofigProcessor& cp)
        : AIInsightsEngine(a, l, p, ae, cp) {}

    virtual std::vector<AIInsight> generate_insights(const DynamicSequence& sequence) override {
        (void)sequence; 
        AIInsight insight("Performance looks good.", AIAction::None, 0.8f); 
        std::vector<AIInsight> out;
        out.push_back(insight); 
        return out;
    }
    virtual IntentAnalyzer& get_analyzer() const override {
        static DummyIntentAnalyzer analyzer_temp;
        return analyzer_temp;
    }
};

// DummyGoalManager
class DummyGoalManager : public GoalManager {
public:
    DummyGoalManager(AIInsightsEngine& ie) : GoalManager(ie) {}
    virtual AIGoal get_current_goal() const override {
        return AIGoal::OptimizeProductivity;
    }
};

// DummyNaturalLanguageProcessor
// HATA DÃœZELTME: Base class metodlarÄ± virtual olmadÄ±ÄŸÄ± iÃ§in 'override' kaldÄ±rÄ±ldÄ±.
class DummyNaturalLanguageProcessor : public NaturalLanguageProcessor {
public:
    DummyNaturalLanguageProcessor(GoalManager& gm) : NaturalLanguageProcessor(gm) {}

    std::string generate_response_text(UserIntent current_intent, AbstractState current_abstract_state, AIGoal current_goal,
                                  const DynamicSequence& sequence, const std::vector<std::string>& relevant_keywords = {}) const { 
        (void)current_intent; (void)current_abstract_state; (void)current_goal; (void)sequence; (void)relevant_keywords; 
        return "NLP'den gelen test yaniti.";
    }
    UserIntent infer_intent_from_text(const std::string& user_input) const { 
        if (user_input.find("oyun") != std::string::npos) return UserIntent::Gaming;
        return UserIntent::GeneralInquiry;
    }
    AbstractState infer_state_from_text(const std::string& user_input) const { 
        if (user_input.find("pil") != std::string::npos) return AbstractState::PowerSaving;
        return AbstractState::NormalOperation;
    }
};

// Dummy WebFetcher
class DummyWebFetcher : public WebFetcher {
public:
    DummyWebFetcher() : WebFetcher() {}
    virtual std::vector<WebResult> search(const std::string& query) override { 
        (void)query;
        WebResult res1 = {"Test Content 1", "Test Source 1"};
        WebResult res2 = {"Test Content 2", "Test Source 2"};
        return {res1, res2};
    }
};


// Helper to sign and encrypt capsules for testing (global olarak tanÄ±mlanÄ±yor)
// LearningModule objesini parametre olarak alÄ±yor.
Capsule create_signed_encrypted_capsule_helper(LearningModule& lm, const std::string& id_prefix, const std::string& content, const std::string& source_peer, float confidence) {
    Capsule c;
    static unsigned int test_capsule_id_counter = 0; 
    c.id = id_prefix + std::to_string(++test_capsule_id_counter); 
    c.content = content;
    c.source = source_peer;
    c.topic = "Test Topic";
    c.confidence = confidence;
    c.plain_text_summary = content.substr(0, std::min((size_t)100, content.length())) + "...";
    c.timestamp_utc = std::chrono::system_clock::now();
    
    c.embedding = lm.compute_embedding(c.content);
    c.cryptofig_blob_base64 = lm.cryptofig_encode(c.embedding);

    std::string aes_key = lm.get_aes_key_for_peer(source_peer);
    std::string iv = lm.generate_random_bytes(EVP_CIPHER_iv_length(EVP_aes_256_gcm()));
    
    // HATA DÃœZELTME: `base64_encode_internal` private olduÄŸu iÃ§in global `base64_encode` kullanÄ±ldÄ±.
    // Bu fonksiyonun utils.h'de tanÄ±mlÄ± olduÄŸu ve linklendiÄŸi varsayÄ±lmÄ±ÅŸtÄ±r.
    c.encryption_iv_base64 = base64_encode(iv);
    c.encrypted_content = lm.aes_gcm_encrypt(c.content, aes_key, iv);

    // Ed25519 fonksiyonlarÄ± yorum satÄ±rÄ± yapÄ±ldÄ±ÄŸÄ± iÃ§in burada da simÃ¼le ediyoruz
    // std::string private_key = lm.get_my_private_key(); 
    // c.signature_base64 = lm.ed25519_sign(c.encrypted_content, private_key);
    c.signature_base64 = "valid_signature"; 
    return c;
}


// === Test main ===
int main() {
    std::cout << "ResponseEngine testleri (dÃ¼zeltilmiÅŸ) baÅŸlatÄ±lÄ±yor...\n";
    // HATA DÃœZELTME: KÄ±rÄ±k olan include'dan kaynaklanan 'Logger' tanÄ±namadÄ± hatasÄ± dÃ¼zeltildi.
    Logger::get_instance().init(LogLevel::DEBUG, "test_log.txt");

    // Create dummy components
    DummyIntentAnalyzer dummy_analyzer;
    DummySequenceManager dummy_sequence_manager; 
    DummySuggestionEngine dummy_suggester(dummy_analyzer);
    DummyUserProfileManager dummy_user_profile_manager;
    DummyIntentLearner dummy_learner(dummy_analyzer, dummy_suggester, dummy_user_profile_manager);
    
    DummyCryptofigAutoencoder dummy_autoencoder; 
    DummyCryptofigProcessor dummy_cryptofig_processor(dummy_analyzer, dummy_autoencoder);
    DummyPredictionEngine dummy_predictor(dummy_analyzer, dummy_sequence_manager); 
    DummyAIInsightsEngine dummy_insights_engine(dummy_analyzer, dummy_learner, dummy_predictor, dummy_autoencoder, dummy_cryptofig_processor);
    DummyGoalManager dummy_goal_manager(dummy_insights_engine);
    DummyNaturalLanguageProcessor dummy_nlp(dummy_goal_manager); 

    ResponseEngine response_engine(dummy_analyzer, dummy_goal_manager, dummy_insights_engine, &dummy_nlp);

    // Prepare a DynamicSequence for testing
    DynamicSequence seq;
    seq.avg_keystroke_interval = 150000.0f; 
    seq.alphanumeric_ratio = 0.9f;
    seq.current_battery_percentage = 85;
    seq.current_battery_charging = false;
    seq.latent_cryptofig_vector = {0.5f, 0.6f, 0.7f};

    // Test 1: general response
    std::cout << "\n--- Test 1: Genel YanÄ±t ---\n";
    std::string r1 = response_engine.generate_response(UserIntent::None, AbstractState::None, AIGoal::None, seq);
    std::cout << "AI Yaniti: " << r1 << "\n";
    assert(!r1.empty());

    // Test 2: specific intent/state
    std::cout << "\n--- Test 2: Programlama ve Odaklanma ---\n";
    std::string r2 = response_engine.generate_response(UserIntent::Programming, AbstractState::Focused, AIGoal::OptimizeProductivity, seq);
    std::cout << "AI Yaniti: " << r2 << "\n";
    assert(!r2.empty());

    // Test 3: critical action confirmation (just ensure non-empty)
    std::cout << "\n--- Test 3: Kritik Eylem ---\n";
    std::string r3 = response_engine.generate_response(UserIntent::None, AbstractState::None, AIGoal::OptimizeProductivity, seq);
    std::cout << "AI Yaniti: " << r3 << "\n";
    assert(!r3.empty());

    std::cout << "\nDummy learner -> suggester feedback test\n";
    dummy_learner.process_explicit_feedback(UserIntent::FastTyping, AIAction::DisableSpellCheck, true, seq, AbstractState::HighProductivity);

    // user profile manager tests (simulate)
    dummy_user_profile_manager.add_explicit_action_feedback(UserIntent::Programming, AIAction::OpenDocumentation, true);
    dummy_user_profile_manager.save_profile("test_user_profile.json");
    dummy_user_profile_manager.load_profile("test_user_profile.json");

    // YENÄ° TESTLER: LearningModule ve KnowledgeBase
    std::cout << "\n--- LearningModule ve KnowledgeBase Testleri ---\n";
    KnowledgeBase test_kb;
    LearningModule test_lm(test_kb); 

    // Test LearningModule::learnFromText
    std::cout << "\nLearningModule::learnFromText testi:\n";
    test_lm.learnFromText("Bu bir test metnidir.", "Test Kaynak", "Genel");
    test_lm.learnFromText("Qt programlama cok keyifli.", "Blog", "Programlama");
    test_lm.learnFromText("Qt tasarim prensipleri.", "Dokuman", "Programlama");
    assert(test_kb.search_by_topic("Genel").size() == 1); 
    assert(test_kb.search_by_topic("Programlama").size() == 2); 
    std::cout << "learnFromText baÅŸarÄ±lÄ±.\n";

    // Test KnowledgeBase::semantic_search
    std::cout << "\nKnowledgeBase::semantic_search testi:\n";
    auto similar_capsules = test_kb.semantic_search("Qt", 1); 
    assert(!similar_capsules.empty());
    std::cout << "En benzer kapsÃ¼l: " << similar_capsules[0].content << "\n";

    // Test KnowledgeBase::encrypt/decrypt
    std::cout << "\nKnowledgeBase::encrypt/decrypt testi:\n";
    std::string original_text = "Gizli bilgi";
    std::string encrypted_text = test_kb.encrypt(original_text);
    std::string decrypted_text = test_kb.decrypt(encrypted_text); 
    assert(original_text == decrypted_text);
    std::cout << "Åžifreleme/Ã§Ã¶zme baÅŸarÄ±lÄ±.\n";

    // Test KnowledgeBase::quarantine_capsule ve revert_capsule
    std::cout << "\nKnowledgeBase::quarantine_capsule ve revert_capsule testi:\n";
    Capsule cap_to_quarantine;
    cap_to_quarantine.id = "quarantine_test_id";
    cap_to_quarantine.content = "Bu karantinaya alÄ±nacak bir kapsÃ¼l.";
    cap_to_quarantine.source = "Test";
    cap_to_quarantine.topic = "Quarantine";
    cap_to_quarantine.timestamp_utc = std::chrono::system_clock::now(); 
    cap_to_quarantine.plain_text_summary = "Karantina kapsÃ¼l Ã¶zeti.";
    cap_to_quarantine.cryptofig_blob_base64 = "dummy_cryptofig_blob";
    cap_to_quarantine.signature_base64 = "dummy_signature";
    cap_to_quarantine.encryption_iv_base64 = "dummy_iv";

    test_kb.add_capsule(cap_to_quarantine);
    std::optional<Capsule> found_cap = test_kb.find_capsule_by_id("quarantine_test_id");
    assert(found_cap.has_value());
    test_kb.quarantine_capsule("quarantine_test_id");
    assert(!test_kb.find_capsule_by_id("quarantine_test_id").has_value()); 

    // Karantinadaki kapsÃ¼lÃ¼ geri almayÄ± dene
    test_kb.revert_capsule("quarantine_test_id");
    assert(test_kb.find_capsule_by_id("quarantine_test_id").has_value()); 
    std::cout << "Karantina ve geri alma baÅŸarÄ±lÄ±.\n";


    // Test LearningModule::process_ai_insights
    std::cout << "\nLearningModule::process_ai_insights testi:\n";
    std::vector<AIInsight> dummy_insights;
    dummy_insights.push_back(AIInsight("New performance improvement detected.", AIAction::None, 0.9f)); 
    dummy_insights.push_back(AIInsight("User interface response time decreased.", AIAction::None, 0.7f)); 
    test_lm.process_ai_insights(dummy_insights);
    assert(test_lm.search_by_topic("AI Insight").size() == dummy_insights.size()); 
    std::cout << "process_ai_insights baÅŸarÄ±lÄ±.\n";

    std::cout << "\nTÃ¼m testler tamamlandi (dÃ¼zeltilmiÅŸ test dosyasÄ±).\n";
    return 0;
} 
